{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"IqPntmE89Cvm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656764298289,"user_tz":-330,"elapsed":16258,"user":{"displayName":"Josh L","userId":"09762323287470919868"}},"outputId":"6749a89c-1bbb-488c-9bcd-b747cfb24e81"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"FOBOuKv7T3Tn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656764302985,"user_tz":-330,"elapsed":4701,"user":{"displayName":"Josh L","userId":"09762323287470919868"}},"outputId":"9cc00089-aa9c-4e5a-fbb3-f3a1623a6a76"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l\r\u001b[K     |▏                               | 10 kB 36.9 MB/s eta 0:00:01\r\u001b[K     |▍                               | 20 kB 29.7 MB/s eta 0:00:01\r\u001b[K     |▋                               | 30 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |▉                               | 40 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█                               | 51 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 61 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 71 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 81 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 92 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |██                              | 102 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 112 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 122 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 133 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 143 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███                             | 153 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 163 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 174 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 184 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 194 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████                            | 204 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 215 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 225 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 235 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 245 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████                           | 256 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 266 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 276 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 286 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 296 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████                          | 307 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 317 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 327 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 337 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 348 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████                         | 358 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 368 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 378 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 389 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 399 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████                        | 409 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 419 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 430 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 440 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 450 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 460 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 471 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 481 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 491 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 501 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 512 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 522 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 532 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 542 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 552 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 563 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 573 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 583 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 593 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 604 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 614 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 624 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 634 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 645 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 655 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 665 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 675 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 686 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 696 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 706 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 716 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 727 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 737 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 747 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 757 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 768 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 778 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 788 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 798 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 808 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 819 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 829 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 839 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 849 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 860 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 870 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 880 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 890 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 901 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 911 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 921 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 931 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 942 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 952 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 962 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 972 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 983 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 993 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 1.0 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.0 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.0 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.0 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.0 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.2 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.2 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.2 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.2 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.2 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.2 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.2 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.2 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.2 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.2 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.3 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.3 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.3 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.3 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.3 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.3 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.3 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.3 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.3 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.4 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.4 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.4 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.4 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.4 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.4 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.4 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.4 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.4 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.4 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.5 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.5 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.5 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.5 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.5 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.5 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.5 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.5 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.5 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.5 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.6 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.6 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.6 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.6 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.6 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.6 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.6 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.6 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.6 MB 5.3 MB/s \n","\u001b[?25h  Building wheel for reverse-geocode (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install reverse_geocode -q"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"5xdjtDy3_H_G","executionInfo":{"status":"ok","timestamp":1656764303539,"user_tz":-330,"elapsed":558,"user":{"displayName":"Josh L","userId":"09762323287470919868"}}},"outputs":[],"source":["import pandas as pd\n","pd.set_option('display.max_rows', 100)\n","pd.set_option('display.max_columns', 200)\n","pd.set_option('display.width', 1000)\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","import reverse_geocode\n","import time\n","import itertools\n","from datetime import datetime\n","import pickle\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"wyrY7e_HEyP-","executionInfo":{"status":"ok","timestamp":1656764304079,"user_tz":-330,"elapsed":545,"user":{"displayName":"Josh L","userId":"09762323287470919868"}}},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing   import OneHotEncoder\n","from sklearn.preprocessing   import OrdinalEncoder\n","from sklearn.preprocessing   import MinMaxScaler\n","\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import f1_score\n","\n","from sklearn.cluster import KMeans\n","\n","from scipy.stats import mode"]},{"cell_type":"markdown","metadata":{"id":"9VJR2VptfOzR"},"source":["Create features for vendor_tag_name attribute (Food specialities available in the restaurant)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"xNCQ_YZtfJjd","executionInfo":{"status":"ok","timestamp":1656764304080,"user_tz":-330,"elapsed":13,"user":{"displayName":"Josh L","userId":"09762323287470919868"}}},"outputs":[],"source":["def add_food_cols(row,food_items):\n","  try:\n","    for item in food_items:\n","      row[item] = int(item in(row[\"vendor_tag_name\"].split(',')))\n","  except:\n","    for item in food_items:\n","      row[item] = 0.0\n","  return row"]},{"cell_type":"markdown","metadata":{"id":"-I6nGGbpiI6b"},"source":["**Extract working hours of the restaurant from OpeningTime attribute**\n","\n","https://www.geeksforgeeks.org/python-datetime-strptime-function/\n","\n","strftime() converts a time input into a string output. strptime() converts a text input into a time output.\n","\n","strptime is a method available in DateTime which is used to format the time stamp which is in string format to date-time object\n","\n","* hour is mostly zero padded decimal (%I)\n","* minute is zero padded (%M)\n","* AM or PM (%p)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"1oBlu1ZmiJt7","executionInfo":{"status":"ok","timestamp":1656764304080,"user_tz":-330,"elapsed":12,"user":{"displayName":"Josh L","userId":"09762323287470919868"}}},"outputs":[],"source":["def calculate_duration(timings):\n","\n","  try:\n","    try:\n","      close_time = datetime.strptime(timings[1],\"%I:%M%p\")\n","    except ValueError:\n","      close_time = datetime.strptime(timings[1],\"%I%p\")\n","    try:\n","      open_time = datetime.strptime(timings[0],\"%I:%M%p\")\n","    except ValueError:\n","      open_time = datetime.strptime(timings[0],\"%I%p\")\n","\n","    duration = close_time-open_time\n","    return round(abs(duration.total_seconds())/3600,2)\n","\n","  except:\n","    return np.nan\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"XriGR4frgLGv","executionInfo":{"status":"ok","timestamp":1656764304081,"user_tz":-330,"elapsed":12,"user":{"displayName":"Josh L","userId":"09762323287470919868"}}},"outputs":[],"source":["def process_vendors(location,filename):\n","  vendors = pd.read_csv(location + filename)\n","  vendors[\"id\"] = vendors[\"id\"].astype('str')\n","  vendors.rename(columns={'id':'vendor_id'},inplace=True)\n","\n","  #Create count feature for vendor_tag attribute (Number of food specialities available in the restaurant)\n","  vendors[\"tag_counts\"]=vendors[\"vendor_tag\"].str.split(',').str.len()\n","  vendors[\"tag_counts\"].fillna(0,inplace=True)\n","\n","  #Food specialities of the vendor\n","  vendor_foods = pd.unique(vendors.loc[~vendors[\"vendor_tag_name\"].isna(),\"vendor_tag_name\"])\n","  food_list = [foods.split(',') for foods in vendor_foods] \n","  food_items = list(set(itertools.chain(*food_list))) \n","  vendors = vendors.apply(lambda x: add_food_cols(x,food_items=food_items),axis=1)\n","  \n","  #Extract numerical part of the primary_tags\n","  vendors[\"primary_tags\"].fillna('{\"primary_tags\":\"0\"}',inplace=True) #0 is assigned for null values\n","  vendors[\"primary_tags_mod\"] = vendors[\"primary_tags\"].str.split('{\"primary_tags\":\"').str[1].str.split('\"}').str[0]  \n","\n","  vendors[\"OpeningTime\"]= vendors[\"OpeningTime\"].str.replace(\" \",\"\").str.replace(\".\",\":\").str.replace(\"::\",\":\").str.replace(\"111\",\"11\").str.replace('08:00AM-11:45-','08:00AM-11:45PM')\n","  vendors[\"timings\"] = vendors[\"OpeningTime\"].str.split('-')\n","  vendors[\"open_duration\"] = vendors[\"timings\"].apply(calculate_duration)\n","  vendors[\"open_duration\"].fillna(round(vendors[\"open_duration\"].mean(),2),inplace=True)\n","\n","  #Time Features\n","  vendors[\"year_vendor_created\"] = pd.to_datetime(vendors[\"created_at\"]).dt.year\n","  vendors[\"month_vendor_created\"] = pd.to_datetime(vendors[\"created_at\"]).dt.month\n","  vendors[\"year_vendor_updated\"] = pd.to_datetime(vendors[\"updated_at\"]).dt.year\n","  vendors[\"month_vendor_updated\"] = pd.to_datetime(vendors[\"updated_at\"]).dt.month\n","\n","  #Fix nan values for commission, language\n","  vendors[\"commission\"].fillna(1.0,inplace=True)\n","  vendors[\"language\"].fillna(\"NA\",inplace=True)\n","  vendors[\"language\"] = vendors[\"language\"].map({\"NA\":0,\"EN\":1})\n","\n","  #Verify vendor locations\n","  #All the vendor locations are in Africa except for 2 which has incorrect coordinate values\n","  vendors_valid = vendors[(((vendors[\"latitude\"] >= -90.0) & (vendors[\"latitude\"] <= 90.0)) & ((vendors[\"longitude\"] >= -180.0) & (vendors[\"longitude\"] <= 180.0)))]\n","\n","  coordinates = list(zip(vendors_valid[\"latitude\"],vendors_valid[\"longitude\"]))\n","  vendors_valid[[\"country_code\",\"vendor_city\",\"vendor_country\"]] = pd.DataFrame(reverse_geocode.search(coordinates))\n","  vendors_valid[\"vendor_city\"].fillna(\"null\",inplace=True)\n","  vendors_valid[\"vendor_country\"].fillna(\"null\",inplace=True)\n","\n","  #Extract the vendor info with incorrect coordinates and set their city and country values\n","  vendors_invalid = vendors[~(((vendors[\"latitude\"] >= -90.0) & (vendors[\"latitude\"] <= 90.0)) & ((vendors[\"longitude\"] >= -180.0) & (vendors[\"longitude\"] <= 180.0)))]\n","  vendors_invalid[\"vendor_city\"]=\"invalid\"\n","  vendors_invalid[\"vendor_country\"]=\"invalid\"\n","  vendors_valid = vendors_valid.append(vendors_invalid,ignore_index=True)\n","\n","  #Remove the unwanted features\n","  vendor_dropcols = [\"vendor_tag_name\",\"vendor_tag\",\"vendor_category_en\",\"authentication_id\",\"created_at\",\"updated_at\",\"OpeningTime\",\"OpeningTime2\",\"timings\",\"primary_tags\",\"is_akeed_delivering\",\"country_code\",\"open_close_flags\",\"one_click_vendor\",\"country_id\",\"city_id\",\"display_orders\",'sunday_from_time1', 'sunday_to_time1', 'sunday_from_time2', 'sunday_to_time2', 'monday_from_time1', 'monday_to_time1', 'monday_from_time2', 'monday_to_time2', 'tuesday_from_time1', 'tuesday_to_time1', 'tuesday_from_time2', 'tuesday_to_time2', 'wednesday_from_time1', 'wednesday_to_time1', 'wednesday_from_time2', 'wednesday_to_time2', 'thursday_from_time1', 'thursday_to_time1', 'thursday_from_time2', 'thursday_to_time2', 'friday_from_time1', 'friday_to_time1', 'friday_from_time2', 'friday_to_time2', 'saturday_from_time1', 'saturday_to_time1', 'saturday_from_time2', 'saturday_to_time2']\n","  vendors_valid = vendors_valid.drop(columns=vendor_dropcols)\n","  return vendors_valid\n"]},{"cell_type":"markdown","metadata":{"id":"pGjR0_guG-EQ"},"source":["Generate vendor summary from orders file"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"Q3JrFyolG7ef","executionInfo":{"status":"ok","timestamp":1656764304081,"user_tz":-330,"elapsed":11,"user":{"displayName":"Josh L","userId":"09762323287470919868"}}},"outputs":[],"source":["def process_vendor_summary(location,filename):\n","  orders = pd.read_csv(location + filename)\n","  orders.drop_duplicates(subset=['akeed_order_id'],inplace=True)\n","  orders['created_at'] = pd.to_datetime(orders[\"created_at\"])\n","  orders['delivered_time'] = pd.to_datetime(orders['delivered_time']) \n","  orders[['CID','LOC_NUM','VENDOR']] = orders['CID X LOC_NUM X VENDOR'].str.split(' X ',expand=True)\n","\n","  orders[\"preparationtime\"].fillna(orders[\"preparationtime\"].groupby(orders[\"VENDOR\"]).transform('mean'),inplace=True)\n","  orders[\"preparationtime\"].fillna(orders[\"preparationtime\"].mean(),inplace=True)\n","  orders[\"promo_code_discount_percentage\"].fillna(0,inplace=True)\n","  orders[\"is_favorite\"].fillna(\"null\",inplace=True)\n","\n","  #For few records the timestamps looks to be swapped...hence absolute function\n","  orders[\"order_turnaround\"] = np.abs((orders[\"delivered_time\"] - orders[\"created_at\"]).apply(lambda x: x.total_seconds())) #total_seconds method belongs to timedelta object\n","\n","  vendor_summary = orders.groupby(orders[\"VENDOR\"]).agg({\n","    'customer_id':['count','nunique'],\n","    'payment_mode':['nunique'],\n","    'promo_code':['count'],\n","    'vendor_discount_amount':['sum'],\n","    'promo_code_discount_percentage':['mean'],\n","    'item_count':['median'],\n","    'grand_total':['median'],\n","    'driver_rating' : ['median'],\n","    'deliverydistance' : ['mean'],\n","    'preparationtime' :['mean'],\n","    'order_turnaround':['min','max','mean']}).reset_index()\n","\n","  vendor_summary.columns = ['_'.join(col).strip() for col in vendor_summary.columns.values]\n","  vendor_summary.rename(columns={'VENDOR_':'vendor_id'},inplace=True)\n","  \n","  return vendor_summary"]},{"cell_type":"markdown","metadata":{"id":"7HDfFry6Baqa"},"source":["Customer Demographics"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"RuuO5ur8BZZh","executionInfo":{"status":"ok","timestamp":1656764304081,"user_tz":-330,"elapsed":11,"user":{"displayName":"Josh L","userId":"09762323287470919868"}}},"outputs":[],"source":["def process_customer_demo(location,filename):\n","\n","  customers = pd.read_csv(location + filename)\n","  customers[\"updated_at\"] = pd.to_datetime(customers[\"updated_at\"])\n","  customers[\"created_at\"] = pd.to_datetime(customers[\"created_at\"])\n","\n","  #Remove duplicate records by extracting the last updated records\n","  customers_dedup = customers[customers[\"updated_at\"] == customers.groupby([\"akeed_customer_id\"])['updated_at'].transform('max')]\n","  \n","  #remove trailing spaces in gender and convert to lower case\n","  customers_dedup.loc[:,\"gender\"] = customers_dedup[\"gender\"].astype(\"str\").str.rstrip().str.lower()\n","\n","  #fix missing and incorrect values as 'unknown'\n","  customers_dedup.loc[~customers_dedup[\"gender\"].isin([\"male\",\"female\"]),\"gender\"] = \"unknown\"\n","\n","  #time features\n","  customers_dedup['year_customer_created'] = customers_dedup['created_at'].dt.year\n","  customers_dedup['month_customer_created'] = customers_dedup['created_at'].dt.month\n","  customers_dedup['year_customer_updated'] = customers_dedup['updated_at'].dt.year\n","  customers_dedup['month_customer_updated'] = customers_dedup['updated_at'].dt.month\n","                                                    \n","  customers_dedup = customers_dedup[['akeed_customer_id', 'gender', 'verified', 'language', 'year_customer_created', 'month_customer_created', 'year_customer_updated', 'month_customer_updated']]\n","\n","  return customers_dedup"]},{"cell_type":"markdown","metadata":{"id":"j3f3mpmrIQXd"},"source":["Customer Locations\n","\n","https://datascientyst.com/reverse-geocoding-latitude-longitude-city-country-python-pandas/"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"N8pWbWuDP0F_","executionInfo":{"status":"ok","timestamp":1656764304082,"user_tz":-330,"elapsed":11,"user":{"displayName":"Josh L","userId":"09762323287470919868"}}},"outputs":[],"source":["def process_customer_location(location,filename):\n","  \n","  locations = pd.read_csv(location + filename)\n","  locations[\"location_type\"].fillna('Null',inplace=True)\n","  locations['location_type'] = locations['location_type'].map({'Null':0,'Home':1,'Work':2,'Other':3})\n","\n","  locations[\"latitude\"].fillna(locations.groupby([\"customer_id\"])[\"latitude\"].transform(\"mean\"),inplace=True)\n","  locations[\"longitude\"].fillna(locations.groupby([\"customer_id\"])[\"longitude\"].transform(\"mean\"),inplace=True)\n","  \n","  locations[\"latitude\"].fillna(locations[\"latitude\"].mean(),inplace=True)\n","  locations[\"longitude\"].fillna(locations[\"longitude\"].mean(),inplace=True)\n","\n","  locations_valid = locations[(((locations[\"latitude\"] >= -90.0) & (locations[\"latitude\"] <= 90.0)) & ((locations[\"longitude\"] >= -180.0) & (locations[\"longitude\"] <= 180.0)))]\n","\n","  #Retrieve the city and country of those coordinates \n","  coordinates = list(zip(locations_valid[\"latitude\"],locations_valid[\"longitude\"]))\n","  locations_valid[[\"country_code\",\"customer_city\",\"customer_country\"]] = pd.DataFrame(reverse_geocode.search(coordinates))\n","  locations_valid.drop(columns=[\"country_code\"],inplace=True)\n","\n","  locations_valid[\"customer_city\"].fillna(\"null\",inplace=True)  #null for coordinates without city or country details\n","  locations_valid[\"customer_country\"].fillna(\"null\",inplace=True)\n","  locations_valid = locations_valid.append(locations[~(((locations[\"latitude\"] >= -90.0) & (locations[\"latitude\"] <= 90.0)) & ((locations[\"longitude\"] >= -180.0) & (locations[\"longitude\"] <= 180.0))) | locations[\"latitude\"].isna()])\n","  locations_valid[\"customer_city\"].fillna(\"invalid\",inplace=True)\n","  locations_valid[\"customer_country\"].fillna(\"invalid\",inplace=True)\n","\n","  return locations_valid"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"PBu_Lc0v2sj3","executionInfo":{"status":"ok","timestamp":1656764304082,"user_tz":-330,"elapsed":11,"user":{"displayName":"Josh L","userId":"09762323287470919868"}}},"outputs":[],"source":["def haversine_np(longitude1, latitude1, longitude2, latitude2):\n","    \"\"\"\n","    Calculate the great circle distance between two points\n","    on the earth (specified in decimal degrees)\n","\n","    All args must be of equal length.    \n","\n","    \"\"\"\n","    longitude1, latitude1, longitude2, latitude2 = map(np.radians, [longitude1, latitude1, longitude2, latitude2])\n","\n","    longdiff = longitude2 - longitude1\n","    latdiff = latitude2 - latitude1\n","\n","    a = np.sin(latdiff/2.0)**2 + np.cos(latitude1) * np.cos(latitude2) * np.sin(longdiff/2.0)**2\n","\n","    c = 2 * np.arcsin(np.sqrt(a))\n","    haversine_dist = 6367 * c\n","    return haversine_dist"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"qlT8sQLn26Dn","executionInfo":{"status":"ok","timestamp":1656764304082,"user_tz":-330,"elapsed":9,"user":{"displayName":"Josh L","userId":"09762323287470919868"}}},"outputs":[],"source":["def merge_demo_loc_vendor(demographics_df,location_df,vendors_df):\n","  '''\n","  1. Merge demographics and location data\n","\n","  2. Then merge vendors data\n","\n","  3. Then merge the target\n","  '''\n","  # Merge demographics and location data\n","  location_demograph = location_df.merge(demographics_df,left_on=\"customer_id\",right_on=\"akeed_customer_id\",how=\"left\")\n","  location_demograph.drop(columns=[\"akeed_customer_id\"],inplace=True)\n","\n","  # Fill for those customer-locations whose customer details are not available in customer-demographics data\n","  location_demograph['month_customer_updated'].fillna(99,inplace=True)\n","  location_demograph['month_customer_created'].fillna(99,inplace=True)\n","  location_demograph['year_customer_created'].fillna(9999,inplace=True)\n","  location_demograph['year_customer_updated'].fillna(9999,inplace=True)\n","  location_demograph['verified'].fillna(99,inplace=True)\n","  location_demograph[\"language\"].fillna('null',inplace=True)\n","  location_demograph.fillna(\"null\",inplace=True) \n","\n","  # Merge vendor data with location demograph file\n","  vendors_df[\"key\"] = 1\n","  location_demograph[\"key\"] = 1\n","  cust_vendorval = location_demograph.merge(vendors_df,on=\"key\") #cartesian join\n","  cust_vendorval[\"CID X LOC_NUM X VENDOR\"] = cust_vendorval[\"customer_id\"] + \" X \" + cust_vendorval[\"location_number\"].astype('str') + \" X \" + cust_vendorval[\"vendor_id\"].astype('str')\n","  \n","  # Compute haversine distance between vendor and customer\n","  # Extract features comparing haversine distance and serving distance of the vendor using differences and ratios\n","  cust_vendorval['haversine_distance'] = haversine_np(cust_vendorval['longitude_x'],cust_vendorval['latitude_x'],cust_vendorval['longitude_y'],cust_vendorval['latitude_y'])\n","  cust_vendorval['distance_diff']      = cust_vendorval['haversine_distance'] - cust_vendorval['serving_distance']\n","  cust_vendorval['distance_ratio']     = cust_vendorval['haversine_distance'] / cust_vendorval['serving_distance']\n","  cust_vendorval['latitude_diff']      = cust_vendorval[\"latitude_x\"] - cust_vendorval[\"latitude_y\"]\n","  cust_vendorval['longitude_diff']     = cust_vendorval[\"longitude_x\"] - cust_vendorval[\"longitude_y\"]\n","\n","  # Create target variable\n","  # Merge feature data with order data to create the target variable\n","  # Those with matches in the order table are considered as positive class since the customer has ordered from the vendor\n","  orders = pd.read_csv(input_location + orders_file)\n","  orders.drop_duplicates(subset=['CID X LOC_NUM X VENDOR'],inplace=True)\n","  orders[\"target\"] = 1\n","  cust_vendorval = pd.merge(cust_vendorval,orders[['CID X LOC_NUM X VENDOR','target']],on='CID X LOC_NUM X VENDOR',how=\"left\")\n","  cust_vendorval[\"target\"].fillna(0,inplace=True)\n","  \n","  return cust_vendorval"]},{"cell_type":"markdown","metadata":{"id":"K8pNopWBpAtU"},"source":["##Separate outliers into different dataframes"]},{"cell_type":"markdown","metadata":{"id":"ZAx0NF1-E3IG"},"source":["1. Outlier customers are those with coordinates corresponding are outside the normal range of latitudes and longitudes.\n","\n","2. Outlier vendors are those with coordinates very different from the rest.\n","\n","3. Subject only valid customers buying from valid vendors (excluding outliers) to clustering\n","\n","4. Separate model will be built for \n","    * valid customers buying from outlier vendors\n","    * outlier customers buying from outlier vendors\n","    * outlier customers buying from valid vendors"]},{"cell_type":"code","source":["def segregate_outliers(cust_vendorval):\n","  outlier_customer_countries = [\"invalid\"] #the coordinates corresponding to these countries are outside the normal range of latitudes and longitudes\n","  outlier_vendors = [\"907\",\"231\"] #these vendor coordinates are very different from the rest\n","  valcust_valvendors = train_cust_vendorval.loc[((~train_cust_vendorval[\"customer_country\"].isin(outlier_customer_countries)) & (~train_cust_vendorval[\"vendor_id\"].isin(outlier_vendors)))].reset_index()\n","  valcust_outvendors = train_cust_vendorval.loc[((~train_cust_vendorval[\"customer_country\"].isin(outlier_customer_countries)) & (train_cust_vendorval[\"vendor_id\"].isin(outlier_vendors)))].reset_index()\n","  outcust_outvendors = train_cust_vendorval.loc[((train_cust_vendorval[\"customer_country\"].isin(outlier_customer_countries)) & (train_cust_vendorval[\"vendor_id\"].isin(outlier_vendors)))].reset_index()\n","  outcust_valvendors = train_cust_vendorval.loc[((train_cust_vendorval[\"customer_country\"].isin(outlier_customer_countries)) & (~train_cust_vendorval[\"vendor_id\"].isin(outlier_vendors)))].reset_index()\n","\n","  return valcust_valvendors, valcust_outvendors, outcust_outvendors, outcust_valvendors"],"metadata":{"id":"13hJ8PNo3dOC","executionInfo":{"status":"ok","timestamp":1656764304082,"user_tz":-330,"elapsed":8,"user":{"displayName":"Josh L","userId":"09762323287470919868"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1656764304083,"user":{"displayName":"Josh L","userId":"09762323287470919868"},"user_tz":-330},"id":"0hLxiMB_Pb4M"},"outputs":[],"source":["def prep_clustering_input(valcust_valvendors,is_train=\"Y\"):\n","  clustering_input_cols = ['latitude_x', 'longitude_x', 'latitude_y', 'longitude_y', 'haversine_distance', 'distance_diff','distance_ratio','latitude_diff','longitude_diff',\n","                              'is_open','Arabic', 'Crepes', 'Kushari', 'Shawarma', 'Fries', 'Manakeesh', 'Mojitos', \n","                              'Organic', 'Frozen yoghurt', 'Sweets', 'Coffee', 'Donuts', 'Hot Chocolate', 'American', 'Rice', 'Thali', 'Healthy Food',\n","                              'Bagels', 'Combos', 'Chinese', 'Free Delivery', 'Kebabs', 'Desserts', 'Waffles', 'Churros', 'Salads', 'Pastas', \n","                              'Fresh Juices', 'Seafood', 'Milkshakes', 'Karak', 'Cafe', 'Biryani', 'Ice creams', 'Pizzas', 'Kids meal', 'Japanese', \n","                              'Cakes', 'Pasta', 'Steaks', 'Indian', 'Sandwiches', 'Vegetarian', 'Thai', 'Spanish Latte', 'Italian', 'Fatayers', \n","                              'Pancakes', 'Smoothies', 'Hot Dogs', 'Mandazi', 'Dimsum', 'Pizza', 'Burgers', 'Rolls', 'Grills', 'Pastry', 'Sushi', \n","                              'Family Meal', 'Breakfast', 'Lebanese', 'Omani', 'Asian', 'Mojitos ', 'Shuwa',\n","                              'Mexican', 'Soups', 'Mishkak', 'open_duration']\n","\n","  to_normalize_cols = ['latitude_x', 'longitude_x', 'latitude_y', 'longitude_y', 'haversine_distance', 'distance_diff','distance_ratio',\n","                     'latitude_diff','longitude_diff','open_duration']\n","\n","  clustering_input = valcust_valvendors[clustering_input_cols]\n","  \n","  if is_train == \"Y\":\n","    mmscaler = MinMaxScaler()\n","    mmscaler.fit(clustering_input[to_normalize_cols])\n","    pickle.dump(mmscaler, open(output_location1 + 'vendcust_cluster_scaler.pkl', 'wb'))\n","\n","  else:\n","    mmscaler = pickle.load(open(output_location1 + \"vendcust_cluster_scaler.pkl\",\"rb\"))\n","\n","  clustering_input[to_normalize_cols] = pd.DataFrame(mmscaler.transform(clustering_input[to_normalize_cols].to_numpy()),columns = to_normalize_cols)\n","\n","  return clustering_input\n","    "]},{"cell_type":"code","execution_count":15,"metadata":{"id":"kWjvbCCwLQ7k","executionInfo":{"status":"ok","timestamp":1656764333367,"user_tz":-330,"elapsed":2,"user":{"displayName":"Josh L","userId":"09762323287470919868"}}},"outputs":[],"source":["input_location = \"/content/drive/MyDrive/01_Machine_Learning/05_Datasets/AppliedAI_data/Assignment23_CS1_RestaurantRecommendation/kaggle_data/\"\n","output_location1 = \"/content/drive/MyDrive/01_Machine_Learning/05_Datasets/AppliedAI_data/Assignment23_CS1_RestaurantRecommendation/vendor_customer/\"\n","train_customer_demographics = \"train_customers.csv\"\n","test_customer_demographics = \"test_customers.csv\"\n","train_customer_locations = \"train_locations.csv\"\n","test_customer_locations  = \"test_locations.csv\"\n","vendor_file = \"vendors.csv\"\n","orders_file = \"orders.csv\"\n","\n","customer_similarity_features = [\"customer_id\",\"location_number\",\"location_type\",'latitude', 'longitude','gender', 'verified', 'language','year_customer_created', 'month_customer_created']\n","categ_to_num = [\"gender\",\"verified\",\"language\",\"year_customer_created\",\"month_customer_created\"]\n","categ_to_ohe = [\"location_type\",'gender', 'verified', 'language','year_customer_created', 'month_customer_created']\n","num_cols = ['customer_id','location_number','latitude','longitude']  #'customer_id','location' added as key"]},{"cell_type":"markdown","metadata":{"id":"kQEYUqs6-Amb"},"source":["Process and Extract Vendor features"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ArI9woui9_kD","outputId":"507caa34-787c-4b43-bfb8-b9e95eaf33e2","executionInfo":{"status":"ok","timestamp":1656764342587,"user_tz":-330,"elapsed":7672,"user":{"displayName":"Josh L","userId":"09762323287470919868"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(100, 107)"]},"metadata":{},"execution_count":16}],"source":["vendors = process_vendors(input_location,vendor_file)\n","vendor_summary = process_vendor_summary(input_location,orders_file)\n","vendors = pd.merge(vendors,vendor_summary,on=[\"vendor_id\"],how=\"inner\")\n","vendor_locations = vendors[['vendor_id','latitude', 'longitude']]\n","vendors.shape"]},{"cell_type":"markdown","metadata":{"id":"D1RA9cdYeHho"},"source":["Process and Merge customer demographics and customer location data"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DV4L2AQQOtbD","outputId":"1d501378-8b67-46f2-b0d0-6217777a6074","executionInfo":{"status":"ok","timestamp":1656764382918,"user_tz":-330,"elapsed":39201,"user":{"displayName":"Josh L","userId":"09762323287470919868"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["(34523, 8)\n","(59503, 7)\n","(5950300, 129)\n","train_cust_vendorval - positive(80142, 129) - negative(5870158, 129)\n","Valid customers buying from valid vendors:  (5701150, 130)\n","Valid customers buying from outlier vendors:  (116350, 130)\n","Outlier customers buying from outlier vendors:  (2656, 130)\n","Outlier customers buying from valid vendors:  (130144, 130)\n"]}],"source":["train_customers = process_customer_demo(input_location,train_customer_demographics)\n","train_locations = process_customer_location(input_location,train_customer_locations)\n","train_cust_vendorval  = merge_demo_loc_vendor(train_customers,train_locations,vendors)    \n","train_valcust_valvendors, train_valcust_outvendors, train_outcust_outvendors, train_outcust_valvendors = segregate_outliers(train_cust_vendorval)   \n","\n","print(train_customers.shape)\n","print(train_locations.shape)\n","print(train_cust_vendorval.shape)\n","print(\"train_cust_vendorval - positive{} - negative{}\".format(train_cust_vendorval[train_cust_vendorval[\"target\"] == 1].shape,train_cust_vendorval[train_cust_vendorval[\"target\"] == 0].shape))\n","\n","print(\"Valid customers buying from valid vendors: \",train_valcust_valvendors.shape)\n","print(\"Valid customers buying from outlier vendors: \",train_valcust_outvendors.shape)\n","print(\"Outlier customers buying from outlier vendors: \",train_outcust_outvendors.shape)\n","print(\"Outlier customers buying from valid vendors: \",train_outcust_valvendors.shape)"]},{"cell_type":"markdown","metadata":{"id":"KF73DORzpqY9"},"source":["##Perform Clustering on Valid Customers buying from Valid Vendors"]},{"cell_type":"code","source":["import gc\n","del train_cust_vendorval, train_locations, train_customers\n","gc.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2-ycylsO-A-b","executionInfo":{"status":"ok","timestamp":1656764382919,"user_tz":-330,"elapsed":5,"user":{"displayName":"Josh L","userId":"09762323287470919868"}},"outputId":"5e174bed-7ac7-4fed-b5b7-0f0aa004a985"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["72"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2419,"status":"ok","timestamp":1656764392536,"user":{"displayName":"Josh L","userId":"09762323287470919868"},"user_tz":-330},"id":"q2A04WyoPBss","outputId":"ac60a339-1a02-4d13-dc9a-9d6732507258"},"outputs":[{"output_type":"stream","name":"stdout","text":["(5701150, 79)\n"]}],"source":["train_clustering_input = prep_clustering_input(train_valcust_valvendors,is_train=\"Y\")\n","print(train_clustering_input.shape)"]},{"cell_type":"markdown","metadata":{"id":"5gZcAnA-qxLf"},"source":["####Identify optimal number of clusters for the data\n","https://www.analyticsvidhya.com/blog/2021/05/k-mean-getting-the-optimal-number-of-clusters/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O3DJ1cRiqxLg"},"outputs":[],"source":["def determine_number_clusters(clustering_input):\n","\n","  metric_cost_dict = dict()\n","\n","  for k in tqdm([2, 3, 5, 10, 15,20,25,30,35,40]):\n","    kmeans = KMeans(n_clusters=k, n_init=10,random_state=7)\n","    kmeans.fit(clustering_input)\n","    y_cluster = kmeans.labels_\n","  \n","    metric_cost_dict[k] = kmeans.inertia_  \n","\n","  plt.plot(list(metric_cost_dict.keys()),list(metric_cost_dict.values()),'bx-')\n","  plt.xlabel('k values') \n","  plt.ylabel('Sum of squared distances') \n","  plt.title('Elbow Method For Optimal k')\n","  plt.show()\n","\n","  metric_key = list(metric_cost_dict.keys())\n","  metric_values = list(metric_cost_dict.values())\n","  diff_dict = dict()\n","  for ind in range(1,len(metric_cost_dict)):\n","    diff_dict[metric_key[ind]] = (metric_values[ind-1] - metric_values[ind]) / metric_values[ind-1]\n","\n","  print(\" \")\n","  plt.plot(list(diff_dict.keys()),list(diff_dict.values()),'bx-')\n","  plt.xlabel('k values') \n","  plt.ylabel('Inertia Differences') \n","  plt.title('Elbow Method For Optimal k')\n","  plt.show()\n","\n","  chosen_clusters = sorted(diff_dict.items(),key=lambda x: x[1])[0][0]\n","\n","  return metric_cost_dict, diff_dict, chosen_clusters"]},{"cell_type":"code","source":["metric_cost_dict, diff_dict, n_clusters = determine_number_clusters(train_clustering_input)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":591},"id":"hbLntz_KA0zH","executionInfo":{"status":"ok","timestamp":1655645152733,"user_tz":-330,"elapsed":2009579,"user":{"displayName":"Josh L","userId":"09762323287470919868"}},"outputId":"6e107bf4-58ac-482a-b24b-7918af3b27d2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 10/10 [33:28<00:00, 200.88s/it]\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"j56JkSLujfks"},"source":["40 is the chosen number of clusters"]},{"cell_type":"markdown","metadata":{"id":"G43-gF0qaOnP"},"source":["####Cluster data using the optimal number of clusters chosen"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"W6VzUJxqA0xU","executionInfo":{"status":"ok","timestamp":1656764425406,"user_tz":-330,"elapsed":299,"user":{"displayName":"Josh L","userId":"09762323287470919868"}}},"outputs":[],"source":["#Clustering using the selected k hyperparameter\n","def cluster_data(clustering_input, chosen_clusters,is_train=\"Y\"):\n","\n","  if is_train == \"Y\":\n","    kmeans = KMeans(n_clusters = chosen_clusters, n_init=10, random_state=7)\n","    kmeans.fit(clustering_input)\n","    pred_cluster = kmeans.labels_\n","    \n","    pickle.dump(kmeans, open(output_location1 + \"vendcust_cluster.pkl\", \"wb\"))\n","  else:\n","    cluster_model = pickle.load(open(output_location1 + \"vendcust_cluster.pkl\", \"rb\"))\n","    pred_cluster   = cluster_model.predict(clustering_input)\n","    \n","  clustering_input[\"cluster\"]  = pred_cluster\n","\n","  return clustering_input"]},{"cell_type":"code","source":["train_clustering_input = cluster_data(train_clustering_input,n_clusters,is_train=\"Y\")\n","train_valcust_valvendors[\"cluster\"] = train_clustering_input[\"cluster\"]\n","#Assign cluster number to the remaining files\n","train_valcust_outvendors[\"cluster\"] = 40\n","train_outcust_outvendors[\"cluster\"] = 41\n","train_outcust_valvendors[\"cluster\"] = 42\n","train_valcust_valvendors.groupby([\"cluster\"])[\"CID X LOC_NUM X VENDOR\"].count() #check how many records have gone to each cluster"],"metadata":{"id":"fwdqDEhlQFJg","executionInfo":{"status":"ok","timestamp":1655659172620,"user_tz":-330,"elapsed":398497,"user":{"displayName":"Josh L","userId":"09762323287470919868"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"93f065ea-b9c6-47b4-bfa1-d1ff09c03180"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["cluster\n","0     274175\n","1      58179\n","2      58175\n","3     418147\n","4     470010\n","5     116350\n","6     391676\n","7     116350\n","8     195840\n","9     152059\n","10    156671\n","11     97840\n","12    190069\n","13    117503\n","14     78338\n","15     58175\n","16    117507\n","17     58175\n","18    116350\n","19    152057\n","20    272522\n","21    313343\n","22     58175\n","23    174525\n","24    195841\n","25     95035\n","26     97344\n","27     97344\n","28     97344\n","29     58175\n","30     77183\n","31    116350\n","32    209082\n","33     57022\n","34     58175\n","35     58175\n","36     58175\n","37     97344\n","38     58175\n","39     58175\n","Name: CID X LOC_NUM X VENDOR, dtype: int64"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["del train_clustering_input\n","gc.collect()"],"metadata":{"id":"Y4QTuV_R9FET"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k8c1AP6hU_7r"},"source":["Customer Vendor Clustering Ends Here"]},{"cell_type":"markdown","metadata":{"id":"wK1JJqxpc9Zt"},"source":["##Convert categorical features to numerical features for LGBM model"]},{"cell_type":"code","source":["def prep_categ_features_lgbm(valcust_valvendors,valcust_outvendors, outcust_outvendors, outcust_valvendors, is_train=\"Y\"):\n","\n","  convert_cols = [\"customer_city\",\"customer_country\",\"vendor_city\",\"vendor_country\",\"gender\",\"verified_x\",\"language_x\",\"year_customer_created\",\"month_customer_created\",\"year_customer_updated\",\"month_customer_updated\",\n","                \"vendor_category_id\",\"delivery_charge\",\"serving_distance\",\"prepration_time\",\"discount_percentage\",\"rank\",\"vendor_rating\",\n","                \"device_type\",\"tag_counts\",\"primary_tags_mod\",\"primary_tags_mod\",\"year_vendor_created\",\"month_vendor_created\", \n","                \"year_vendor_updated\", \"month_vendor_updated\"]\n","\n","  dropcols = ['customer_id', 'location_number','key', 'vendor_id']\n","  valcust_valvendors.drop(columns=dropcols,inplace=True)\n","  valcust_outvendors.drop(columns=dropcols,inplace=True)\n","  outcust_outvendors.drop(columns=dropcols,inplace=True)\n","  outcust_valvendors.drop(columns=dropcols,inplace=True)\n","\n","  if is_train == \"Y\":\n","    valcust_valvendors_enc = OrdinalEncoder()\n","    valcust_valvendors_enc.fit(valcust_valvendors[convert_cols])\n","    valcust_valvendors[convert_cols] = valcust_valvendors_enc.transform(valcust_valvendors[convert_cols])\n","    pickle.dump(valcust_valvendors_enc, open(output_location1 + \"valcust_valvendors_encoder.pkl\",\"wb\"))\n","\n","    valcust_outvendors_enc = OrdinalEncoder()\n","    valcust_outvendors_enc.fit(valcust_outvendors[convert_cols])\n","    valcust_outvendors[convert_cols] = valcust_outvendors_enc.transform(valcust_outvendors[convert_cols])\n","    pickle.dump(valcust_outvendors_enc, open(output_location1 + \"valcust_outvendors_encoder.pkl\",\"wb\"))\n","\n","    outcust_outvendors_enc = OrdinalEncoder()\n","    outcust_outvendors_enc.fit(outcust_outvendors[convert_cols])\n","    outcust_outvendors[convert_cols] = outcust_outvendors_enc.transform(outcust_outvendors[convert_cols])\n","    pickle.dump(outcust_outvendors_enc, open(output_location1 + \"outcust_outvendors_encoder.pkl\",\"wb\"))\n","\n","    outcust_valvendors_enc = OrdinalEncoder()\n","    outcust_valvendors_enc.fit(outcust_valvendors[convert_cols])\n","    outcust_valvendors[convert_cols] = outcust_valvendors_enc.transform(outcust_valvendors[convert_cols])\n","    pickle.dump(outcust_valvendors_enc, open(output_location1 + \"outcust_valvendors_encoder.pkl\",\"wb\"))\n","\n","  else:\n","\n","    valcust_valvendors_enc = pickle.load(open(output_location1 + \"valcust_valvendors_encoder.pkl\",\"rb\"))\n","    valcust_valvendors[convert_cols] = valcust_valvendors_enc.transform(valcust_valvendors[convert_cols])\n","    \n","    valcust_outvendors_enc = pickle.load(open(output_location1 + \"valcust_outvendors_encoder.pkl\",\"rb\"))\n","    valcust_outvendors[convert_cols] = valcust_outvendors_enc.transform(valcust_outvendors[convert_cols])\n","    \n","    outcust_outvendors_enc = pickle.load(open(output_location1 + \"outcust_outvendors_encoder.pkl\",\"rb\"))\n","    outcust_outvendors[convert_cols] = outcust_outvendors_enc.transform(outcust_outvendors[convert_cols])\n","    \n","    outcust_valvendors_enc = pickle.load(open(output_location1 + \"outcust_valvendors_encoder.pkl\",\"rb\"))\n","    outcust_valvendors[convert_cols] = outcust_valvendors_enc.transform(outcust_valvendors[convert_cols])\n","    \n","  return valcust_valvendors, valcust_outvendors, outcust_outvendors, outcust_valvendors\n","  "],"metadata":{"id":"KO4baV1sy8yK","executionInfo":{"status":"ok","timestamp":1656764524577,"user_tz":-330,"elapsed":473,"user":{"displayName":"Josh L","userId":"09762323287470919868"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["train_valcust_valvendors, train_valcust_outvendors, train_outcust_outvendors, train_outcust_valvendors = prep_categ_features_lgbm(train_valcust_valvendors,train_valcust_outvendors, train_outcust_outvendors, train_outcust_valvendors, is_train=\"Y\")"],"metadata":{"id":"zI55svzh4sTv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KNVYbNDMdLDe"},"source":["##Save feature data cluster-wise\n","This was done to circumvent the memory problem"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1opeOHo5u4m1"},"outputs":[],"source":["cluster_df = valcust_valvendors.groupby([\"cluster\"])[\"CID X LOC_NUM X VENDOR\"].count().reset_index()\n","cluster_df.sort_values(by=\"CID X LOC_NUM X VENDOR\",ascending=False,inplace=True)\n","cluster_ids = cluster_df[\"cluster\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r4RnOS69A-IY"},"outputs":[],"source":["cluster_df.to_csv((\"/content/drive/MyDrive/01_Machine_Learning/05_Datasets/AppliedAI_data/Assignment23_CS1_RestaurantRecommendation/\"+\"cluster_vendcust.csv\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y1a6PubdwfZD"},"outputs":[],"source":["#cluster_ids\n","for c_id in cluster_ids:\n","  globals()[\"train_valcust_valvendors_clus\"+str(int(c_id))] = valcust_valvendors[valcust_valvendors[\"cluster\"] == c_id]\n","  globals()[\"train_valcust_valvendors_clus\"+str(int(c_id))].to_csv(\"/content/drive/MyDrive/01_Machine_Learning/05_Datasets/AppliedAI_data/Assignment23_CS1_RestaurantRecommendation/vendcust/\"+\"train_valcust_valvendors_clus\"+str(int(c_id))+\".csv\")\n","  globals()[\"train_valcust_valvendors_clus\"+str(int(c_id))].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VYpEklJxwpv1"},"outputs":[],"source":["c_id=40\n","valcust_outvendors.to_csv(\"/content/drive/MyDrive/01_Machine_Learning/05_Datasets/AppliedAI_data/Assignment23_CS1_RestaurantRecommendation/vendcust/\"+\"train_valcust_valvendors_clus\"+str(int(c_id))+\".csv\")\n","c_id=41\n","outcust_outvendors.to_csv(\"/content/drive/MyDrive/01_Machine_Learning/05_Datasets/AppliedAI_data/Assignment23_CS1_RestaurantRecommendation/vendcust/\"+\"train_valcust_valvendors_clus\"+str(int(c_id))+\".csv\")\n","c_id=42\n","outcust_valvendors.to_csv(\"/content/drive/MyDrive/01_Machine_Learning/05_Datasets/AppliedAI_data/Assignment23_CS1_RestaurantRecommendation/vendcust/\"+\"train_valcust_valvendors_clus\"+str(int(c_id))+\".csv\")"]},{"cell_type":"markdown","metadata":{"id":"PIRQKi-ydfBw"},"source":["##Cluster-wise modeling"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2852,"status":"ok","timestamp":1655353556440,"user":{"displayName":"Josh L","userId":"09762323287470919868"},"user_tz":-330},"id":"e36rbl5zVRcR","outputId":"ab9ef5bd-11ee-4232-e9d7-a922af82b392"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"ccjob4LyVRZj","executionInfo":{"status":"ok","timestamp":1656764607291,"user_tz":-330,"elapsed":294,"user":{"displayName":"Josh L","userId":"09762323287470919868"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"KVhfbPsjJCmC","executionInfo":{"status":"ok","timestamp":1656764608595,"user_tz":-330,"elapsed":5,"user":{"displayName":"Josh L","userId":"09762323287470919868"}}},"outputs":[],"source":["from sklearn import metrics\n","from scipy.stats import randint as sp_randint\n","from scipy.stats import uniform as sp_uniform\n","from sklearn.model_selection import RandomizedSearchCV\n","from sklearn.metrics import f1_score, recall_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import OneHotEncoder\n","import pickle\n","import ast\n","import lightgbm as lgb\n","import sklearn.externals\n","import joblib"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"0DN5Vvqj72_k","executionInfo":{"status":"ok","timestamp":1656764609962,"user_tz":-330,"elapsed":2,"user":{"displayName":"Josh L","userId":"09762323287470919868"}}},"outputs":[],"source":["cat_features = ['location_type','customer_city', 'customer_country', 'gender', 'verified_x','language_x', 'year_customer_created', \n","                'month_customer_created', 'year_customer_updated', 'month_customer_updated','vendor_category_id', 'delivery_charge', \n","                'serving_distance', 'is_open', 'prepration_time', 'commission', 'discount_percentage', 'status', 'verified_y', 'rank', \n","                'language_y', 'vendor_rating', 'device_type', 'tag_counts','Pasta', 'Shawarma', 'Frozen yoghurt', 'Waffles', 'Mojitos ', \n","                'Kushari', 'Indian', 'Free Delivery', 'Soups', 'Mojitos', 'Vegetarian', 'Mexican', 'Dimsum', 'Smoothies', 'Grills', 'Desserts', \n","                'Fresh Juices', 'Rice','Pastas', 'Pancakes', 'Omani', 'Combos', 'Bagels', 'Kids meal', 'Breakfast', 'Lebanese', 'Spanish Latte', \n","                'Steaks', 'Organic', 'Sushi', 'Milkshakes', 'Pizza', 'American', 'Churros', 'Biryani', 'Family Meal', 'Chinese', 'Seafood', 'Pastry', \n","                'Healthy Food', 'Donuts', 'Mishkak', 'Hot Dogs', 'Cakes', 'Coffee', 'Manakeesh', 'Shuwa', 'Burgers', 'Sandwiches', 'Thai', 'Japanese', 'Karak', \n","                'Kebabs', 'Arabic', 'Cafe', 'Mandazi', 'Salads', 'Hot Chocolate', 'Thali', 'Fatayers', 'Sweets', 'Asian', 'Ice creams', 'Italian', 'Pizzas', \n","                'Rolls', 'Crepes', 'Fries','primary_tags_mod', 'year_vendor_created', 'month_vendor_created', 'year_vendor_updated', 'month_vendor_updated', \n","                'vendor_city', 'vendor_country']"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"5WNdty7e75Mb","executionInfo":{"status":"ok","timestamp":1656764634684,"user_tz":-330,"elapsed":321,"user":{"displayName":"Josh L","userId":"09762323287470919868"}}},"outputs":[],"source":["num_features = ['latitude_x', 'longitude_x','latitude_y', 'longitude_y','open_duration','customer_id_count', 'customer_id_nunique', \n","                'payment_mode_nunique', 'promo_code_count', 'vendor_discount_amount_sum', 'promo_code_discount_percentage_mean', \n","                'item_count_median', 'grand_total_median', 'driver_rating_median', 'deliverydistance_mean', 'preparationtime_mean', \n","                'order_turnaround_min', 'order_turnaround_max', 'order_turnaround_mean','haversine_distance', \n","                'distance_diff', 'distance_ratio', 'latitude_diff','longitude_diff']"]},{"cell_type":"markdown","metadata":{"id":"z3gDDME0dy-h"},"source":["Read the cluster data - file where the cluster ids are ordered by size"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":781,"status":"ok","timestamp":1656764638380,"user":{"displayName":"Josh L","userId":"09762323287470919868"},"user_tz":-330},"id":"aAJi4QSgVJmK","outputId":"ffd858ca-b0e5-48b7-968a-a2690847843f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   cluster  CID X LOC_NUM X VENDOR\n","0        4                  470010\n","1        3                  418147\n","2        6                  391676\n","3       21                  313343\n","4        0                  274175"],"text/html":["\n","  <div id=\"df-6ce41429-a787-4e72-bfab-05ed0de7a3b5\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>cluster</th>\n","      <th>CID X LOC_NUM X VENDOR</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4</td>\n","      <td>470010</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3</td>\n","      <td>418147</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>6</td>\n","      <td>391676</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>21</td>\n","      <td>313343</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>274175</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ce41429-a787-4e72-bfab-05ed0de7a3b5')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6ce41429-a787-4e72-bfab-05ed0de7a3b5 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6ce41429-a787-4e72-bfab-05ed0de7a3b5');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":26}],"source":["cluster_df = pd.read_csv(\"/content/drive/MyDrive/01_Machine_Learning/05_Datasets/AppliedAI_data/Assignment23_CS1_RestaurantRecommendation/\"+\"cluster_vendcust.csv\",index_col=False)\n","cluster_df.drop(columns = [\"Unnamed: 0\"],inplace=True)\n","clusters = cluster_df[\"cluster\"].tolist()\n","cluster_df.head()"]},{"cell_type":"markdown","metadata":{"id":"QbH4bcRidqZw"},"source":["This method builds the lgbm classifier model along with its hyperparameter space"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"pMdNDIy6CUSK","executionInfo":{"status":"ok","timestamp":1656764640391,"user_tz":-330,"elapsed":5,"user":{"displayName":"Josh L","userId":"09762323287470919868"}}},"outputs":[],"source":["def preprocess_lgbmodel(pos,neg):\n","  if pos != 0:\n","    class_weight = round(np.sqrt(neg/pos))\n","  else:\n","    class_weight = 1\n","\n","  #model and its parameters\n","  param ={'n_estimators':[20,50,75,100,150],\n","        'learning_rate':[0.005,0.01,0.05,0.1],\n","        'num_leaves': sp_randint(20,100) \n","        }\n","\n","\n","  clf_dt = lgb.LGBMClassifier(categorical_features=cat_features,\n","      boosting_type='gbdt', objective='binary', scale_pos_weight= class_weight, #is_unbalance=True,\n","      subsample=0.8,feature_fraction=0.9,max_depth=-1,\n","      random_state=7)\n","  \n","  return clf_dt, param"]},{"cell_type":"markdown","metadata":{"id":"4RCUFpkjeKf6"},"source":["This method builds the lgbm classifier model for the best hyperparameters"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"fEop9pvTlNl9","executionInfo":{"status":"ok","timestamp":1656764645195,"user_tz":-330,"elapsed":302,"user":{"displayName":"Josh L","userId":"09762323287470919868"}}},"outputs":[],"source":["def define_best_lgbmodel(chosen_params,pos,neg):\n","\n","  #https://stats.stackexchange.com/questions/243207/what-is-the-proper-usage-of-scale-pos-weight-in-xgboost-for-imbalanced-datasets\n","  if pos != 0:\n","    class_weight = round(np.sqrt(neg/pos))\n","  else:\n","    class_weight = 1\n","\n","\n","  best_clf = lgb.LGBMClassifier(learning_rate=chosen_params[\"learning_rate\"],\n","                                n_estimators=chosen_params[\"n_estimators\"],\n","                                num_leaves=chosen_params[\"num_leaves\"],\n","                                boosting_type='gbdt', objective='binary', \n","                                scale_pos_weight= class_weight,\n","                                subsample=0.8,feature_fraction=0.9,max_depth=-1,random_state=7)\n","  \n","  return best_clf"]},{"cell_type":"markdown","metadata":{"id":"kQyan8b9eQC7"},"source":["This method \n","* reads cluster-wise feature data\n","* does hyperparameter tuning for lgbm models\n","* trains the best model \n","* predicts using the best model\n","* saves the best model for later usage"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"QYvW9RMy28zM","executionInfo":{"status":"ok","timestamp":1656764657382,"user_tz":-330,"elapsed":320,"user":{"displayName":"Josh L","userId":"09762323287470919868"}}},"outputs":[],"source":["def search_hyper_lgbmodel(c_id):\n","  \n","  train_cust_vendorval_clus = pd.read_csv(\"/content/drive/MyDrive/01_Machine_Learning/05_Datasets/AppliedAI_data/Assignment23_CS1_RestaurantRecommendation/vendcust/\"+\"train_valcust_valvendors_clus\"+str(int(c_id))+\".csv\")\n","  train_cust_vendorval_clus.drop(columns = [\"Unnamed: 0\"],inplace=True)\n","  #form X_train and y_train using the cluster data\n","  y_train = train_cust_vendorval_clus[\"target\"].values\n","  X_train = train_cust_vendorval_clus.drop(columns=[\"target\",\"CID X LOC_NUM X VENDOR\",\"cluster\"])\n","\n","  pos = np.count_nonzero(y_train == 1)\n","  neg = np.count_nonzero(y_train == 0)\n","  print(\"cluster:{} ; total_samples:{} ; positives:{} ; negatives:{}\".format(c_id,X_train.shape[0],pos,neg))\n","\n","  #define the model, its hyperparameter space and do required data preprocessing if any\n","  model,param = preprocess_lgbmodel(pos,neg)\n","  \n","  #using RandomizedSearchCV to search for hyperparameters with k-fold cross validation\n","  cv_fold = 7\n","  score = 'f1'\n","  nbr_combos = 8\n","  srch_model = RandomizedSearchCV(model, param ,cv=cv_fold,scoring=score,return_train_score=True,n_iter=nbr_combos,random_state=7,verbose=100)  \n","  clf_model = srch_model.fit(X_train,y_train)  \n","\n","  #retrieve the best hyperparameters\n","  best_params = clf_model.best_params_  #retrieve the best hyperparameters after training\n","  print(\"Best_Hyperparameters: \\n\",best_params)\n","  \n","  return best_params\n","  "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2aOQ0FYPWyVa","outputId":"d2779f53-cbca-473c-d757-29e07358be2c","executionInfo":{"status":"ok","timestamp":1655358569809,"user_tz":-330,"elapsed":1605303,"user":{"displayName":"Josh L","userId":"09762323287470919868"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["cluster:4 ; total_samples:470010 ; positives:5178 ; negatives:464832\n","Fitting 7 folds for each of 8 candidates, totalling 56 fits\n","[CV 1/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 1/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.255, test=0.000) total time=   6.3s\n","[CV 2/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 2/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.267, test=0.109) total time=   5.8s\n","[CV 3/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 3/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.249, test=0.112) total time=   5.8s\n","[CV 4/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 4/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.258, test=0.111) total time=   5.8s\n","[CV 5/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 5/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.258, test=0.120) total time=   6.0s\n","[CV 6/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 6/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.251, test=0.120) total time=   5.9s\n","[CV 7/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 7/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.254, test=0.033) total time=   5.9s\n","[CV 1/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 1/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.164, test=0.000) total time=   5.4s\n","[CV 2/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 2/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.161, test=0.112) total time=   5.6s\n","[CV 3/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 3/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.168, test=0.118) total time=   5.1s\n","[CV 4/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 4/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.156, test=0.124) total time=   4.8s\n","[CV 5/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 5/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.158, test=0.118) total time=   4.9s\n","[CV 6/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 6/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.164, test=0.120) total time=   4.9s\n","[CV 7/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 7/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.155, test=0.029) total time=   5.0s\n","[CV 1/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 1/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.390, test=0.000) total time=   6.4s\n","[CV 2/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 2/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.390, test=0.101) total time=   6.4s\n","[CV 3/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 3/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.369, test=0.115) total time=   6.2s\n","[CV 4/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 4/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.381, test=0.118) total time=   6.2s\n","[CV 5/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 5/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.377, test=0.123) total time=   6.4s\n","[CV 6/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 6/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.389, test=0.107) total time=   6.4s\n","[CV 7/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 7/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.400, test=0.038) total time=   6.4s\n","[CV 1/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 1/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.030, test=0.000) total time=   1.9s\n","[CV 2/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 2/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.002, test=0.038) total time=   2.0s\n","[CV 3/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 3/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.013, test=0.047) total time=   1.9s\n","[CV 4/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 4/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.029, test=0.048) total time=   1.9s\n","[CV 5/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 5/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.009, test=0.008) total time=   1.9s\n","[CV 6/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 6/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.009, test=0.011) total time=   2.0s\n","[CV 7/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 7/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.013, test=0.008) total time=   1.9s\n","[CV 1/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 1/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.028, test=0.000) total time=   1.9s\n","[CV 2/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 2/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.002, test=0.026) total time=   1.9s\n","[CV 3/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 3/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.016, test=0.055) total time=   1.9s\n","[CV 4/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 4/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.017, test=0.024) total time=   1.9s\n","[CV 5/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 5/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.008, test=0.003) total time=   1.9s\n","[CV 6/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 6/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.008, test=0.008) total time=   1.9s\n","[CV 7/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 7/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.004, test=0.005) total time=   1.9s\n","[CV 1/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 1/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.247, test=0.000) total time=   6.9s\n","[CV 2/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 2/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.237, test=0.111) total time=   6.9s\n","[CV 3/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 3/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.248, test=0.121) total time=   6.8s\n","[CV 4/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 4/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.251, test=0.127) total time=   6.6s\n","[CV 5/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 5/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.236, test=0.113) total time=   6.8s\n","[CV 6/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 6/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.238, test=0.124) total time=   6.9s\n","[CV 7/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 7/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.241, test=0.029) total time=   7.0s\n","[CV 1/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 1/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.175, test=0.000) total time=   5.3s\n","[CV 2/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 2/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.173, test=0.108) total time=   5.3s\n","[CV 3/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 3/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.173, test=0.118) total time=   5.3s\n","[CV 4/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 4/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.175, test=0.113) total time=   5.3s\n","[CV 5/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 5/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.169, test=0.115) total time=   5.3s\n","[CV 6/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 6/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.167, test=0.135) total time=   5.3s\n","[CV 7/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 7/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.169, test=0.027) total time=   5.4s\n","[CV 1/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 1/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.157, test=0.000) total time=   3.4s\n","[CV 2/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 2/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.159, test=0.110) total time=   3.4s\n","[CV 3/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 3/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.154, test=0.119) total time=   3.4s\n","[CV 4/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 4/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.157, test=0.111) total time=   3.3s\n","[CV 5/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 5/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.145, test=0.120) total time=   3.5s\n","[CV 6/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 6/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.150, test=0.133) total time=   3.4s\n","[CV 7/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 7/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.153, test=0.028) total time=   3.5s\n","Best_Hyperparameters: \n"," {'learning_rate': 0.05, 'n_estimators': 150, 'num_leaves': 68}\n","cluster:3 ; total_samples:418147 ; positives:8642 ; negatives:409505\n","Fitting 7 folds for each of 8 candidates, totalling 56 fits\n","[CV 1/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 1/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.292, test=0.002) total time=   5.3s\n","[CV 2/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 2/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.286, test=0.219) total time=   5.3s\n","[CV 3/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 3/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.291, test=0.209) total time=   5.2s\n","[CV 4/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 4/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.296, test=0.189) total time=   5.0s\n","[CV 5/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 5/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.285, test=0.240) total time=   5.2s\n","[CV 6/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 6/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.292, test=0.191) total time=   5.0s\n","[CV 7/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 7/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.292, test=0.108) total time=   5.0s\n","[CV 1/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 1/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.255, test=0.002) total time=   4.4s\n","[CV 2/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 2/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.249, test=0.253) total time=   6.3s\n","[CV 3/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 3/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.255, test=0.233) total time=   4.3s\n","[CV 4/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 4/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.256, test=0.233) total time=   4.2s\n","[CV 5/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 5/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.250, test=0.248) total time=   4.3s\n","[CV 6/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 6/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.256, test=0.210) total time=   4.2s\n","[CV 7/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 7/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.253, test=0.175) total time=   4.2s\n","[CV 1/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 1/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.338, test=0.000) total time=   5.6s\n","[CV 2/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 2/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.346, test=0.214) total time=   5.6s\n","[CV 3/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 3/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.344, test=0.203) total time=   5.4s\n","[CV 4/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 4/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.350, test=0.169) total time=   5.5s\n","[CV 5/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 5/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.349, test=0.229) total time=   5.6s\n","[CV 6/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 6/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.345, test=0.179) total time=   5.4s\n","[CV 7/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 7/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.347, test=0.110) total time=   5.2s\n","[CV 1/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 1/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.082, test=0.071) total time=   1.7s\n","[CV 2/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 2/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.103, test=0.115) total time=   1.7s\n","[CV 3/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 3/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.083, test=0.076) total time=   1.8s\n","[CV 4/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 4/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.102, test=0.097) total time=   1.7s\n","[CV 5/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 5/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.101, test=0.108) total time=   1.7s\n","[CV 6/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 6/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.082, test=0.078) total time=   1.7s\n","[CV 7/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 7/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.094, test=0.078) total time=   1.7s\n","[CV 1/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 1/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.082, test=0.071) total time=   1.7s\n","[CV 2/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 2/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.104, test=0.112) total time=   1.7s\n","[CV 3/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 3/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.083, test=0.076) total time=   1.7s\n","[CV 4/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 4/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.097, test=0.091) total time=   1.7s\n","[CV 5/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 5/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.101, test=0.107) total time=   1.7s\n","[CV 6/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 6/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.082, test=0.078) total time=   1.7s\n","[CV 7/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 7/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.105, test=0.090) total time=   1.7s\n","[CV 1/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 1/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.281, test=0.003) total time=   6.2s\n","[CV 2/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 2/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.276, test=0.241) total time=   6.3s\n","[CV 3/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 3/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.281, test=0.236) total time=   5.8s\n","[CV 4/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 4/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.283, test=0.209) total time=   5.9s\n","[CV 5/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 5/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.277, test=0.240) total time=   6.0s\n","[CV 6/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 6/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.281, test=0.201) total time=   5.8s\n","[CV 7/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 7/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.282, test=0.099) total time=   5.8s\n","[CV 1/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 1/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.257, test=0.002) total time=   4.9s\n","[CV 2/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 2/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.252, test=0.233) total time=   4.9s\n","[CV 3/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 3/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.260, test=0.216) total time=   4.8s\n","[CV 4/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 4/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.261, test=0.217) total time=   4.7s\n","[CV 5/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 5/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.253, test=0.245) total time=   4.8s\n","[CV 6/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 6/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.259, test=0.181) total time=   4.7s\n","[CV 7/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 7/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.258, test=0.107) total time=   4.8s\n","[CV 1/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 1/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.250, test=0.002) total time=   3.1s\n","[CV 2/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 2/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.241, test=0.244) total time=   3.2s\n","[CV 3/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 3/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.244, test=0.222) total time=   3.1s\n","[CV 4/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 4/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.251, test=0.230) total time=   3.1s\n","[CV 5/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 5/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.248, test=0.240) total time=   3.1s\n","[CV 6/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 6/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.248, test=0.203) total time=   3.1s\n","[CV 7/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 7/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.251, test=0.151) total time=   3.1s\n","Best_Hyperparameters: \n"," {'learning_rate': 0.05, 'n_estimators': 100, 'num_leaves': 43}\n","cluster:6 ; total_samples:391676 ; positives:4864 ; negatives:386812\n","Fitting 7 folds for each of 8 candidates, totalling 56 fits\n","[CV 1/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 1/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.331, test=0.000) total time=   4.8s\n","[CV 2/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 2/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.338, test=0.176) total time=   4.9s\n","[CV 3/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 3/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.338, test=0.188) total time=   4.8s\n","[CV 4/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 4/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.337, test=0.162) total time=   4.8s\n","[CV 5/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 5/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.332, test=0.189) total time=   4.8s\n","[CV 6/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 6/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.354, test=0.177) total time=   4.8s\n","[CV 7/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 7/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.324, test=0.042) total time=   4.7s\n","[CV 1/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 1/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.251, test=0.000) total time=   4.0s\n","[CV 2/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 2/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.246, test=0.196) total time=   4.1s\n","[CV 3/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 3/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.241, test=0.209) total time=   3.9s\n","[CV 4/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 4/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.242, test=0.182) total time=   4.0s\n","[CV 5/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 5/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.245, test=0.195) total time=   4.0s\n","[CV 6/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 6/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.248, test=0.202) total time=   4.0s\n","[CV 7/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 7/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.244, test=0.059) total time=   4.1s\n","[CV 1/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 1/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.453, test=0.000) total time=   5.2s\n","[CV 2/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 2/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.461, test=0.178) total time=   7.1s\n","[CV 3/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 3/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.468, test=0.169) total time=   5.2s\n","[CV 4/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 4/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.455, test=0.163) total time=   5.2s\n","[CV 5/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 5/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.451, test=0.182) total time=   5.1s\n","[CV 6/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 6/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.460, test=0.184) total time=   5.2s\n","[CV 7/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 7/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.453, test=0.019) total time=   5.1s\n","[CV 1/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 1/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.140, test=0.000) total time=   1.5s\n","[CV 2/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 2/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.152, test=0.154) total time=   1.5s\n","[CV 3/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 3/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.119, test=0.093) total time=   1.5s\n","[CV 4/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 4/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.132, test=0.129) total time=   1.5s\n","[CV 5/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 5/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.142, test=0.113) total time=   1.5s\n","[CV 6/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 6/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.138, test=0.156) total time=   1.5s\n","[CV 7/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 7/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.159, test=0.020) total time=   1.5s\n","[CV 1/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 1/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.156, test=0.000) total time=   1.5s\n","[CV 2/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 2/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.152, test=0.151) total time=   1.5s\n","[CV 3/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 3/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.119, test=0.097) total time=   1.6s\n","[CV 4/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 4/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.134, test=0.153) total time=   1.5s\n","[CV 5/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 5/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.142, test=0.113) total time=   1.5s\n","[CV 6/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 6/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.134, test=0.149) total time=   1.5s\n","[CV 7/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 7/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.160, test=0.017) total time=   1.5s\n","[CV 1/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 1/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.321, test=0.000) total time=   5.4s\n","[CV 2/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 2/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.328, test=0.187) total time=   5.6s\n","[CV 3/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 3/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.322, test=0.196) total time=   5.6s\n","[CV 4/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 4/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.317, test=0.176) total time=   5.5s\n","[CV 5/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 5/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.319, test=0.193) total time=   5.5s\n","[CV 6/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 6/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.335, test=0.191) total time=   5.5s\n","[CV 7/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 7/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.325, test=0.041) total time=   5.5s\n","[CV 1/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 1/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.257, test=0.000) total time=   4.5s\n","[CV 2/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 2/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.258, test=0.191) total time=   4.5s\n","[CV 3/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 3/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.265, test=0.189) total time=   4.5s\n","[CV 4/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 4/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.264, test=0.159) total time=   4.5s\n","[CV 5/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 5/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.255, test=0.189) total time=   4.4s\n","[CV 6/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 6/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.257, test=0.183) total time=   4.3s\n","[CV 7/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 7/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.258, test=0.059) total time=   4.5s\n","[CV 1/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 1/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.226, test=0.000) total time=   2.8s\n","[CV 2/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 2/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.230, test=0.199) total time=   3.0s\n","[CV 3/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 3/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.232, test=0.187) total time=   3.0s\n","[CV 4/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 4/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.237, test=0.167) total time=   2.9s\n","[CV 5/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 5/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.234, test=0.190) total time=   2.8s\n","[CV 6/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 6/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.232, test=0.189) total time=   2.9s\n","[CV 7/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 7/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.229, test=0.079) total time=   2.9s\n","Best_Hyperparameters: \n"," {'learning_rate': 0.05, 'n_estimators': 100, 'num_leaves': 43}\n","cluster:21 ; total_samples:313343 ; positives:5355 ; negatives:307988\n","Fitting 7 folds for each of 8 candidates, totalling 56 fits\n","[CV 1/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 1/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.366, test=0.125) total time=   4.2s\n","[CV 2/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 2/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.366, test=0.117) total time=   4.3s\n","[CV 3/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 3/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.362, test=0.134) total time=   4.1s\n","[CV 4/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 4/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.364, test=0.127) total time=   4.0s\n","[CV 5/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 5/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.373, test=0.141) total time=   4.2s\n","[CV 6/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 6/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.364, test=0.135) total time=   4.0s\n","[CV 7/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 7/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.372, test=0.000) total time=   4.1s\n","[CV 1/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 1/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.205, test=0.144) total time=   3.4s\n","[CV 2/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 2/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.201, test=0.108) total time=   3.5s\n","[CV 3/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 3/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.200, test=0.117) total time=   4.5s\n","[CV 4/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 4/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.193, test=0.100) total time=   3.5s\n","[CV 5/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 5/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.200, test=0.133) total time=   3.5s\n","[CV 6/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 6/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.193, test=0.130) total time=   3.5s\n","[CV 7/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 7/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.196, test=0.000) total time=   3.5s\n","[CV 1/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 1/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.520, test=0.132) total time=   4.5s\n","[CV 2/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 2/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.518, test=0.108) total time=   4.6s\n","[CV 3/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 3/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.526, test=0.139) total time=   4.5s\n","[CV 4/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 4/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.513, test=0.131) total time=   4.5s\n","[CV 5/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 5/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.516, test=0.135) total time=   4.6s\n","[CV 6/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 6/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.523, test=0.140) total time=   4.5s\n","[CV 7/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 7/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.520, test=0.000) total time=   4.5s\n","[CV 1/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 1/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.000, test=0.014) total time=   1.4s\n","[CV 2/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 2/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.000, test=0.000) total time=   1.3s\n","[CV 3/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 3/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.000, test=0.000) total time=   1.4s\n","[CV 4/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 4/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.002, test=0.000) total time=   1.3s\n","[CV 5/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 5/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.001, test=0.000) total time=   1.3s\n","[CV 6/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 6/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.000, test=0.000) total time=   1.3s\n","[CV 7/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 7/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.000, test=0.000) total time=   1.4s\n","[CV 1/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 1/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.000, test=0.017) total time=   1.3s\n","[CV 2/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 2/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.000, test=0.000) total time=   1.4s\n","[CV 3/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 3/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.000, test=0.000) total time=   1.3s\n","[CV 4/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 4/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.001, test=0.000) total time=   1.4s\n","[CV 5/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 5/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.001, test=0.000) total time=   1.3s\n","[CV 6/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 6/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.000, test=0.000) total time=   1.4s\n","[CV 7/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 7/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.000, test=0.000) total time=   1.4s\n","[CV 1/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 1/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.349, test=0.133) total time=   4.8s\n","[CV 2/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 2/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.343, test=0.101) total time=   5.0s\n","[CV 3/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 3/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.364, test=0.136) total time=   6.8s\n","[CV 4/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 4/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.336, test=0.117) total time=   4.9s\n","[CV 5/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 5/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.349, test=0.133) total time=   4.9s\n","[CV 6/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 6/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.345, test=0.131) total time=   4.7s\n","[CV 7/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 7/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.330, test=0.000) total time=   4.8s\n","[CV 1/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 1/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.193, test=0.132) total time=   3.8s\n","[CV 2/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 2/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.207, test=0.121) total time=   3.8s\n","[CV 3/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 3/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.180, test=0.110) total time=   3.8s\n","[CV 4/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 4/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.206, test=0.126) total time=   3.8s\n","[CV 5/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 5/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.211, test=0.139) total time=   3.9s\n","[CV 6/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 6/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.212, test=0.136) total time=   3.7s\n","[CV 7/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 7/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.213, test=0.000) total time=   3.7s\n","[CV 1/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 1/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.192, test=0.142) total time=   2.5s\n","[CV 2/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 2/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.190, test=0.129) total time=   2.5s\n","[CV 3/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 3/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.172, test=0.109) total time=   2.4s\n","[CV 4/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 4/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.179, test=0.126) total time=   2.5s\n","[CV 5/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 5/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.182, test=0.144) total time=   2.5s\n","[CV 6/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 6/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.190, test=0.137) total time=   2.4s\n","[CV 7/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 7/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.177, test=0.000) total time=   2.4s\n","Best_Hyperparameters: \n"," {'learning_rate': 0.1, 'n_estimators': 75, 'num_leaves': 26}\n","cluster:0 ; total_samples:274175 ; positives:4768 ; negatives:269407\n","Fitting 7 folds for each of 8 candidates, totalling 56 fits\n","[CV 1/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 1/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.457, test=0.303) total time=   3.1s\n","[CV 2/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 2/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.481, test=0.305) total time=   3.1s\n","[CV 3/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 3/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.468, test=0.292) total time=   3.1s\n","[CV 4/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 4/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.474, test=0.260) total time=   3.0s\n","[CV 5/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 5/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.479, test=0.297) total time=   3.1s\n","[CV 6/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 6/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.473, test=0.323) total time=   3.1s\n","[CV 7/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 7/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.467, test=0.291) total time=   3.0s\n","[CV 1/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 1/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.392, test=0.289) total time=   2.5s\n","[CV 2/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 2/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.384, test=0.304) total time=   2.6s\n","[CV 3/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 3/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.385, test=0.306) total time=   2.5s\n","[CV 4/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 4/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.384, test=0.282) total time=   2.5s\n","[CV 5/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 5/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.379, test=0.311) total time=   2.5s\n","[CV 6/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 6/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.381, test=0.333) total time=   2.5s\n","[CV 7/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 7/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.386, test=0.324) total time=   2.6s\n","[CV 1/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 1/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.567, test=0.306) total time=   3.4s\n","[CV 2/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 2/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.585, test=0.301) total time=   3.1s\n","[CV 3/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 3/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.544, test=0.290) total time=   3.4s\n","[CV 4/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 4/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.582, test=0.262) total time=   3.3s\n","[CV 5/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 5/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.576, test=0.288) total time=   3.2s\n","[CV 6/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 6/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.575, test=0.308) total time=   3.3s\n","[CV 7/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 7/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.555, test=0.230) total time=   3.3s\n","[CV 1/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 1/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.310, test=0.278) total time=   1.0s\n","[CV 2/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 2/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.314, test=0.301) total time=   1.1s\n","[CV 3/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 3/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.301, test=0.251) total time=   1.1s\n","[CV 4/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 4/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.296, test=0.266) total time=   1.1s\n","[CV 5/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 5/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.305, test=0.273) total time=   1.0s\n","[CV 6/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 6/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.306, test=0.279) total time=   1.1s\n","[CV 7/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 7/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.305, test=0.277) total time=   1.2s\n","[CV 1/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 1/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.290, test=0.293) total time=   1.1s\n","[CV 2/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 2/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.302, test=0.314) total time=   1.0s\n","[CV 3/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 3/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.307, test=0.253) total time=   1.1s\n","[CV 4/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 4/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.292, test=0.270) total time=   1.1s\n","[CV 5/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 5/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.297, test=0.257) total time=   1.1s\n","[CV 6/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 6/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.285, test=0.255) total time=   1.1s\n","[CV 7/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 7/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.289, test=0.283) total time=   1.1s\n","[CV 1/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 1/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.470, test=0.306) total time=   3.5s\n","[CV 2/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 2/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.469, test=0.312) total time=   3.4s\n","[CV 3/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 3/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.465, test=0.300) total time=   3.6s\n","[CV 4/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 4/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.463, test=0.268) total time=   3.6s\n","[CV 5/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 5/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.466, test=0.311) total time=   3.6s\n","[CV 6/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 6/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.473, test=0.320) total time=   3.6s\n","[CV 7/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 7/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.467, test=0.293) total time=   3.6s\n","[CV 1/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 1/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.384, test=0.289) total time=   2.8s\n","[CV 2/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 2/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.367, test=0.286) total time=   2.8s\n","[CV 3/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 3/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.366, test=0.278) total time=   2.8s\n","[CV 4/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 4/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.381, test=0.255) total time=   2.8s\n","[CV 5/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 5/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.370, test=0.299) total time=   2.8s\n","[CV 6/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 6/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.364, test=0.325) total time=   2.8s\n","[CV 7/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 7/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.362, test=0.273) total time=   3.0s\n","[CV 1/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 1/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.347, test=0.285) total time=   1.9s\n","[CV 2/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 2/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.363, test=0.288) total time=   1.9s\n","[CV 3/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 3/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.339, test=0.294) total time=   1.8s\n","[CV 4/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 4/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.342, test=0.266) total time=   1.9s\n","[CV 5/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 5/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.360, test=0.299) total time=   1.9s\n","[CV 6/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 6/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.351, test=0.320) total time=   1.8s\n","[CV 7/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 7/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.349, test=0.310) total time=   1.9s\n","Best_Hyperparameters: \n"," {'learning_rate': 0.05, 'n_estimators': 100, 'num_leaves': 43}\n","cluster:20 ; total_samples:272522 ; positives:6808 ; negatives:265714\n","Fitting 7 folds for each of 8 candidates, totalling 56 fits\n","[CV 1/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 1/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.399, test=0.235) total time=   3.4s\n","[CV 2/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 2/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.387, test=0.216) total time=   3.6s\n","[CV 3/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 3/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.403, test=0.274) total time=   3.5s\n","[CV 4/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 4/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.396, test=0.275) total time=   3.4s\n","[CV 5/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 5/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.402, test=0.275) total time=   3.3s\n","[CV 6/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 6/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.400, test=0.254) total time=   3.4s\n","[CV 7/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 7/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.387, test=0.257) total time=   3.6s\n","[CV 1/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 1/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.324, test=0.235) total time=   2.9s\n","[CV 2/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 2/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.328, test=0.256) total time=   2.9s\n","[CV 3/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 3/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.323, test=0.275) total time=   2.9s\n","[CV 4/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 4/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.327, test=0.280) total time=   2.8s\n","[CV 5/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 5/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.321, test=0.302) total time=   2.9s\n","[CV 6/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 6/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.328, test=0.270) total time=   2.8s\n","[CV 7/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 7/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.326, test=0.278) total time=   2.8s\n","[CV 1/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 1/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.514, test=0.230) total time=   3.7s\n","[CV 2/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 2/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.499, test=0.182) total time=   3.8s\n","[CV 3/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 3/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.503, test=0.267) total time=   3.7s\n","[CV 4/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 4/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.489, test=0.270) total time=   5.5s\n","[CV 5/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 5/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.505, test=0.274) total time=   3.7s\n","[CV 6/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 6/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.483, test=0.247) total time=   3.9s\n","[CV 7/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 7/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.478, test=0.266) total time=   3.8s\n","[CV 1/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 1/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.196, test=0.218) total time=   1.2s\n","[CV 2/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 2/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.211, test=0.177) total time=   1.2s\n","[CV 3/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 3/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.187, test=0.191) total time=   1.2s\n","[CV 4/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 4/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.184, test=0.196) total time=   1.2s\n","[CV 5/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 5/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.163, test=0.143) total time=   1.2s\n","[CV 6/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 6/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.176, test=0.169) total time=   1.2s\n","[CV 7/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 7/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.202, test=0.211) total time=   1.2s\n","[CV 1/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 1/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.206, test=0.225) total time=   1.2s\n","[CV 2/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 2/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.209, test=0.175) total time=   1.1s\n","[CV 3/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 3/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.187, test=0.191) total time=   1.2s\n","[CV 4/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 4/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.170, test=0.189) total time=   1.1s\n","[CV 5/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 5/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.164, test=0.141) total time=   1.2s\n","[CV 6/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 6/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.186, test=0.170) total time=   1.2s\n","[CV 7/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 7/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.202, test=0.210) total time=   1.2s\n","[CV 1/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 1/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.397, test=0.226) total time=   4.0s\n","[CV 2/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 2/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.385, test=0.246) total time=   4.0s\n","[CV 3/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 3/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.391, test=0.265) total time=   3.9s\n","[CV 4/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 4/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.384, test=0.272) total time=   4.0s\n","[CV 5/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 5/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.386, test=0.296) total time=   4.0s\n","[CV 6/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 6/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.386, test=0.271) total time=   3.9s\n","[CV 7/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 7/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.379, test=0.280) total time=   4.0s\n","[CV 1/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 1/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.327, test=0.230) total time=   3.1s\n","[CV 2/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 2/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.324, test=0.264) total time=   3.1s\n","[CV 3/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 3/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.322, test=0.274) total time=   3.0s\n","[CV 4/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 4/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.318, test=0.273) total time=   3.2s\n","[CV 5/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 5/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.329, test=0.297) total time=   3.1s\n","[CV 6/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 6/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.309, test=0.276) total time=   3.2s\n","[CV 7/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 7/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.303, test=0.279) total time=   3.2s\n","[CV 1/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 1/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.311, test=0.238) total time=   2.0s\n","[CV 2/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 2/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.313, test=0.265) total time=   2.1s\n","[CV 3/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 3/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.310, test=0.277) total time=   2.0s\n","[CV 4/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 4/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.306, test=0.270) total time=   2.1s\n","[CV 5/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 5/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.313, test=0.295) total time=   2.1s\n","[CV 6/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 6/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.304, test=0.265) total time=   2.1s\n","[CV 7/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 7/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.303, test=0.283) total time=   2.1s\n","Best_Hyperparameters: \n"," {'learning_rate': 0.05, 'n_estimators': 100, 'num_leaves': 43}\n","cluster:32 ; total_samples:209082 ; positives:2511 ; negatives:206571\n","Fitting 7 folds for each of 8 candidates, totalling 56 fits\n","[CV 1/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 1/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.329, test=0.000) total time=   2.8s\n","[CV 2/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 2/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.352, test=0.102) total time=   2.7s\n","[CV 3/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 3/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.350, test=0.104) total time=   2.6s\n","[CV 4/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 4/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.340, test=0.062) total time=   2.7s\n","[CV 5/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 5/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.330, test=0.111) total time=   2.7s\n","[CV 6/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 6/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.338, test=0.118) total time=   2.7s\n","[CV 7/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 7/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.344, test=0.111) total time=   2.7s\n","[CV 1/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 1/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.185, test=0.000) total time=   2.2s\n","[CV 2/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 2/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.169, test=0.160) total time=   2.0s\n","[CV 3/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 3/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.187, test=0.104) total time=   2.2s\n","[CV 4/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 4/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.187, test=0.121) total time=   2.5s\n","[CV 5/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 5/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.186, test=0.150) total time=   3.9s\n","[CV 6/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 6/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.181, test=0.155) total time=   4.2s\n","[CV 7/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 7/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.178, test=0.132) total time=   2.2s\n","[CV 1/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 1/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.538, test=0.000) total time=   3.0s\n","[CV 2/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 2/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.537, test=0.099) total time=   2.9s\n","[CV 3/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 3/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.568, test=0.094) total time=   3.1s\n","[CV 4/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 4/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.541, test=0.066) total time=   2.9s\n","[CV 5/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 5/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.567, test=0.108) total time=   2.9s\n","[CV 6/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 6/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.545, test=0.079) total time=   2.9s\n","[CV 7/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 7/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.550, test=0.070) total time=   3.1s\n","[CV 1/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 1/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.129, test=0.000) total time=   1.0s\n","[CV 2/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 2/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.117, test=0.126) total time=   1.0s\n","[CV 3/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 3/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.125, test=0.102) total time=   1.0s\n","[CV 4/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 4/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.122, test=0.119) total time=   1.0s\n","[CV 5/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 5/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.129, test=0.135) total time=   1.0s\n","[CV 6/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 6/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.129, test=0.126) total time=   1.0s\n","[CV 7/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 7/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.121, test=0.108) total time=   1.0s\n","[CV 1/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 1/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.125, test=0.000) total time=   1.0s\n","[CV 2/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 2/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.117, test=0.126) total time=   1.0s\n","[CV 3/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 3/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.126, test=0.103) total time=   1.0s\n","[CV 4/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 4/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.120, test=0.121) total time=   1.0s\n","[CV 5/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 5/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.130, test=0.134) total time=   1.0s\n","[CV 6/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 6/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.130, test=0.126) total time=   1.0s\n","[CV 7/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 7/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.119, test=0.103) total time=   1.0s\n","[CV 1/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 1/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.295, test=0.000) total time=   3.0s\n","[CV 2/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 2/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.287, test=0.123) total time=   3.1s\n","[CV 3/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 3/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.289, test=0.113) total time=   3.0s\n","[CV 4/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 4/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.301, test=0.087) total time=   3.0s\n","[CV 5/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 5/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.286, test=0.140) total time=   3.0s\n","[CV 6/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 6/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.281, test=0.152) total time=   3.1s\n","[CV 7/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 7/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.304, test=0.122) total time=   3.1s\n","[CV 1/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 1/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.199, test=0.000) total time=   2.4s\n","[CV 2/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 2/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.192, test=0.134) total time=   2.4s\n","[CV 3/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 3/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.211, test=0.099) total time=   2.5s\n","[CV 4/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 4/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.211, test=0.065) total time=   2.4s\n","[CV 5/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 5/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.196, test=0.110) total time=   2.4s\n","[CV 6/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 6/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.198, test=0.150) total time=   2.4s\n","[CV 7/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 7/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.203, test=0.121) total time=   2.4s\n","[CV 1/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 1/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.182, test=0.000) total time=   1.6s\n","[CV 2/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 2/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.175, test=0.115) total time=   1.5s\n","[CV 3/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 3/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.177, test=0.094) total time=   1.5s\n","[CV 4/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 4/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.173, test=0.080) total time=   1.5s\n","[CV 5/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 5/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.179, test=0.151) total time=   1.6s\n","[CV 6/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 6/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.179, test=0.122) total time=   1.6s\n","[CV 7/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 7/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.184, test=0.111) total time=   1.6s\n","Best_Hyperparameters: \n"," {'learning_rate': 0.05, 'n_estimators': 100, 'num_leaves': 43}\n","cluster:24 ; total_samples:195841 ; positives:4080 ; negatives:191761\n","Fitting 7 folds for each of 8 candidates, totalling 56 fits\n","[CV 1/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 1/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.512, test=0.332) total time=   2.7s\n","[CV 2/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 2/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.501, test=0.344) total time=   2.8s\n","[CV 3/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 3/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.507, test=0.322) total time=   2.8s\n","[CV 4/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 4/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.492, test=0.339) total time=   2.7s\n","[CV 5/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 5/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.506, test=0.320) total time=   2.9s\n","[CV 6/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 6/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.506, test=0.328) total time=   2.7s\n","[CV 7/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 7/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.505, test=0.007) total time=   2.7s\n","[CV 1/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 1/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.389, test=0.339) total time=   2.3s\n","[CV 2/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 2/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.388, test=0.353) total time=   2.4s\n","[CV 3/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 3/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.395, test=0.333) total time=   2.3s\n","[CV 4/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 4/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.395, test=0.340) total time=   2.2s\n","[CV 5/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 5/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.392, test=0.329) total time=   2.3s\n","[CV 6/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 6/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.383, test=0.336) total time=   2.3s\n","[CV 7/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 7/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.398, test=0.017) total time=   2.3s\n","[CV 1/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 1/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.611, test=0.330) total time=   3.1s\n","[CV 2/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 2/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.631, test=0.342) total time=   3.1s\n","[CV 3/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 3/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.613, test=0.320) total time=   5.5s\n","[CV 4/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 4/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.621, test=0.334) total time=   3.1s\n","[CV 5/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 5/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.617, test=0.312) total time=   3.2s\n","[CV 6/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 6/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.631, test=0.332) total time=   3.1s\n","[CV 7/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 7/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.612, test=0.010) total time=   2.9s\n","[CV 1/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 1/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.339, test=0.312) total time=   0.9s\n","[CV 2/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 2/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.287, test=0.273) total time=   1.0s\n","[CV 3/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 3/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.324, test=0.293) total time=   1.0s\n","[CV 4/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 4/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.331, test=0.336) total time=   0.9s\n","[CV 5/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 5/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.307, test=0.313) total time=   1.0s\n","[CV 6/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 6/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.328, test=0.292) total time=   1.0s\n","[CV 7/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 7/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.336, test=0.010) total time=   1.0s\n","[CV 1/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 1/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.336, test=0.320) total time=   0.9s\n","[CV 2/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 2/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.288, test=0.286) total time=   1.0s\n","[CV 3/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 3/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.326, test=0.296) total time=   0.9s\n","[CV 4/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 4/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.335, test=0.335) total time=   0.9s\n","[CV 5/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 5/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.325, test=0.328) total time=   0.9s\n","[CV 6/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 6/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.326, test=0.291) total time=   0.9s\n","[CV 7/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 7/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.326, test=0.010) total time=   1.0s\n","[CV 1/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 1/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.487, test=0.345) total time=   3.2s\n","[CV 2/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 2/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.483, test=0.360) total time=   3.2s\n","[CV 3/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 3/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.478, test=0.328) total time=   3.2s\n","[CV 4/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 4/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.483, test=0.348) total time=   3.2s\n","[CV 5/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 5/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.485, test=0.329) total time=   3.3s\n","[CV 6/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 6/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.479, test=0.342) total time=   3.2s\n","[CV 7/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 7/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.482, test=0.014) total time=   3.3s\n","[CV 1/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 1/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.414, test=0.335) total time=   2.5s\n","[CV 2/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 2/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.397, test=0.358) total time=   2.5s\n","[CV 3/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 3/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.400, test=0.326) total time=   2.6s\n","[CV 4/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 4/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.401, test=0.346) total time=   2.5s\n","[CV 5/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 5/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.407, test=0.332) total time=   2.6s\n","[CV 6/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 6/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.406, test=0.344) total time=   2.6s\n","[CV 7/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 7/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.404, test=0.007) total time=   2.4s\n","[CV 1/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 1/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.375, test=0.342) total time=   1.6s\n","[CV 2/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 2/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.370, test=0.356) total time=   1.7s\n","[CV 3/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 3/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.376, test=0.319) total time=   1.7s\n","[CV 4/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 4/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.379, test=0.343) total time=   1.7s\n","[CV 5/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 5/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.378, test=0.332) total time=   1.7s\n","[CV 6/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 6/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.373, test=0.335) total time=   1.7s\n","[CV 7/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 7/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.378, test=0.014) total time=   1.7s\n","Best_Hyperparameters: \n"," {'learning_rate': 0.05, 'n_estimators': 150, 'num_leaves': 68}\n","cluster:8 ; total_samples:195840 ; positives:2855 ; negatives:192985\n","Fitting 7 folds for each of 8 candidates, totalling 56 fits\n","[CV 1/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 1/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.451, test=0.046) total time=   2.4s\n","[CV 2/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 2/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.483, test=0.016) total time=   2.3s\n","[CV 3/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 3/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.487, test=0.079) total time=   2.4s\n","[CV 4/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 4/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.503, test=0.073) total time=   2.3s\n","[CV 5/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 5/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.483, test=0.095) total time=   2.4s\n","[CV 6/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 6/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.455, test=0.094) total time=   2.3s\n","[CV 7/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 7/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.462, test=0.087) total time=   2.4s\n","[CV 1/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 1/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.149, test=0.046) total time=   1.9s\n","[CV 2/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 2/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.150, test=0.014) total time=   2.0s\n","[CV 3/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 3/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.164, test=0.100) total time=   2.0s\n","[CV 4/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 4/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.164, test=0.091) total time=   2.0s\n","[CV 5/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 5/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.152, test=0.101) total time=   1.9s\n","[CV 6/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 6/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.159, test=0.076) total time=   2.0s\n","[CV 7/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 7/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.146, test=0.093) total time=   2.0s\n","[CV 1/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 1/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.675, test=0.053) total time=   2.5s\n","[CV 2/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 2/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.686, test=0.047) total time=   2.8s\n","[CV 3/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 3/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.687, test=0.082) total time=   2.7s\n","[CV 4/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 4/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.709, test=0.069) total time=   2.6s\n","[CV 5/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 5/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.671, test=0.098) total time=   2.7s\n","[CV 6/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 6/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.681, test=0.092) total time=   2.6s\n","[CV 7/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 7/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.675, test=0.083) total time=   2.6s\n","[CV 1/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 1/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.006, test=0.000) total time=   0.9s\n","[CV 2/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 2/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.014, test=0.000) total time=   0.9s\n","[CV 3/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 3/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.018, test=0.017) total time=   0.9s\n","[CV 4/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 4/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.018, test=0.017) total time=   0.9s\n","[CV 5/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 5/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.021, test=0.009) total time=   0.9s\n","[CV 6/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 6/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.014, test=0.010) total time=   0.9s\n","[CV 7/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 7/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.026, test=0.081) total time=   0.9s\n","[CV 1/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 1/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.009, test=0.000) total time=   0.9s\n","[CV 2/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 2/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.014, test=0.000) total time=   0.9s\n","[CV 3/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 3/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.016, test=0.009) total time=   0.9s\n","[CV 4/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 4/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.020, test=0.034) total time=   0.8s\n","[CV 5/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 5/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.016, test=0.009) total time=   0.9s\n","[CV 6/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 6/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.015, test=0.005) total time=   0.9s\n","[CV 7/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 7/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.025, test=0.074) total time=   0.9s\n","[CV 1/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 1/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.388, test=0.059) total time=   2.8s\n","[CV 2/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 2/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.422, test=0.017) total time=   2.7s\n","[CV 3/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 3/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.418, test=0.091) total time=   2.6s\n","[CV 4/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 4/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.415, test=0.077) total time=   2.8s\n","[CV 5/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 5/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.397, test=0.106) total time=   2.8s\n","[CV 6/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 6/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.410, test=0.084) total time=   2.7s\n","[CV 7/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 7/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.383, test=0.090) total time=   2.8s\n","[CV 1/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 1/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.199, test=0.041) total time=   2.2s\n","[CV 2/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 2/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.191, test=0.025) total time=   2.2s\n","[CV 3/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 3/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.205, test=0.089) total time=   2.1s\n","[CV 4/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 4/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.227, test=0.073) total time=   2.2s\n","[CV 5/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 5/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.205, test=0.102) total time=   2.2s\n","[CV 6/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 6/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.220, test=0.106) total time=   2.1s\n","[CV 7/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 7/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.200, test=0.094) total time=   2.1s\n","[CV 1/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 1/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.154, test=0.044) total time=   1.4s\n","[CV 2/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 2/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.141, test=0.022) total time=   1.4s\n","[CV 3/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 3/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.140, test=0.089) total time=   1.4s\n","[CV 4/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 4/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.152, test=0.075) total time=   1.4s\n","[CV 5/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 5/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.145, test=0.106) total time=   1.4s\n","[CV 6/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 6/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.135, test=0.066) total time=   1.5s\n","[CV 7/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 7/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.147, test=0.088) total time=   1.5s\n","Best_Hyperparameters: \n"," {'learning_rate': 0.1, 'n_estimators': 150, 'num_leaves': 20}\n","cluster:12 ; total_samples:190069 ; positives:1254 ; negatives:188815\n","Fitting 7 folds for each of 8 candidates, totalling 56 fits\n","[CV 1/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 1/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.468, test=0.056) total time=   2.7s\n","[CV 2/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 2/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.544, test=0.043) total time=   2.8s\n","[CV 3/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 3/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.507, test=0.077) total time=   2.6s\n","[CV 4/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 4/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.478, test=0.070) total time=   2.8s\n","[CV 5/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 5/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.529, test=0.088) total time=   2.6s\n","[CV 6/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 6/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.513, test=0.077) total time=   2.8s\n","[CV 7/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 7/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.502, test=0.046) total time=   2.7s\n","[CV 1/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 1/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.220, test=0.049) total time=   2.1s\n","[CV 2/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 2/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.257, test=0.000) total time=   2.0s\n","[CV 3/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 3/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.220, test=0.065) total time=   2.0s\n","[CV 4/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 4/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.252, test=0.063) total time=   2.1s\n","[CV 5/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 5/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.216, test=0.063) total time=   2.1s\n","[CV 6/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 6/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.237, test=0.102) total time=   2.1s\n","[CV 7/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 7/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.223, test=0.042) total time=   2.0s\n","[CV 1/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 1/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.700, test=0.031) total time=   3.1s\n","[CV 2/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 2/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.758, test=0.000) total time=   3.0s\n","[CV 3/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 3/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.742, test=0.028) total time=   3.1s\n","[CV 4/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 4/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.730, test=0.065) total time=   3.0s\n","[CV 5/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 5/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.757, test=0.075) total time=   3.0s\n","[CV 6/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 6/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.745, test=0.086) total time=   3.0s\n","[CV 7/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 7/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.757, test=0.038) total time=   3.1s\n","[CV 1/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 1/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.139, test=0.048) total time=   0.9s\n","[CV 2/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 2/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.118, test=0.000) total time=   0.9s\n","[CV 3/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 3/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.127, test=0.033) total time=   0.9s\n","[CV 4/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 4/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.140, test=0.032) total time=   0.9s\n","[CV 5/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 5/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.126, test=0.059) total time=   0.9s\n","[CV 6/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 6/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.114, test=0.073) total time=   0.9s\n","[CV 7/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 7/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.127, test=0.023) total time=   0.9s\n","[CV 1/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 1/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.133, test=0.050) total time=   0.9s\n","[CV 2/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 2/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.112, test=0.000) total time=   0.9s\n","[CV 3/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 3/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.122, test=0.033) total time=   0.9s\n","[CV 4/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 4/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.140, test=0.043) total time=   0.9s\n","[CV 5/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 5/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.127, test=0.058) total time=   0.9s\n","[CV 6/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 6/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.116, test=0.084) total time=   0.9s\n","[CV 7/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 7/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.122, test=0.025) total time=   0.9s\n","[CV 1/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 1/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.460, test=0.058) total time=   2.9s\n","[CV 2/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 2/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.498, test=0.016) total time=   2.9s\n","[CV 3/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 3/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.493, test=0.045) total time=   3.0s\n","[CV 4/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 4/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.463, test=0.064) total time=   4.9s\n","[CV 5/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 5/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.456, test=0.065) total time=   3.0s\n","[CV 6/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 6/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.483, test=0.096) total time=   3.0s\n","[CV 7/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 7/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.461, test=0.030) total time=   2.9s\n","[CV 1/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 1/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.261, test=0.070) total time=   2.3s\n","[CV 2/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 2/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.270, test=0.010) total time=   2.3s\n","[CV 3/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 3/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.288, test=0.086) total time=   2.3s\n","[CV 4/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 4/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.295, test=0.081) total time=   2.3s\n","[CV 5/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 5/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.249, test=0.069) total time=   2.4s\n","[CV 6/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 6/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.243, test=0.061) total time=   2.3s\n","[CV 7/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 7/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.236, test=0.047) total time=   2.4s\n","[CV 1/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 1/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.186, test=0.060) total time=   1.6s\n","[CV 2/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 2/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.184, test=0.053) total time=   1.5s\n","[CV 3/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 3/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.188, test=0.062) total time=   1.5s\n","[CV 4/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 4/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.198, test=0.042) total time=   1.6s\n","[CV 5/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 5/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.174, test=0.051) total time=   1.5s\n","[CV 6/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 6/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.170, test=0.091) total time=   1.6s\n","[CV 7/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 7/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.178, test=0.065) total time=   1.6s\n","Best_Hyperparameters: \n"," {'learning_rate': 0.1, 'n_estimators': 150, 'num_leaves': 45}\n","cluster:23 ; total_samples:174525 ; positives:1217 ; negatives:173308\n","Fitting 7 folds for each of 8 candidates, totalling 56 fits\n","[CV 1/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 1/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.615, test=0.000) total time=   2.1s\n","[CV 2/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 2/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.569, test=0.076) total time=   2.1s\n","[CV 3/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 3/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.571, test=0.045) total time=   2.1s\n","[CV 4/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 4/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.634, test=0.044) total time=   2.1s\n","[CV 5/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 5/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.579, test=0.054) total time=   2.1s\n","[CV 6/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 6/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.580, test=0.057) total time=   2.1s\n","[CV 7/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 7/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.554, test=0.025) total time=   2.2s\n","[CV 1/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 1/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.281, test=0.000) total time=   1.7s\n","[CV 2/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 2/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.245, test=0.064) total time=   1.7s\n","[CV 3/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 3/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.266, test=0.046) total time=   1.6s\n","[CV 4/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 4/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.274, test=0.045) total time=   1.6s\n","[CV 5/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 5/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.304, test=0.057) total time=   1.6s\n","[CV 6/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 6/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.254, test=0.062) total time=   1.6s\n","[CV 7/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 7/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.263, test=0.021) total time=   1.6s\n","[CV 1/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 1/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.819, test=0.000) total time=   2.4s\n","[CV 2/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 2/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.797, test=0.055) total time=   2.4s\n","[CV 3/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 3/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.834, test=0.034) total time=   2.4s\n","[CV 4/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 4/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.841, test=0.040) total time=   2.6s\n","[CV 5/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 5/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.834, test=0.065) total time=   2.3s\n","[CV 6/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 6/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.824, test=0.034) total time=   2.4s\n","[CV 7/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 7/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.786, test=0.018) total time=   2.4s\n","[CV 1/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 1/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.126, test=0.036) total time=   0.7s\n","[CV 2/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 2/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.137, test=0.050) total time=   0.7s\n","[CV 3/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 3/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.131, test=0.030) total time=   0.7s\n","[CV 4/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 4/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.125, test=0.031) total time=   0.7s\n","[CV 5/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 5/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.135, test=0.065) total time=   0.7s\n","[CV 6/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 6/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.112, test=0.023) total time=   0.8s\n","[CV 7/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 7/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.134, test=0.036) total time=   0.8s\n","[CV 1/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 1/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.122, test=0.010) total time=   0.8s\n","[CV 2/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 2/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.129, test=0.033) total time=   0.8s\n","[CV 3/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 3/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.123, test=0.031) total time=   0.8s\n","[CV 4/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 4/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.117, test=0.024) total time=   0.8s\n","[CV 5/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 5/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.134, test=0.073) total time=   0.7s\n","[CV 6/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 6/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.107, test=0.022) total time=   0.8s\n","[CV 7/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 7/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.136, test=0.031) total time=   0.7s\n","[CV 1/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 1/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.538, test=0.011) total time=   2.3s\n","[CV 2/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 2/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.522, test=0.030) total time=   2.3s\n","[CV 3/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 3/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.581, test=0.048) total time=   2.3s\n","[CV 4/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 4/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.532, test=0.042) total time=   2.4s\n","[CV 5/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 5/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.555, test=0.059) total time=   2.3s\n","[CV 6/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 6/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.513, test=0.041) total time=   2.3s\n","[CV 7/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 7/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.539, test=0.029) total time=   2.3s\n","[CV 1/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 1/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.324, test=0.000) total time=   1.8s\n","[CV 2/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 2/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.305, test=0.060) total time=   1.8s\n","[CV 3/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 3/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.307, test=0.037) total time=   1.8s\n","[CV 4/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 4/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.312, test=0.053) total time=   1.7s\n","[CV 5/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 5/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.281, test=0.052) total time=   1.8s\n","[CV 6/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 6/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.290, test=0.059) total time=   1.8s\n","[CV 7/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 7/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.329, test=0.026) total time=   1.8s\n","[CV 1/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 1/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.204, test=0.011) total time=   1.2s\n","[CV 2/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 2/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.209, test=0.065) total time=   1.2s\n","[CV 3/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 3/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.193, test=0.040) total time=   1.2s\n","[CV 4/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 4/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.202, test=0.042) total time=   1.3s\n","[CV 5/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 5/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.199, test=0.052) total time=   1.2s\n","[CV 6/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 6/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.202, test=0.054) total time=   1.2s\n","[CV 7/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 7/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.223, test=0.040) total time=   1.2s\n","Best_Hyperparameters: \n"," {'learning_rate': 0.1, 'n_estimators': 75, 'num_leaves': 26}\n","cluster:10 ; total_samples:156671 ; positives:1662 ; negatives:155009\n","Fitting 7 folds for each of 8 candidates, totalling 56 fits\n","[CV 1/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 1/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.535, test=0.000) total time=   1.9s\n","[CV 2/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 2/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.520, test=0.100) total time=   1.9s\n","[CV 3/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 3/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.519, test=0.099) total time=   1.9s\n","[CV 4/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 4/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.557, test=0.111) total time=   1.9s\n","[CV 5/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 5/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.508, test=0.082) total time=   1.8s\n","[CV 6/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 6/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.557, test=0.089) total time=   1.9s\n","[CV 7/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 7/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.518, test=0.090) total time=   1.9s\n","[CV 1/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 1/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.288, test=0.000) total time=   1.5s\n","[CV 2/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 2/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.302, test=0.118) total time=   1.5s\n","[CV 3/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 3/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.301, test=0.108) total time=   1.4s\n","[CV 4/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 4/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.273, test=0.144) total time=   1.5s\n","[CV 5/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 5/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.277, test=0.101) total time=   1.6s\n","[CV 6/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 6/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.306, test=0.100) total time=   1.5s\n","[CV 7/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 7/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.280, test=0.092) total time=   1.6s\n","[CV 1/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 1/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.737, test=0.000) total time=   2.2s\n","[CV 2/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 2/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.717, test=0.081) total time=   2.1s\n","[CV 3/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 3/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.722, test=0.111) total time=   2.2s\n","[CV 4/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 4/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.764, test=0.133) total time=   2.2s\n","[CV 5/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 5/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.728, test=0.079) total time=   2.1s\n","[CV 6/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 6/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.710, test=0.095) total time=   2.1s\n","[CV 7/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 7/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.733, test=0.102) total time=   2.2s\n","[CV 1/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 1/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.092, test=0.000) total time=   0.7s\n","[CV 2/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 2/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.072, test=0.030) total time=   0.7s\n","[CV 3/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 3/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.061, test=0.050) total time=   0.7s\n","[CV 4/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 4/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.086, test=0.040) total time=   0.7s\n","[CV 5/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 5/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.126, test=0.019) total time=   0.7s\n","[CV 6/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 6/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.088, test=0.105) total time=   0.7s\n","[CV 7/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 7/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.139, test=0.064) total time=   0.7s\n","[CV 1/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 1/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.093, test=0.000) total time=   0.7s\n","[CV 2/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 2/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.077, test=0.027) total time=   0.7s\n","[CV 3/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 3/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.070, test=0.037) total time=   0.7s\n","[CV 4/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 4/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.094, test=0.058) total time=   0.7s\n","[CV 5/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 5/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.113, test=0.019) total time=   0.7s\n","[CV 6/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 6/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.093, test=0.055) total time=   0.7s\n","[CV 7/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 7/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.127, test=0.061) total time=   0.7s\n","[CV 1/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 1/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.560, test=0.000) total time=   2.2s\n","[CV 2/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 2/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.499, test=0.097) total time=   2.2s\n","[CV 3/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 3/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.541, test=0.124) total time=   2.1s\n","[CV 4/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 4/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.561, test=0.134) total time=   2.2s\n","[CV 5/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 5/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.548, test=0.078) total time=   2.2s\n","[CV 6/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 6/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.551, test=0.102) total time=   2.1s\n","[CV 7/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 7/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.532, test=0.095) total time=   2.1s\n","[CV 1/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 1/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.286, test=0.000) total time=   1.6s\n","[CV 2/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 2/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.303, test=0.117) total time=   1.7s\n","[CV 3/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 3/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.310, test=0.105) total time=   1.6s\n","[CV 4/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 4/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.326, test=0.113) total time=   1.7s\n","[CV 5/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 5/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.319, test=0.084) total time=   1.7s\n","[CV 6/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 6/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.296, test=0.079) total time=   1.6s\n","[CV 7/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 7/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.308, test=0.096) total time=   1.6s\n","[CV 1/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 1/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.249, test=0.000) total time=   1.2s\n","[CV 2/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 2/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.224, test=0.117) total time=   1.1s\n","[CV 3/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 3/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.227, test=0.131) total time=   1.1s\n","[CV 4/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 4/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.248, test=0.120) total time=   1.1s\n","[CV 5/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 5/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.243, test=0.093) total time=   1.1s\n","[CV 6/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 6/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.239, test=0.079) total time=   1.1s\n","[CV 7/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 7/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.259, test=0.097) total time=   1.1s\n","Best_Hyperparameters: \n"," {'learning_rate': 0.05, 'n_estimators': 100, 'num_leaves': 43}\n","cluster:9 ; total_samples:152059 ; positives:2378 ; negatives:149681\n","Fitting 7 folds for each of 8 candidates, totalling 56 fits\n","[CV 1/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 1/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.410, test=0.083) total time=   1.9s\n","[CV 2/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 2/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.422, test=0.041) total time=   1.9s\n","[CV 3/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 3/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.424, test=0.139) total time=   1.9s\n","[CV 4/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 4/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.427, test=0.144) total time=   1.9s\n","[CV 5/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 5/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.423, test=0.126) total time=   2.1s\n","[CV 6/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 6/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.418, test=0.143) total time=   1.9s\n","[CV 7/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 7/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.410, test=0.000) total time=   1.9s\n","[CV 1/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 1/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.263, test=0.078) total time=   1.6s\n","[CV 2/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 2/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.249, test=0.100) total time=   1.8s\n","[CV 3/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 3/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.238, test=0.156) total time=   2.0s\n","[CV 4/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 4/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.236, test=0.144) total time=   2.4s\n","[CV 5/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 5/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.232, test=0.100) total time=   3.0s\n","[CV 6/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 6/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.249, test=0.139) total time=   3.8s\n","[CV 7/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 7/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.241, test=0.000) total time=   1.6s\n","[CV 1/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 1/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.619, test=0.086) total time=   2.2s\n","[CV 2/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 2/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.632, test=0.025) total time=   2.3s\n","[CV 3/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 3/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.590, test=0.151) total time=   2.1s\n","[CV 4/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 4/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.605, test=0.126) total time=   2.3s\n","[CV 5/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 5/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.624, test=0.109) total time=   2.3s\n","[CV 6/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 6/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.585, test=0.117) total time=   2.2s\n","[CV 7/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 7/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.607, test=0.000) total time=   2.2s\n","[CV 1/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 1/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.008, test=0.076) total time=   0.7s\n","[CV 2/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 2/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.030, test=0.006) total time=   0.8s\n","[CV 3/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 3/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.000, test=0.012) total time=   1.9s\n","[CV 4/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 4/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.003, test=0.000) total time=   0.7s\n","[CV 5/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 5/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.060, test=0.016) total time=   0.7s\n","[CV 6/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 6/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.054, test=0.017) total time=   0.7s\n","[CV 7/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 7/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.005, test=0.000) total time=   0.7s\n","[CV 1/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 1/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.004, test=0.098) total time=   0.7s\n","[CV 2/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 2/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.034, test=0.006) total time=   0.7s\n","[CV 3/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 3/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.004, test=0.000) total time=   0.7s\n","[CV 4/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 4/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.001, test=0.006) total time=   0.7s\n","[CV 5/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 5/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.064, test=0.016) total time=   0.7s\n","[CV 6/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 6/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.047, test=0.012) total time=   0.7s\n","[CV 7/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 7/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.006, test=0.000) total time=   0.7s\n","[CV 1/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 1/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.405, test=0.090) total time=   2.2s\n","[CV 2/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 2/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.415, test=0.056) total time=   2.4s\n","[CV 3/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 3/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.391, test=0.159) total time=   2.2s\n","[CV 4/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 4/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.402, test=0.149) total time=   2.3s\n","[CV 5/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 5/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.407, test=0.105) total time=   2.3s\n","[CV 6/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 6/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.396, test=0.145) total time=   2.2s\n","[CV 7/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 7/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.413, test=0.000) total time=   2.2s\n","[CV 1/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 1/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.267, test=0.095) total time=   1.6s\n","[CV 2/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 2/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.259, test=0.055) total time=   1.6s\n","[CV 3/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 3/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.271, test=0.158) total time=   1.7s\n","[CV 4/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 4/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.265, test=0.149) total time=   1.7s\n","[CV 5/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 5/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.265, test=0.128) total time=   1.7s\n","[CV 6/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 6/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.265, test=0.142) total time=   1.7s\n","[CV 7/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 7/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.270, test=0.000) total time=   1.7s\n","[CV 1/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 1/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.235, test=0.096) total time=   1.1s\n","[CV 2/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 2/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.232, test=0.126) total time=   1.1s\n","[CV 3/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 3/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.222, test=0.176) total time=   1.2s\n","[CV 4/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 4/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.229, test=0.155) total time=   1.1s\n","[CV 5/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 5/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.227, test=0.133) total time=   1.1s\n","[CV 6/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 6/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.225, test=0.145) total time=   1.1s\n","[CV 7/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 7/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.228, test=0.000) total time=   1.1s\n","Best_Hyperparameters: \n"," {'learning_rate': 0.1, 'n_estimators': 75, 'num_leaves': 26}\n","cluster:19 ; total_samples:152057 ; positives:0 ; negatives:152057\n","Fitting 7 folds for each of 8 candidates, totalling 56 fits\n","[CV 1/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 1/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 2/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 2/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 3/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 3/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 4/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 4/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 5/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 5/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 6/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 6/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 7/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 7/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 1/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 1/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 2/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 2/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 3/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 3/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 4/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 4/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 5/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 5/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 6/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 6/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 7/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 7/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 1/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 1/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 2/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 2/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 3/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 3/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 4/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 4/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 5/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 5/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 6/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 6/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 7/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 7/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 1/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 1/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 2/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 2/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 3/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 3/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 4/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 4/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 5/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 5/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 6/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 6/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 7/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 7/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 1/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 1/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 2/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 2/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 3/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 3/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 4/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 4/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 5/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 5/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 6/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 6/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 7/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 7/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 1/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 1/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 2/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 2/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 3/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 3/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 4/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 4/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 5/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 5/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 6/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 6/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 7/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 7/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 1/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 1/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 2/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 2/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 3/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 3/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 4/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 4/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 5/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 5/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 6/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 6/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 7/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 7/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 1/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 1/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 2/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 2/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 3/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 3/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 4/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 4/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 5/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 5/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 6/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 6/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.000, test=0.000) total time=   0.4s\n","[CV 7/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 7/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.000, test=0.000) total time=   0.4s\n","Best_Hyperparameters: \n"," {'learning_rate': 0.1, 'n_estimators': 150, 'num_leaves': 45}\n","cluster:16 ; total_samples:117507 ; positives:2745 ; negatives:114762\n","Fitting 7 folds for each of 8 candidates, totalling 56 fits\n","[CV 1/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 1/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.564, test=0.174) total time=   1.6s\n","[CV 2/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 2/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.578, test=0.278) total time=   1.7s\n","[CV 3/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 3/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.581, test=0.150) total time=   1.7s\n","[CV 4/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 4/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.600, test=0.262) total time=   1.6s\n","[CV 5/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 5/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.580, test=0.259) total time=   1.7s\n","[CV 6/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 6/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.598, test=0.254) total time=   1.7s\n","[CV 7/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 7/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.565, test=0.000) total time=   1.7s\n","[CV 1/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 1/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.387, test=0.246) total time=   1.3s\n","[CV 2/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 2/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.391, test=0.292) total time=   1.3s\n","[CV 3/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 3/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.398, test=0.256) total time=   1.3s\n","[CV 4/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 4/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.402, test=0.279) total time=   1.3s\n","[CV 5/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 5/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.387, test=0.259) total time=   1.4s\n","[CV 6/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 6/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.396, test=0.280) total time=   1.2s\n","[CV 7/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 7/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.387, test=0.000) total time=   1.3s\n","[CV 1/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 1/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.719, test=0.179) total time=   1.9s\n","[CV 2/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 2/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.714, test=0.269) total time=   1.9s\n","[CV 3/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 3/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.725, test=0.081) total time=   1.8s\n","[CV 4/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 4/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.703, test=0.256) total time=   1.8s\n","[CV 5/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 5/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.713, test=0.244) total time=   2.0s\n","[CV 6/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 6/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.725, test=0.246) total time=   1.8s\n","[CV 7/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 7/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.730, test=0.010) total time=   1.8s\n","[CV 1/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 1/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.023, test=0.000) total time=   0.5s\n","[CV 2/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 2/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.045, test=0.053) total time=   0.6s\n","[CV 3/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 3/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.017, test=0.005) total time=   0.6s\n","[CV 4/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 4/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.007, test=0.000) total time=   0.6s\n","[CV 5/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 5/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.102, test=0.069) total time=   0.6s\n","[CV 6/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 6/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.091, test=0.074) total time=   0.5s\n","[CV 7/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 7/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.065, test=0.000) total time=   0.6s\n","[CV 1/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 1/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.004, test=0.000) total time=   0.5s\n","[CV 2/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 2/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.041, test=0.048) total time=   0.6s\n","[CV 3/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 3/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.006, test=0.000) total time=   0.6s\n","[CV 4/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 4/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.014, test=0.000) total time=   0.6s\n","[CV 5/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 5/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.094, test=0.074) total time=   0.5s\n","[CV 6/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 6/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.070, test=0.065) total time=   0.5s\n","[CV 7/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 7/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.053, test=0.000) total time=   0.6s\n","[CV 1/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 1/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.539, test=0.166) total time=   1.8s\n","[CV 2/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 2/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.534, test=0.302) total time=   1.8s\n","[CV 3/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 3/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.549, test=0.217) total time=   1.9s\n","[CV 4/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 4/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.548, test=0.268) total time=   1.8s\n","[CV 5/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 5/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.551, test=0.260) total time=   1.8s\n","[CV 6/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 6/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.552, test=0.249) total time=   1.8s\n","[CV 7/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 7/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.542, test=0.000) total time=   1.8s\n","[CV 1/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 1/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.404, test=0.184) total time=   1.4s\n","[CV 2/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 2/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.398, test=0.284) total time=   1.3s\n","[CV 3/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 3/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.398, test=0.263) total time=   1.4s\n","[CV 4/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 4/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.411, test=0.272) total time=   1.4s\n","[CV 5/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 5/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.421, test=0.268) total time=   1.4s\n","[CV 6/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 6/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.413, test=0.253) total time=   1.4s\n","[CV 7/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 7/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.393, test=0.005) total time=   1.4s\n","[CV 1/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 1/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.371, test=0.219) total time=   0.9s\n","[CV 2/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 2/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.356, test=0.291) total time=   0.9s\n","[CV 3/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 3/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.364, test=0.263) total time=   1.0s\n","[CV 4/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 4/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.375, test=0.267) total time=   0.9s\n","[CV 5/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 5/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.352, test=0.259) total time=   1.0s\n","[CV 6/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 6/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.364, test=0.251) total time=   0.9s\n","[CV 7/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 7/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.354, test=0.005) total time=   0.9s\n","Best_Hyperparameters: \n"," {'learning_rate': 0.05, 'n_estimators': 100, 'num_leaves': 43}\n","cluster:13 ; total_samples:117503 ; positives:575 ; negatives:116928\n","Fitting 7 folds for each of 8 candidates, totalling 56 fits\n","[CV 1/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 1/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.815, test=0.000) total time=   1.6s\n","[CV 2/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 2/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.767, test=0.050) total time=   1.5s\n","[CV 3/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 3/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.770, test=0.069) total time=   1.5s\n","[CV 4/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 4/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.758, test=0.028) total time=   1.4s\n","[CV 5/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 5/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.675, test=0.011) total time=   1.4s\n","[CV 6/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 6/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.769, test=0.030) total time=   1.5s\n","[CV 7/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 7/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.750, test=0.000) total time=   1.5s\n","[CV 1/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 1/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.418, test=0.000) total time=   1.1s\n","[CV 2/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 2/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.446, test=0.076) total time=   1.1s\n","[CV 3/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 3/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.438, test=0.074) total time=   1.2s\n","[CV 4/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 4/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.438, test=0.060) total time=   1.1s\n","[CV 5/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 5/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.409, test=0.052) total time=   1.1s\n","[CV 6/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 6/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.450, test=0.038) total time=   1.1s\n","[CV 7/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 7/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.469, test=0.000) total time=   1.1s\n","[CV 1/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 1/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.960, test=0.000) total time=   1.8s\n","[CV 2/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 2/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.728, test=0.051) total time=   1.7s\n","[CV 3/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 3/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.968, test=0.073) total time=   1.8s\n","[CV 4/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 4/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.619, test=0.026) total time=   1.8s\n","[CV 5/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 5/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.861, test=0.043) total time=   1.7s\n","[CV 6/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 6/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.765, test=0.025) total time=   1.7s\n","[CV 7/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 7/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.778, test=0.000) total time=   1.8s\n","[CV 1/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 1/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.204, test=0.048) total time=   0.5s\n","[CV 2/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 2/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.172, test=0.072) total time=   0.5s\n","[CV 3/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 3/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.207, test=0.074) total time=   0.5s\n","[CV 4/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 4/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.177, test=0.040) total time=   0.5s\n","[CV 5/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 5/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.162, test=0.044) total time=   0.5s\n","[CV 6/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 6/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.198, test=0.059) total time=   0.5s\n","[CV 7/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 7/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.184, test=0.012) total time=   0.5s\n","[CV 1/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 1/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.183, test=0.027) total time=   0.5s\n","[CV 2/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 2/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.174, test=0.073) total time=   0.5s\n","[CV 3/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 3/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.192, test=0.076) total time=   0.5s\n","[CV 4/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 4/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.164, test=0.049) total time=   0.5s\n","[CV 5/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 5/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.162, test=0.043) total time=   0.5s\n","[CV 6/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 6/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.196, test=0.044) total time=   0.5s\n","[CV 7/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 7/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.189, test=0.013) total time=   0.5s\n","[CV 1/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 1/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.777, test=0.000) total time=   1.8s\n","[CV 2/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 2/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.789, test=0.073) total time=   1.8s\n","[CV 3/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 3/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.739, test=0.067) total time=   1.8s\n","[CV 4/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 4/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.802, test=0.047) total time=   1.7s\n","[CV 5/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 5/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.772, test=0.029) total time=   1.7s\n","[CV 6/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 6/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.766, test=0.014) total time=   1.7s\n","[CV 7/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 7/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.809, test=0.000) total time=   1.8s\n","[CV 1/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 1/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.426, test=0.000) total time=   1.3s\n","[CV 2/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 2/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.548, test=0.043) total time=   1.3s\n","[CV 3/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 3/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.462, test=0.091) total time=   1.2s\n","[CV 4/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 4/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.254, test=0.048) total time=   1.4s\n","[CV 5/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 5/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.346, test=0.087) total time=   1.3s\n","[CV 6/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 6/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.453, test=0.009) total time=   1.2s\n","[CV 7/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 7/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.436, test=0.019) total time=   1.3s\n","[CV 1/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 1/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.284, test=0.038) total time=   0.9s\n","[CV 2/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 2/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.346, test=0.043) total time=   0.9s\n","[CV 3/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 3/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.311, test=0.073) total time=   0.9s\n","[CV 4/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 4/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.306, test=0.029) total time=   0.8s\n","[CV 5/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 5/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.295, test=0.034) total time=   0.8s\n","[CV 6/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 6/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.289, test=0.011) total time=   0.8s\n","[CV 7/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 7/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.344, test=0.000) total time=   0.8s\n","Best_Hyperparameters: \n"," {'learning_rate': 0.05, 'n_estimators': 20, 'num_leaves': 62}\n","cluster:31 ; total_samples:116350 ; positives:1762 ; negatives:114588\n","Fitting 7 folds for each of 8 candidates, totalling 56 fits\n","[CV 1/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 1/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.496, test=0.000) total time=   1.3s\n","[CV 2/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 2/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.523, test=0.090) total time=   1.5s\n","[CV 3/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 3/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.512, test=0.150) total time=   1.4s\n","[CV 4/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 4/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.537, test=0.127) total time=   1.4s\n","[CV 5/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 5/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.506, test=0.094) total time=   1.4s\n","[CV 6/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 6/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.507, test=0.116) total time=   1.4s\n","[CV 7/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 7/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.488, test=0.000) total time=   1.4s\n","[CV 1/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 1/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.204, test=0.000) total time=   1.1s\n","[CV 2/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 2/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.205, test=0.100) total time=   1.2s\n","[CV 3/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 3/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.204, test=0.167) total time=   1.2s\n","[CV 4/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 4/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.205, test=0.097) total time=   1.1s\n","[CV 5/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 5/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.200, test=0.094) total time=   1.1s\n","[CV 6/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 6/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.204, test=0.108) total time=   1.1s\n","[CV 7/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 7/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.204, test=0.000) total time=   1.1s\n","[CV 1/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 1/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.727, test=0.000) total time=   1.7s\n","[CV 2/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 2/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.721, test=0.084) total time=   1.6s\n","[CV 3/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 3/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.758, test=0.125) total time=   1.7s\n","[CV 4/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 4/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.771, test=0.129) total time=   1.7s\n","[CV 5/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 5/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.730, test=0.096) total time=   1.6s\n","[CV 6/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 6/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.745, test=0.079) total time=   1.7s\n","[CV 7/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 7/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.732, test=0.000) total time=   1.7s\n","[CV 1/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 1/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.001, test=0.000) total time=   0.5s\n","[CV 2/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 2/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.010, test=0.000) total time=   0.5s\n","[CV 3/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 3/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.001, test=0.000) total time=   0.6s\n","[CV 4/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 4/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.008, test=0.000) total time=   0.6s\n","[CV 5/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 5/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.001, test=0.000) total time=   0.6s\n","[CV 6/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 6/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.004, test=0.000) total time=   0.6s\n","[CV 7/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 7/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.004, test=0.000) total time=   0.5s\n","[CV 1/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 1/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.001, test=0.000) total time=   0.5s\n","[CV 2/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 2/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.010, test=0.000) total time=   0.5s\n","[CV 3/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 3/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.001, test=0.000) total time=   0.6s\n","[CV 4/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 4/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.007, test=0.000) total time=   0.6s\n","[CV 5/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 5/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.003, test=0.007) total time=   0.5s\n","[CV 6/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 6/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.001, test=0.000) total time=   0.5s\n","[CV 7/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 7/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.003, test=0.000) total time=   0.6s\n","[CV 1/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 1/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.481, test=0.000) total time=   1.7s\n","[CV 2/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 2/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.483, test=0.083) total time=   1.8s\n","[CV 3/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 3/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.500, test=0.150) total time=   1.8s\n","[CV 4/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 4/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.515, test=0.093) total time=   1.7s\n","[CV 5/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 5/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.465, test=0.085) total time=   1.7s\n","[CV 6/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 6/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.484, test=0.090) total time=   1.7s\n","[CV 7/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 7/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.483, test=0.000) total time=   1.8s\n","[CV 1/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 1/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.236, test=0.000) total time=   1.2s\n","[CV 2/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 2/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.247, test=0.107) total time=   1.2s\n","[CV 3/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 3/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.225, test=0.153) total time=   1.3s\n","[CV 4/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 4/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.226, test=0.099) total time=   1.2s\n","[CV 5/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 5/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.241, test=0.086) total time=   1.3s\n","[CV 6/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 6/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.228, test=0.113) total time=   1.3s\n","[CV 7/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 7/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.240, test=0.000) total time=   3.5s\n","[CV 1/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 1/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.177, test=0.000) total time=   0.8s\n","[CV 2/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 2/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.183, test=0.103) total time=   0.8s\n","[CV 3/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 3/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.169, test=0.145) total time=   0.8s\n","[CV 4/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 4/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.189, test=0.113) total time=   0.8s\n","[CV 5/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 5/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.195, test=0.088) total time=   0.8s\n","[CV 6/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 6/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.181, test=0.116) total time=   0.8s\n","[CV 7/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 7/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.181, test=0.000) total time=   0.9s\n","Best_Hyperparameters: \n"," {'learning_rate': 0.1, 'n_estimators': 150, 'num_leaves': 45}\n","cluster:7 ; total_samples:116350 ; positives:3048 ; negatives:113302\n","Fitting 7 folds for each of 8 candidates, totalling 56 fits\n","[CV 1/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 1/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.608, test=0.000) total time=   1.4s\n","[CV 2/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 2/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.616, test=0.370) total time=   1.4s\n","[CV 3/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 3/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.602, test=0.346) total time=   1.3s\n","[CV 4/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 4/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.607, test=0.313) total time=   1.3s\n","[CV 5/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 5/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.622, test=0.320) total time=   1.4s\n","[CV 6/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 6/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.619, test=0.342) total time=   1.3s\n","[CV 7/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 7/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.615, test=0.382) total time=   1.4s\n","[CV 1/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 1/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.508, test=0.000) total time=   1.1s\n","[CV 2/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 2/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.503, test=0.394) total time=   1.1s\n","[CV 3/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 3/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.500, test=0.350) total time=   1.1s\n","[CV 4/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 4/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.501, test=0.328) total time=   1.1s\n","[CV 5/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 5/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.506, test=0.318) total time=   1.0s\n","[CV 6/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 6/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.509, test=0.346) total time=   1.1s\n","[CV 7/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 7/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.495, test=0.362) total time=   1.1s\n","[CV 1/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 1/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.735, test=0.000) total time=   1.6s\n","[CV 2/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 2/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.737, test=0.347) total time=   1.5s\n","[CV 3/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 3/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.715, test=0.333) total time=   1.5s\n","[CV 4/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 4/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.713, test=0.311) total time=   1.6s\n","[CV 5/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 5/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.741, test=0.329) total time=   1.6s\n","[CV 6/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 6/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.725, test=0.339) total time=   1.6s\n","[CV 7/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 7/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.721, test=0.370) total time=   1.6s\n","[CV 1/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 1/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.421, test=0.000) total time=   0.5s\n","[CV 2/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 2/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.400, test=0.356) total time=   0.4s\n","[CV 3/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 3/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.392, test=0.344) total time=   0.4s\n","[CV 4/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 4/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.428, test=0.319) total time=   0.5s\n","[CV 5/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 5/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.403, test=0.385) total time=   0.5s\n","[CV 6/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 6/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.436, test=0.387) total time=   0.5s\n","[CV 7/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 7/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.417, test=0.427) total time=   0.5s\n","[CV 1/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 1/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.414, test=0.005) total time=   0.4s\n","[CV 2/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 2/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.401, test=0.352) total time=   0.5s\n","[CV 3/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 3/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.378, test=0.351) total time=   0.5s\n","[CV 4/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 4/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.425, test=0.314) total time=   0.5s\n","[CV 5/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 5/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.408, test=0.392) total time=   0.4s\n","[CV 6/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 6/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.430, test=0.372) total time=   0.4s\n","[CV 7/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 7/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.407, test=0.392) total time=   0.5s\n","[CV 1/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 1/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.604, test=0.000) total time=   1.7s\n","[CV 2/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 2/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.601, test=0.387) total time=   1.5s\n","[CV 3/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 3/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.590, test=0.357) total time=   1.5s\n","[CV 4/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 4/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.606, test=0.304) total time=   1.5s\n","[CV 5/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 5/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.600, test=0.328) total time=   1.5s\n","[CV 6/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 6/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.605, test=0.335) total time=   1.6s\n","[CV 7/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 7/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.598, test=0.377) total time=   1.5s\n","[CV 1/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 1/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.511, test=0.000) total time=   1.2s\n","[CV 2/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 2/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.508, test=0.380) total time=   1.2s\n","[CV 3/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 3/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.502, test=0.338) total time=   1.2s\n","[CV 4/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 4/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.507, test=0.297) total time=   1.2s\n","[CV 5/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 5/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.503, test=0.307) total time=   1.3s\n","[CV 6/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 6/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.498, test=0.326) total time=   1.1s\n","[CV 7/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 7/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.496, test=0.379) total time=   1.1s\n","[CV 1/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 1/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.468, test=0.000) total time=   0.8s\n","[CV 2/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 2/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.474, test=0.388) total time=   0.8s\n","[CV 3/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 3/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.471, test=0.340) total time=   0.8s\n","[CV 4/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 4/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.472, test=0.289) total time=   0.8s\n","[CV 5/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 5/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.475, test=0.308) total time=   0.8s\n","[CV 6/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 6/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.478, test=0.348) total time=   0.8s\n","[CV 7/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 7/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.463, test=0.372) total time=   0.8s\n","Best_Hyperparameters: \n"," {'learning_rate': 0.05, 'n_estimators': 20, 'num_leaves': 62}\n","cluster:5 ; total_samples:116350 ; positives:2352 ; negatives:113998\n","Fitting 7 folds for each of 8 candidates, totalling 56 fits\n","[CV 1/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 1/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.575, test=0.267) total time=   1.4s\n","[CV 2/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 2/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.571, test=0.287) total time=   1.4s\n","[CV 3/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 3/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.558, test=0.247) total time=   1.4s\n","[CV 4/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 4/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.574, test=0.087) total time=   1.4s\n","[CV 5/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 5/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.572, test=0.264) total time=   1.5s\n","[CV 6/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 6/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.553, test=0.268) total time=   1.5s\n","[CV 7/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 7/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.564, test=0.099) total time=   1.4s\n","[CV 1/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 1/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.424, test=0.259) total time=   1.2s\n","[CV 2/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 2/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.418, test=0.298) total time=   1.2s\n","[CV 3/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 3/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.419, test=0.273) total time=   1.2s\n","[CV 4/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 4/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.419, test=0.299) total time=   1.2s\n","[CV 5/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 5/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.419, test=0.274) total time=   1.1s\n","[CV 6/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 6/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.425, test=0.297) total time=   1.1s\n","[CV 7/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 7/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.420, test=0.261) total time=   1.3s\n","[CV 1/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 1/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.713, test=0.266) total time=   1.6s\n","[CV 2/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 2/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.705, test=0.281) total time=   1.6s\n","[CV 3/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 3/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.693, test=0.253) total time=   1.7s\n","[CV 4/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 4/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.695, test=0.198) total time=   1.6s\n","[CV 5/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 5/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.695, test=0.265) total time=   1.7s\n","[CV 6/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 6/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.701, test=0.264) total time=   1.8s\n","[CV 7/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 7/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.691, test=0.142) total time=   1.6s\n","[CV 1/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 1/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.192, test=0.302) total time=   0.5s\n","[CV 2/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 2/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.068, test=0.064) total time=   0.5s\n","[CV 3/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 3/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.199, test=0.123) total time=   0.5s\n","[CV 4/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 4/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.074, test=0.033) total time=   0.5s\n","[CV 5/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 5/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.170, test=0.179) total time=   0.5s\n","[CV 6/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 6/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.086, test=0.006) total time=   0.5s\n","[CV 7/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 7/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.199, test=0.134) total time=   0.5s\n","[CV 1/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 1/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.196, test=0.320) total time=   0.5s\n","[CV 2/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 2/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.060, test=0.055) total time=   0.5s\n","[CV 3/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 3/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.177, test=0.106) total time=   0.5s\n","[CV 4/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 4/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.074, test=0.032) total time=   0.5s\n","[CV 5/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 5/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.168, test=0.191) total time=   0.5s\n","[CV 6/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 6/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.038, test=0.006) total time=   0.5s\n","[CV 7/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 7/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.207, test=0.162) total time=   0.5s\n","[CV 1/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 1/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.575, test=0.272) total time=   1.8s\n","[CV 2/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 2/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.571, test=0.292) total time=   1.7s\n","[CV 3/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 3/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.565, test=0.243) total time=   1.6s\n","[CV 4/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 4/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.568, test=0.307) total time=   1.6s\n","[CV 5/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 5/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.556, test=0.272) total time=   1.6s\n","[CV 6/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 6/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.556, test=0.290) total time=   1.7s\n","[CV 7/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 7/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.558, test=0.220) total time=   1.8s\n","[CV 1/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 1/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.434, test=0.259) total time=   1.2s\n","[CV 2/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 2/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.426, test=0.267) total time=   1.2s\n","[CV 3/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 3/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.431, test=0.258) total time=   1.2s\n","[CV 4/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 4/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.430, test=0.291) total time=   1.2s\n","[CV 5/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 5/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.425, test=0.274) total time=   1.2s\n","[CV 6/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 6/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.435, test=0.279) total time=   1.2s\n","[CV 7/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 7/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.432, test=0.196) total time=   1.2s\n","[CV 1/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 1/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.386, test=0.246) total time=   0.9s\n","[CV 2/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 2/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.372, test=0.295) total time=   0.9s\n","[CV 3/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 3/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.376, test=0.261) total time=   0.9s\n","[CV 4/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 4/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.390, test=0.297) total time=   0.8s\n","[CV 5/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 5/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.376, test=0.292) total time=   0.9s\n","[CV 6/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 6/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.387, test=0.287) total time=   0.9s\n","[CV 7/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 7/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.375, test=0.251) total time=   0.8s\n","Best_Hyperparameters: \n"," {'learning_rate': 0.05, 'n_estimators': 100, 'num_leaves': 43}\n","cluster:18 ; total_samples:116350 ; positives:961 ; negatives:115389\n","Fitting 7 folds for each of 8 candidates, totalling 56 fits\n","[CV 1/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 1/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.699, test=0.036) total time=   1.4s\n","[CV 2/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 2/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.694, test=0.042) total time=   1.4s\n","[CV 3/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 3/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.756, test=0.054) total time=   1.4s\n","[CV 4/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 4/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.716, test=0.053) total time=   1.4s\n","[CV 5/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 5/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.717, test=0.070) total time=   1.4s\n","[CV 6/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 6/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.708, test=0.047) total time=   1.4s\n","[CV 7/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 7/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.746, test=0.073) total time=   1.4s\n","[CV 1/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 1/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.380, test=0.022) total time=   1.1s\n","[CV 2/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 2/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.402, test=0.021) total time=   1.1s\n","[CV 3/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 3/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.412, test=0.074) total time=   1.2s\n","[CV 4/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 4/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.409, test=0.071) total time=   1.1s\n","[CV 5/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 5/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.364, test=0.083) total time=   1.1s\n","[CV 6/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 6/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.371, test=0.030) total time=   1.1s\n","[CV 7/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 7/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.358, test=0.077) total time=   1.1s\n","[CV 1/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 1/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.917, test=0.036) total time=   1.6s\n","[CV 2/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 2/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.902, test=0.010) total time=   1.7s\n","[CV 3/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 3/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.928, test=0.057) total time=   1.8s\n","[CV 4/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 4/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.892, test=0.080) total time=   1.6s\n","[CV 5/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 5/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.918, test=0.067) total time=   1.8s\n","[CV 6/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 6/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.886, test=0.041) total time=   1.7s\n","[CV 7/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 7/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.906, test=0.062) total time=   1.7s\n","[CV 1/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 1/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.142, test=0.029) total time=   0.5s\n","[CV 2/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 2/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.149, test=0.017) total time=   0.5s\n","[CV 3/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 3/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.117, test=0.055) total time=   0.5s\n","[CV 4/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 4/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.129, test=0.044) total time=   0.5s\n","[CV 5/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 5/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.119, test=0.048) total time=   0.5s\n","[CV 6/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 6/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.146, test=0.030) total time=   0.5s\n","[CV 7/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 7/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.136, test=0.080) total time=   0.5s\n","[CV 1/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 1/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.138, test=0.040) total time=   0.5s\n","[CV 2/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 2/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.144, test=0.017) total time=   0.5s\n","[CV 3/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 3/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.088, test=0.044) total time=   0.5s\n","[CV 4/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 4/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.136, test=0.041) total time=   0.5s\n","[CV 5/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 5/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.108, test=0.059) total time=   0.5s\n","[CV 6/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 6/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.136, test=0.030) total time=   0.5s\n","[CV 7/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 7/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.134, test=0.079) total time=   0.5s\n","[CV 1/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 1/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.716, test=0.027) total time=   1.8s\n","[CV 2/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 2/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.688, test=0.022) total time=   1.6s\n","[CV 3/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 3/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.747, test=0.063) total time=   1.7s\n","[CV 4/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 4/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.694, test=0.061) total time=   1.7s\n","[CV 5/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 5/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.698, test=0.068) total time=   1.6s\n","[CV 6/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 6/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.708, test=0.045) total time=   1.6s\n","[CV 7/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 7/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.699, test=0.078) total time=   1.6s\n","[CV 1/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 1/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.452, test=0.036) total time=   1.2s\n","[CV 2/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 2/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.439, test=0.022) total time=   1.1s\n","[CV 3/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 3/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.349, test=0.050) total time=   1.3s\n","[CV 4/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 4/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.379, test=0.066) total time=   1.2s\n","[CV 5/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 5/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.371, test=0.080) total time=   1.2s\n","[CV 6/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 6/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.406, test=0.032) total time=   1.3s\n","[CV 7/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 7/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.412, test=0.069) total time=   1.2s\n","[CV 1/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 1/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.277, test=0.036) total time=   0.9s\n","[CV 2/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 2/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.284, test=0.008) total time=   0.9s\n","[CV 3/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 3/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.257, test=0.060) total time=   0.8s\n","[CV 4/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 4/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.256, test=0.064) total time=   0.8s\n","[CV 5/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 5/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.267, test=0.072) total time=   0.8s\n","[CV 6/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 6/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.293, test=0.046) total time=   0.8s\n","[CV 7/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 7/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.285, test=0.077) total time=   0.8s\n","Best_Hyperparameters: \n"," {'learning_rate': 0.05, 'n_estimators': 100, 'num_leaves': 43}\n","cluster:11 ; total_samples:97840 ; positives:712 ; negatives:97128\n","Fitting 7 folds for each of 8 candidates, totalling 56 fits\n","[CV 1/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 1/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.765, test=0.000) total time=   1.8s\n","[CV 2/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 2/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.753, test=0.054) total time=   1.5s\n","[CV 3/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 3/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.744, test=0.041) total time=   1.5s\n","[CV 4/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 4/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.784, test=0.050) total time=   1.5s\n","[CV 5/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 5/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.752, test=0.071) total time=   1.5s\n","[CV 6/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 6/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.798, test=0.067) total time=   1.6s\n","[CV 7/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 7/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.733, test=0.062) total time=   1.5s\n","[CV 1/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 1/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.392, test=0.000) total time=   1.1s\n","[CV 2/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 2/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.385, test=0.069) total time=   1.1s\n","[CV 3/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 3/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.405, test=0.049) total time=   1.1s\n","[CV 4/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 4/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.412, test=0.061) total time=   1.1s\n","[CV 5/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 5/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.398, test=0.072) total time=   1.1s\n","[CV 6/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 6/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.423, test=0.073) total time=   1.1s\n","[CV 7/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 7/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.394, test=0.054) total time=   1.1s\n","[CV 1/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 1/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.914, test=0.000) total time=   1.7s\n","[CV 2/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 2/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.911, test=0.058) total time=   1.7s\n","[CV 3/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 3/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.922, test=0.043) total time=   1.8s\n","[CV 4/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 4/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.942, test=0.059) total time=   1.7s\n","[CV 5/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 5/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.934, test=0.048) total time=   1.7s\n","[CV 6/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 6/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.934, test=0.063) total time=   1.7s\n","[CV 7/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 7/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.924, test=0.068) total time=   1.7s\n","[CV 1/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 1/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.191, test=0.000) total time=   0.5s\n","[CV 2/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 2/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.226, test=0.051) total time=   0.5s\n","[CV 3/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 3/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.200, test=0.052) total time=   0.5s\n","[CV 4/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 4/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.200, test=0.060) total time=   0.5s\n","[CV 5/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 5/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.197, test=0.057) total time=   0.5s\n","[CV 6/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 6/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.157, test=0.077) total time=   0.5s\n","[CV 7/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 7/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.213, test=0.045) total time=   0.5s\n","[CV 1/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 1/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.215, test=0.000) total time=   0.5s\n","[CV 2/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 2/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.215, test=0.061) total time=   0.5s\n","[CV 3/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 3/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.198, test=0.049) total time=   0.5s\n","[CV 4/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 4/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.192, test=0.064) total time=   0.6s\n","[CV 5/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 5/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.212, test=0.057) total time=   1.8s\n","[CV 6/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 6/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.177, test=0.074) total time=   0.5s\n","[CV 7/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 7/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.208, test=0.045) total time=   0.5s\n","[CV 1/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 1/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.739, test=0.000) total time=   1.7s\n","[CV 2/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 2/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.687, test=0.073) total time=   1.6s\n","[CV 3/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 3/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.711, test=0.052) total time=   1.7s\n","[CV 4/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 4/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.767, test=0.053) total time=   1.7s\n","[CV 5/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 5/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.700, test=0.078) total time=   1.6s\n","[CV 6/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 6/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.753, test=0.078) total time=   1.7s\n","[CV 7/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 7/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.701, test=0.061) total time=   1.7s\n","[CV 1/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 1/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.428, test=0.000) total time=   1.2s\n","[CV 2/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 2/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.454, test=0.069) total time=   1.1s\n","[CV 3/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 3/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.427, test=0.046) total time=   1.3s\n","[CV 4/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 4/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.440, test=0.049) total time=   1.2s\n","[CV 5/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 5/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.421, test=0.076) total time=   1.3s\n","[CV 6/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 6/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.442, test=0.072) total time=   1.2s\n","[CV 7/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 7/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.426, test=0.058) total time=   1.3s\n","[CV 1/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 1/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.297, test=0.000) total time=   0.8s\n","[CV 2/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 2/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.334, test=0.090) total time=   0.8s\n","[CV 3/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 3/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.294, test=0.047) total time=   0.8s\n","[CV 4/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 4/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.317, test=0.061) total time=   0.8s\n","[CV 5/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 5/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.311, test=0.070) total time=   0.8s\n","[CV 6/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 6/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.331, test=0.077) total time=   0.8s\n","[CV 7/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 7/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.264, test=0.052) total time=   0.8s\n","Best_Hyperparameters: \n"," {'learning_rate': 0.1, 'n_estimators': 75, 'num_leaves': 26}\n","cluster:37 ; total_samples:97344 ; positives:1247 ; negatives:96097\n","Fitting 7 folds for each of 8 candidates, totalling 56 fits\n","[CV 1/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 1/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.592, test=0.088) total time=   1.2s\n","[CV 2/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 2/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.572, test=0.134) total time=   1.2s\n","[CV 3/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 3/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.608, test=0.138) total time=   1.3s\n","[CV 4/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 4/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.600, test=0.148) total time=   1.2s\n","[CV 5/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 5/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.626, test=0.134) total time=   1.4s\n","[CV 6/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 6/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.580, test=0.135) total time=   1.3s\n","[CV 7/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 7/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.580, test=0.000) total time=   1.3s\n","[CV 1/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 1/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.305, test=0.140) total time=   1.0s\n","[CV 2/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 2/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.298, test=0.157) total time=   1.0s\n","[CV 3/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 3/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.301, test=0.135) total time=   1.1s\n","[CV 4/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 4/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.324, test=0.170) total time=   1.0s\n","[CV 5/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 5/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.311, test=0.137) total time=   1.0s\n","[CV 6/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 6/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.309, test=0.148) total time=   1.0s\n","[CV 7/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 7/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.306, test=0.000) total time=   1.1s\n","[CV 1/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 1/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.796, test=0.100) total time=   1.5s\n","[CV 2/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 2/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.797, test=0.135) total time=   1.5s\n","[CV 3/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 3/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.784, test=0.108) total time=   1.5s\n","[CV 4/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 4/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.803, test=0.142) total time=   1.5s\n","[CV 5/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 5/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.804, test=0.095) total time=   1.5s\n","[CV 6/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 6/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.797, test=0.143) total time=   1.5s\n","[CV 7/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 7/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.799, test=0.000) total time=   1.6s\n","[CV 1/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 1/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.051, test=0.039) total time=   0.5s\n","[CV 2/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 2/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.042, test=0.000) total time=   0.5s\n","[CV 3/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 3/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.057, test=0.010) total time=   0.4s\n","[CV 4/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 4/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.028, test=0.011) total time=   0.4s\n","[CV 5/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 5/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.059, test=0.027) total time=   0.5s\n","[CV 6/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 6/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.051, test=0.000) total time=   0.4s\n","[CV 7/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 7/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.000, test=0.000) total time=   0.5s\n","[CV 1/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 1/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.053, test=0.008) total time=   0.5s\n","[CV 2/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 2/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.047, test=0.000) total time=   0.5s\n","[CV 3/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 3/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.065, test=0.010) total time=   0.5s\n","[CV 4/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 4/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.013, test=0.000) total time=   0.5s\n","[CV 5/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 5/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.065, test=0.018) total time=   0.4s\n","[CV 6/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 6/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.044, test=0.000) total time=   0.5s\n","[CV 7/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 7/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.002, test=0.000) total time=   0.4s\n","[CV 1/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 1/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.564, test=0.104) total time=   1.5s\n","[CV 2/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 2/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.582, test=0.145) total time=   1.5s\n","[CV 3/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 3/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.578, test=0.134) total time=   1.5s\n","[CV 4/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 4/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.624, test=0.150) total time=   1.5s\n","[CV 5/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 5/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.652, test=0.147) total time=   1.5s\n","[CV 6/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 6/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.554, test=0.146) total time=   1.4s\n","[CV 7/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 7/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.580, test=0.000) total time=   1.5s\n","[CV 1/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 1/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.332, test=0.100) total time=   1.0s\n","[CV 2/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 2/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.333, test=0.132) total time=   1.0s\n","[CV 3/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 3/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.318, test=0.143) total time=   1.0s\n","[CV 4/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 4/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.323, test=0.153) total time=   1.0s\n","[CV 5/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 5/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.327, test=0.198) total time=   1.0s\n","[CV 6/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 6/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.337, test=0.149) total time=   1.0s\n","[CV 7/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 7/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.317, test=0.000) total time=   1.0s\n","[CV 1/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 1/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.274, test=0.122) total time=   0.7s\n","[CV 2/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 2/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.263, test=0.132) total time=   0.7s\n","[CV 3/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 3/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.256, test=0.149) total time=   0.8s\n","[CV 4/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 4/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.265, test=0.157) total time=   0.7s\n","[CV 5/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 5/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.255, test=0.198) total time=   0.7s\n","[CV 6/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 6/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.268, test=0.140) total time=   0.7s\n","[CV 7/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 7/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.243, test=0.000) total time=   0.7s\n","Best_Hyperparameters: \n"," {'learning_rate': 0.1, 'n_estimators': 75, 'num_leaves': 26}\n","cluster:26 ; total_samples:97344 ; positives:721 ; negatives:96623\n","Fitting 7 folds for each of 8 candidates, totalling 56 fits\n","[CV 1/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 1/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.752, test=0.050) total time=   1.3s\n","[CV 2/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 2/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.743, test=0.081) total time=   1.3s\n","[CV 3/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 3/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.784, test=0.063) total time=   1.3s\n","[CV 4/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 4/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.800, test=0.049) total time=   1.4s\n","[CV 5/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 5/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.790, test=0.047) total time=   1.4s\n","[CV 6/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 6/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.782, test=0.091) total time=   1.3s\n","[CV 7/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 7/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.776, test=0.036) total time=   1.3s\n","[CV 1/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 1/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.381, test=0.082) total time=   1.0s\n","[CV 2/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 2/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.394, test=0.144) total time=   1.1s\n","[CV 3/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 3/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.398, test=0.067) total time=   1.0s\n","[CV 4/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 4/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.411, test=0.064) total time=   1.0s\n","[CV 5/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 5/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.394, test=0.042) total time=   1.0s\n","[CV 6/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 6/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.401, test=0.125) total time=   1.0s\n","[CV 7/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 7/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.406, test=0.066) total time=   1.0s\n","[CV 1/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 1/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.913, test=0.022) total time=   1.7s\n","[CV 2/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 2/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.922, test=0.068) total time=   1.6s\n","[CV 3/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 3/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.911, test=0.056) total time=   1.6s\n","[CV 4/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 4/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.938, test=0.055) total time=   1.7s\n","[CV 5/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 5/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.873, test=0.049) total time=   1.7s\n","[CV 6/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 6/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.920, test=0.099) total time=   1.6s\n","[CV 7/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 7/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.940, test=0.026) total time=   1.7s\n","[CV 1/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 1/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.207, test=0.038) total time=   0.4s\n","[CV 2/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 2/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.198, test=0.116) total time=   0.4s\n","[CV 3/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 3/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.217, test=0.056) total time=   0.4s\n","[CV 4/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 4/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.208, test=0.073) total time=   0.4s\n","[CV 5/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 5/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.209, test=0.080) total time=   0.5s\n","[CV 6/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 6/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.217, test=0.125) total time=   0.5s\n","[CV 7/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 7/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.225, test=0.083) total time=   0.5s\n","[CV 1/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 1/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.196, test=0.034) total time=   0.5s\n","[CV 2/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 2/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.189, test=0.131) total time=   0.5s\n","[CV 3/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 3/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.214, test=0.059) total time=   0.4s\n","[CV 4/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 4/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.188, test=0.080) total time=   0.5s\n","[CV 5/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 5/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.211, test=0.082) total time=   0.5s\n","[CV 6/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 6/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.210, test=0.123) total time=   0.4s\n","[CV 7/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 7/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.215, test=0.078) total time=   0.5s\n","[CV 1/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 1/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.702, test=0.049) total time=   1.6s\n","[CV 2/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 2/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.694, test=0.067) total time=   1.5s\n","[CV 3/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 3/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.700, test=0.064) total time=   1.5s\n","[CV 4/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 4/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.728, test=0.041) total time=   1.5s\n","[CV 5/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 5/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.725, test=0.057) total time=   1.5s\n","[CV 6/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 6/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.745, test=0.123) total time=   1.6s\n","[CV 7/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 7/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.741, test=0.053) total time=   1.6s\n","[CV 1/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 1/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.477, test=0.042) total time=   1.1s\n","[CV 2/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 2/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.444, test=0.066) total time=   1.2s\n","[CV 3/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 3/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.435, test=0.064) total time=   1.2s\n","[CV 4/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 4/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.456, test=0.057) total time=   1.1s\n","[CV 5/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 5/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.480, test=0.059) total time=   1.1s\n","[CV 6/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 6/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.444, test=0.100) total time=   1.1s\n","[CV 7/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 7/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.490, test=0.059) total time=   1.1s\n","[CV 1/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 1/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.353, test=0.052) total time=   0.7s\n","[CV 2/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 2/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.301, test=0.095) total time=   0.7s\n","[CV 3/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 3/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.296, test=0.059) total time=   0.8s\n","[CV 4/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 4/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.349, test=0.061) total time=   0.8s\n","[CV 5/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 5/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.361, test=0.056) total time=   0.7s\n","[CV 6/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 6/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.309, test=0.116) total time=   0.7s\n","[CV 7/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 7/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.349, test=0.052) total time=   0.8s\n","Best_Hyperparameters: \n"," {'learning_rate': 0.05, 'n_estimators': 100, 'num_leaves': 43}\n","cluster:27 ; total_samples:97344 ; positives:1176 ; negatives:96168\n","Fitting 7 folds for each of 8 candidates, totalling 56 fits\n","[CV 1/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 1/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.663, test=0.101) total time=   1.3s\n","[CV 2/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 2/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.644, test=0.135) total time=   1.3s\n","[CV 3/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 3/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.644, test=0.125) total time=   1.2s\n","[CV 4/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 4/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.638, test=0.097) total time=   1.3s\n","[CV 5/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 5/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.682, test=0.050) total time=   1.3s\n","[CV 6/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 6/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.669, test=0.121) total time=   1.3s\n","[CV 7/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 7/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.647, test=0.000) total time=   1.2s\n","[CV 1/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 1/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.407, test=0.129) total time=   1.0s\n","[CV 2/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 2/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.387, test=0.161) total time=   1.0s\n","[CV 3/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 3/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.376, test=0.134) total time=   1.0s\n","[CV 4/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 4/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.381, test=0.110) total time=   0.9s\n","[CV 5/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 5/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.364, test=0.080) total time=   1.1s\n","[CV 6/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 6/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.372, test=0.086) total time=   1.0s\n","[CV 7/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 7/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.374, test=0.000) total time=   1.0s\n","[CV 1/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 1/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.815, test=0.098) total time=   1.5s\n","[CV 2/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 2/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.829, test=0.118) total time=   1.5s\n","[CV 3/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 3/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.840, test=0.121) total time=   1.5s\n","[CV 4/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 4/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.844, test=0.101) total time=   1.8s\n","[CV 5/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 5/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.841, test=0.062) total time=   1.5s\n","[CV 6/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 6/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.820, test=0.112) total time=   1.5s\n","[CV 7/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 7/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.849, test=0.000) total time=   1.5s\n","[CV 1/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 1/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.159, test=0.128) total time=   0.5s\n","[CV 2/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 2/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.132, test=0.071) total time=   0.5s\n","[CV 3/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 3/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.075, test=0.036) total time=   0.4s\n","[CV 4/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 4/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.150, test=0.028) total time=   0.4s\n","[CV 5/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 5/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.063, test=0.017) total time=   0.4s\n","[CV 6/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 6/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.059, test=0.023) total time=   0.4s\n","[CV 7/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 7/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.049, test=0.000) total time=   0.5s\n","[CV 1/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 1/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.158, test=0.138) total time=   0.4s\n","[CV 2/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 2/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.147, test=0.099) total time=   0.5s\n","[CV 3/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 3/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.084, test=0.029) total time=   0.4s\n","[CV 4/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 4/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.152, test=0.020) total time=   0.5s\n","[CV 5/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 5/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.055, test=0.000) total time=   0.4s\n","[CV 6/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 6/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.051, test=0.023) total time=   0.4s\n","[CV 7/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 7/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.045, test=0.000) total time=   0.5s\n","[CV 1/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 1/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.631, test=0.111) total time=   1.5s\n","[CV 2/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 2/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.650, test=0.137) total time=   1.5s\n","[CV 3/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 3/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.624, test=0.128) total time=   1.5s\n","[CV 4/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 4/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.627, test=0.097) total time=   1.5s\n","[CV 5/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 5/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.642, test=0.054) total time=   1.5s\n","[CV 6/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 6/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.634, test=0.135) total time=   1.5s\n","[CV 7/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 7/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.602, test=0.000) total time=   1.5s\n","[CV 1/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 1/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.390, test=0.132) total time=   1.0s\n","[CV 2/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 2/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.372, test=0.132) total time=   1.1s\n","[CV 3/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 3/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.391, test=0.118) total time=   1.1s\n","[CV 4/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 4/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.390, test=0.111) total time=   1.1s\n","[CV 5/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 5/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.386, test=0.076) total time=   1.1s\n","[CV 6/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 6/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.391, test=0.172) total time=   1.1s\n","[CV 7/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 7/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.385, test=0.000) total time=   1.1s\n","[CV 1/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 1/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.303, test=0.145) total time=   0.8s\n","[CV 2/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 2/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.280, test=0.171) total time=   0.7s\n","[CV 3/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 3/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.288, test=0.149) total time=   0.7s\n","[CV 4/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 4/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.302, test=0.106) total time=   0.8s\n","[CV 5/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 5/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.310, test=0.098) total time=   0.7s\n","[CV 6/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 6/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.290, test=0.150) total time=   0.7s\n","[CV 7/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 7/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.291, test=0.000) total time=   0.8s\n","Best_Hyperparameters: \n"," {'learning_rate': 0.1, 'n_estimators': 75, 'num_leaves': 26}\n","cluster:28 ; total_samples:97344 ; positives:2658 ; negatives:94686\n","Fitting 7 folds for each of 8 candidates, totalling 56 fits\n","[CV 1/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 1/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.587, test=0.300) total time=   1.4s\n","[CV 2/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 2/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.579, test=0.320) total time=   1.3s\n","[CV 3/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 3/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.589, test=0.317) total time=   1.4s\n","[CV 4/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 4/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.591, test=0.333) total time=   1.3s\n","[CV 5/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 5/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.590, test=0.342) total time=   1.4s\n","[CV 6/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 6/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.596, test=0.332) total time=   1.3s\n","[CV 7/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 7/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.587, test=0.262) total time=   1.3s\n","[CV 1/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 1/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.427, test=0.339) total time=   1.0s\n","[CV 2/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 2/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.438, test=0.313) total time=   1.1s\n","[CV 3/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 3/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.428, test=0.361) total time=   1.1s\n","[CV 4/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 4/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.425, test=0.347) total time=   1.1s\n","[CV 5/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 5/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.431, test=0.340) total time=   1.0s\n","[CV 6/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 6/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.428, test=0.355) total time=   1.1s\n","[CV 7/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 7/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.423, test=0.299) total time=   1.1s\n","[CV 1/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 1/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.711, test=0.173) total time=   1.4s\n","[CV 2/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 2/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.714, test=0.298) total time=   1.4s\n","[CV 3/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 3/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.726, test=0.294) total time=   1.6s\n","[CV 4/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 4/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.715, test=0.322) total time=   1.6s\n","[CV 5/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 5/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.732, test=0.320) total time=   1.6s\n","[CV 6/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 6/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.723, test=0.337) total time=   1.5s\n","[CV 7/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 7/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.708, test=0.240) total time=   1.5s\n","[CV 1/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 1/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.285, test=0.318) total time=   0.5s\n","[CV 2/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 2/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.291, test=0.257) total time=   0.4s\n","[CV 3/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 3/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.287, test=0.310) total time=   0.5s\n","[CV 4/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 4/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.293, test=0.257) total time=   0.5s\n","[CV 5/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 5/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.291, test=0.276) total time=   0.5s\n","[CV 6/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 6/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.294, test=0.321) total time=   0.5s\n","[CV 7/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 7/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.295, test=0.250) total time=   0.5s\n","[CV 1/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 1/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.284, test=0.316) total time=   0.5s\n","[CV 2/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 2/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.291, test=0.257) total time=   0.5s\n","[CV 3/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 3/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.286, test=0.310) total time=   0.4s\n","[CV 4/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 4/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.293, test=0.257) total time=   0.5s\n","[CV 5/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 5/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.289, test=0.278) total time=   0.5s\n","[CV 6/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 6/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.293, test=0.318) total time=   0.4s\n","[CV 7/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 7/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.294, test=0.251) total time=   0.5s\n","[CV 1/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 1/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.569, test=0.293) total time=   1.5s\n","[CV 2/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 2/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.576, test=0.316) total time=   1.5s\n","[CV 3/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 3/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.572, test=0.364) total time=   1.6s\n","[CV 4/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 4/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.567, test=0.330) total time=   1.5s\n","[CV 5/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 5/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.576, test=0.338) total time=   1.6s\n","[CV 6/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 6/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.575, test=0.343) total time=   1.6s\n","[CV 7/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 7/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.568, test=0.293) total time=   1.5s\n","[CV 1/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 1/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.449, test=0.297) total time=   1.1s\n","[CV 2/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 2/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.457, test=0.330) total time=   1.2s\n","[CV 3/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 3/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.446, test=0.350) total time=   1.1s\n","[CV 4/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 4/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.449, test=0.333) total time=   1.1s\n","[CV 5/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 5/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.451, test=0.334) total time=   1.1s\n","[CV 6/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 6/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.449, test=0.370) total time=   1.1s\n","[CV 7/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 7/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.457, test=0.289) total time=   1.1s\n","[CV 1/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 1/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.408, test=0.359) total time=   0.8s\n","[CV 2/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 2/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.410, test=0.323) total time=   0.8s\n","[CV 3/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 3/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.410, test=0.346) total time=   0.8s\n","[CV 4/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 4/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.403, test=0.323) total time=   0.8s\n","[CV 5/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 5/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.401, test=0.324) total time=   0.8s\n","[CV 6/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 6/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.408, test=0.368) total time=   0.8s\n","[CV 7/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 7/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.412, test=0.299) total time=   0.7s\n","Best_Hyperparameters: \n"," {'learning_rate': 0.05, 'n_estimators': 100, 'num_leaves': 43}\n","cluster:25 ; total_samples:95035 ; positives:612 ; negatives:94423\n","Fitting 7 folds for each of 8 candidates, totalling 56 fits\n","[CV 1/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 1/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.767, test=0.039) total time=   1.3s\n","[CV 2/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 2/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.797, test=0.020) total time=   1.3s\n","[CV 3/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 3/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.793, test=0.051) total time=   1.4s\n","[CV 4/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 4/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.824, test=0.020) total time=   1.4s\n","[CV 5/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 5/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.767, test=0.048) total time=   1.3s\n","[CV 6/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 6/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.769, test=0.075) total time=   1.3s\n","[CV 7/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 7/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.768, test=0.084) total time=   1.3s\n","[CV 1/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 1/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.407, test=0.046) total time=   1.0s\n","[CV 2/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 2/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.465, test=0.081) total time=   0.9s\n","[CV 3/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 3/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.443, test=0.068) total time=   0.9s\n","[CV 4/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 4/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.468, test=0.056) total time=   0.9s\n","[CV 5/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 5/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.415, test=0.048) total time=   0.9s\n","[CV 6/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 6/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.380, test=0.082) total time=   0.9s\n","[CV 7/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 7/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.398, test=0.063) total time=   0.9s\n","[CV 1/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 1/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.940, test=0.045) total time=   1.5s\n","[CV 2/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 2/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.952, test=0.019) total time=   1.5s\n","[CV 3/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 3/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.942, test=0.042) total time=   1.6s\n","[CV 4/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 4/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.928, test=0.055) total time=   1.5s\n","[CV 5/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 5/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.924, test=0.031) total time=   1.6s\n","[CV 6/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 6/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.929, test=0.051) total time=   1.5s\n","[CV 7/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 7/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.933, test=0.039) total time=   1.5s\n","[CV 1/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 1/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.224, test=0.044) total time=   0.4s\n","[CV 2/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 2/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.210, test=0.072) total time=   0.4s\n","[CV 3/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 3/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.211, test=0.056) total time=   0.4s\n","[CV 4/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 4/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.191, test=0.114) total time=   0.4s\n","[CV 5/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 5/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.214, test=0.054) total time=   0.4s\n","[CV 6/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 6/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.212, test=0.070) total time=   0.4s\n","[CV 7/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 7/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.190, test=0.088) total time=   0.4s\n","[CV 1/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 1/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.212, test=0.045) total time=   0.4s\n","[CV 2/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 2/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.208, test=0.078) total time=   0.4s\n","[CV 3/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 3/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.204, test=0.037) total time=   0.4s\n","[CV 4/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 4/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.178, test=0.084) total time=   0.4s\n","[CV 5/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 5/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.206, test=0.056) total time=   0.4s\n","[CV 6/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 6/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.228, test=0.078) total time=   0.4s\n","[CV 7/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 7/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.181, test=0.088) total time=   0.4s\n","[CV 1/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 1/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.753, test=0.041) total time=   1.4s\n","[CV 2/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 2/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.750, test=0.000) total time=   1.5s\n","[CV 3/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 3/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.741, test=0.055) total time=   1.4s\n","[CV 4/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 4/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.753, test=0.040) total time=   1.5s\n","[CV 5/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 5/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.714, test=0.056) total time=   1.4s\n","[CV 6/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 6/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.744, test=0.056) total time=   1.4s\n","[CV 7/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 7/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.737, test=0.062) total time=   1.5s\n","[CV 1/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 1/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.427, test=0.036) total time=   2.3s\n","[CV 2/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 2/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.546, test=0.000) total time=   1.1s\n","[CV 3/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 3/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.479, test=0.070) total time=   1.1s\n","[CV 4/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 4/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.473, test=0.022) total time=   1.1s\n","[CV 5/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 5/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.474, test=0.054) total time=   1.1s\n","[CV 6/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 6/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.464, test=0.091) total time=   1.2s\n","[CV 7/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 7/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.456, test=0.054) total time=   1.1s\n","[CV 1/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 1/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.336, test=0.041) total time=   0.7s\n","[CV 2/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 2/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.367, test=0.050) total time=   0.8s\n","[CV 3/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 3/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.270, test=0.073) total time=   0.7s\n","[CV 4/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 4/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.336, test=0.087) total time=   0.7s\n","[CV 5/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 5/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.344, test=0.061) total time=   0.8s\n","[CV 6/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 6/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.318, test=0.070) total time=   0.7s\n","[CV 7/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 7/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.326, test=0.047) total time=   0.8s\n","Best_Hyperparameters: \n"," {'learning_rate': 0.05, 'n_estimators': 20, 'num_leaves': 62}\n","cluster:14 ; total_samples:78338 ; positives:1374 ; negatives:76964\n","Fitting 7 folds for each of 8 candidates, totalling 56 fits\n","[CV 1/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 1/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.736, test=0.000) total time=   1.1s\n","[CV 2/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 2/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.723, test=0.143) total time=   1.1s\n","[CV 3/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 3/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.720, test=0.175) total time=   1.1s\n","[CV 4/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 4/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.721, test=0.191) total time=   1.1s\n","[CV 5/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 5/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.707, test=0.124) total time=   1.0s\n","[CV 6/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 6/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.687, test=0.017) total time=   1.0s\n","[CV 7/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 7/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.693, test=0.152) total time=   1.1s\n","[CV 1/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 1/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.412, test=0.000) total time=   0.8s\n","[CV 2/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 2/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.406, test=0.170) total time=   0.8s\n","[CV 3/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 3/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.376, test=0.188) total time=   0.9s\n","[CV 4/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 4/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.383, test=0.225) total time=   0.9s\n","[CV 5/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 5/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.367, test=0.204) total time=   0.8s\n","[CV 6/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 6/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.401, test=0.130) total time=   0.8s\n","[CV 7/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 7/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.404, test=0.168) total time=   0.8s\n","[CV 1/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 1/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.898, test=0.000) total time=   1.2s\n","[CV 2/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 2/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.876, test=0.119) total time=   1.8s\n","[CV 3/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 3/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.895, test=0.161) total time=   1.6s\n","[CV 4/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 4/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.891, test=0.206) total time=   2.5s\n","[CV 5/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 5/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.888, test=0.107) total time=   3.0s\n","[CV 6/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 6/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.882, test=0.040) total time=   2.6s\n","[CV 7/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 7/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.893, test=0.121) total time=   1.2s\n","[CV 1/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 1/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.015, test=0.000) total time=   0.4s\n","[CV 2/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 2/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.028, test=0.000) total time=   0.4s\n","[CV 3/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 3/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.030, test=0.000) total time=   0.4s\n","[CV 4/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 4/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.017, test=0.000) total time=   0.4s\n","[CV 5/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 5/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.017, test=0.020) total time=   0.4s\n","[CV 6/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 6/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.050, test=0.000) total time=   0.4s\n","[CV 7/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 7/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.063, test=0.170) total time=   0.4s\n","[CV 1/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 1/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.018, test=0.000) total time=   0.4s\n","[CV 2/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 2/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.027, test=0.000) total time=   0.4s\n","[CV 3/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 3/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.030, test=0.000) total time=   0.4s\n","[CV 4/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 4/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.005, test=0.000) total time=   0.4s\n","[CV 5/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 5/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.015, test=0.000) total time=   0.4s\n","[CV 6/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 6/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.044, test=0.010) total time=   0.4s\n","[CV 7/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 7/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.047, test=0.160) total time=   0.4s\n","[CV 1/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 1/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.706, test=0.000) total time=   1.3s\n","[CV 2/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 2/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.697, test=0.139) total time=   1.3s\n","[CV 3/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 3/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.709, test=0.174) total time=   1.2s\n","[CV 4/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 4/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.718, test=0.204) total time=   1.3s\n","[CV 5/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 5/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.693, test=0.155) total time=   1.3s\n","[CV 6/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 6/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.688, test=0.071) total time=   1.2s\n","[CV 7/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 7/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.694, test=0.167) total time=   1.2s\n","[CV 1/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 1/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.417, test=0.000) total time=   0.9s\n","[CV 2/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 2/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.441, test=0.159) total time=   0.8s\n","[CV 3/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 3/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.423, test=0.173) total time=   0.9s\n","[CV 4/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 4/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.427, test=0.182) total time=   0.9s\n","[CV 5/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 5/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.416, test=0.189) total time=   0.9s\n","[CV 6/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 6/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.422, test=0.123) total time=   0.9s\n","[CV 7/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 7/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.431, test=0.149) total time=   0.8s\n","[CV 1/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 1/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.331, test=0.000) total time=   0.6s\n","[CV 2/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 2/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.348, test=0.161) total time=   0.6s\n","[CV 3/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 3/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.336, test=0.191) total time=   0.6s\n","[CV 4/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 4/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.334, test=0.203) total time=   0.6s\n","[CV 5/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 5/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.335, test=0.211) total time=   0.6s\n","[CV 6/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 6/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.344, test=0.160) total time=   0.6s\n","[CV 7/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 7/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.344, test=0.160) total time=   0.6s\n","Best_Hyperparameters: \n"," {'learning_rate': 0.05, 'n_estimators': 100, 'num_leaves': 43}\n","cluster:30 ; total_samples:77183 ; positives:867 ; negatives:76316\n","Fitting 7 folds for each of 8 candidates, totalling 56 fits\n","[CV 1/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 1/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.772, test=0.000) total time=   1.0s\n","[CV 2/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 2/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.799, test=0.048) total time=   1.1s\n","[CV 3/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 3/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.757, test=0.063) total time=   1.1s\n","[CV 4/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 4/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.772, test=0.028) total time=   1.0s\n","[CV 5/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 5/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.762, test=0.056) total time=   1.0s\n","[CV 6/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 6/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.755, test=0.059) total time=   1.0s\n","[CV 7/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 7/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.730, test=0.012) total time=   1.1s\n","[CV 1/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 1/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.375, test=0.000) total time=   0.8s\n","[CV 2/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 2/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.373, test=0.087) total time=   0.8s\n","[CV 3/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 3/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.339, test=0.099) total time=   0.8s\n","[CV 4/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 4/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.369, test=0.021) total time=   0.8s\n","[CV 5/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 5/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.385, test=0.080) total time=   0.8s\n","[CV 6/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 6/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.397, test=0.086) total time=   0.8s\n","[CV 7/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 7/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.380, test=0.027) total time=   0.8s\n","[CV 1/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 1/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.936, test=0.000) total time=   1.3s\n","[CV 2/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 2/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.935, test=0.033) total time=   1.4s\n","[CV 3/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 3/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.936, test=0.065) total time=   1.3s\n","[CV 4/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 4/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.939, test=0.010) total time=   1.3s\n","[CV 5/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 5/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.932, test=0.035) total time=   1.2s\n","[CV 6/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 6/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.943, test=0.046) total time=   1.2s\n","[CV 7/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 7/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.921, test=0.041) total time=   1.4s\n","[CV 1/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 1/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.097, test=0.000) total time=   0.4s\n","[CV 2/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 2/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.147, test=0.047) total time=   0.4s\n","[CV 3/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 3/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.105, test=0.027) total time=   0.4s\n","[CV 4/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 4/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.131, test=0.000) total time=   0.4s\n","[CV 5/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 5/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.103, test=0.030) total time=   0.4s\n","[CV 6/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 6/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.090, test=0.026) total time=   0.4s\n","[CV 7/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 7/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.124, test=0.051) total time=   0.4s\n","[CV 1/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 1/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.102, test=0.000) total time=   0.4s\n","[CV 2/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 2/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.150, test=0.058) total time=   0.4s\n","[CV 3/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 3/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.094, test=0.013) total time=   0.4s\n","[CV 4/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 4/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.127, test=0.000) total time=   0.4s\n","[CV 5/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 5/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.099, test=0.043) total time=   0.4s\n","[CV 6/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 6/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.102, test=0.026) total time=   0.4s\n","[CV 7/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 7/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.132, test=0.065) total time=   0.4s\n","[CV 1/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 1/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.752, test=0.000) total time=   1.3s\n","[CV 2/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 2/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.787, test=0.032) total time=   1.2s\n","[CV 3/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 3/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.754, test=0.094) total time=   1.2s\n","[CV 4/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 4/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.749, test=0.021) total time=   1.3s\n","[CV 5/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 5/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.725, test=0.068) total time=   1.3s\n","[CV 6/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 6/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.737, test=0.039) total time=   1.3s\n","[CV 7/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 7/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.744, test=0.000) total time=   1.3s\n","[CV 1/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 1/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.405, test=0.000) total time=   0.9s\n","[CV 2/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 2/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.392, test=0.080) total time=   0.9s\n","[CV 3/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 3/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.385, test=0.088) total time=   0.8s\n","[CV 4/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 4/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.401, test=0.027) total time=   0.8s\n","[CV 5/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 5/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.421, test=0.092) total time=   0.9s\n","[CV 6/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 6/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.440, test=0.064) total time=   0.9s\n","[CV 7/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 7/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.404, test=0.039) total time=   0.9s\n","[CV 1/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 1/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.274, test=0.000) total time=   0.6s\n","[CV 2/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 2/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.292, test=0.086) total time=   0.6s\n","[CV 3/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 3/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.286, test=0.085) total time=   0.6s\n","[CV 4/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 4/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.282, test=0.024) total time=   0.6s\n","[CV 5/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 5/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.309, test=0.078) total time=   0.6s\n","[CV 6/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 6/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.306, test=0.061) total time=   0.6s\n","[CV 7/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 7/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.279, test=0.071) total time=   0.6s\n","Best_Hyperparameters: \n"," {'learning_rate': 0.1, 'n_estimators': 75, 'num_leaves': 26}\n","cluster:1 ; total_samples:58179 ; positives:546 ; negatives:57633\n","Fitting 7 folds for each of 8 candidates, totalling 56 fits\n","[CV 1/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 1/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.864, test=0.000) total time=   0.7s\n","[CV 2/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 2/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.902, test=0.095) total time=   0.7s\n","[CV 3/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 3/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.859, test=0.051) total time=   0.6s\n","[CV 4/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 4/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.878, test=0.081) total time=   0.7s\n","[CV 5/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 5/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.878, test=0.029) total time=   0.8s\n","[CV 6/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 6/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.903, test=0.102) total time=   0.7s\n","[CV 7/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 7/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.884, test=0.060) total time=   0.7s\n","[CV 1/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 1/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.585, test=0.000) total time=   0.5s\n","[CV 2/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 2/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.623, test=0.099) total time=   0.5s\n","[CV 3/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 3/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.550, test=0.046) total time=   0.5s\n","[CV 4/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 4/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.569, test=0.077) total time=   0.5s\n","[CV 5/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 5/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.575, test=0.064) total time=   0.5s\n","[CV 6/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 6/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.584, test=0.099) total time=   0.6s\n","[CV 7/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 7/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.554, test=0.078) total time=   0.5s\n","[CV 1/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 1/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.982, test=0.000) total time=   0.8s\n","[CV 2/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 2/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.983, test=0.063) total time=   0.9s\n","[CV 3/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 3/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.989, test=0.061) total time=   0.9s\n","[CV 4/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 4/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.971, test=0.074) total time=   0.9s\n","[CV 5/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 5/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.984, test=0.034) total time=   0.9s\n","[CV 6/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 6/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.982, test=0.027) total time=   0.9s\n","[CV 7/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 7/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.987, test=0.040) total time=   1.0s\n","[CV 1/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 1/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.237, test=0.000) total time=   0.3s\n","[CV 2/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 2/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.175, test=0.092) total time=   0.2s\n","[CV 3/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 3/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.162, test=0.043) total time=   0.3s\n","[CV 4/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 4/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.221, test=0.037) total time=   0.2s\n","[CV 5/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 5/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.251, test=0.020) total time=   0.3s\n","[CV 6/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 6/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.205, test=0.038) total time=   0.2s\n","[CV 7/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 7/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.201, test=0.047) total time=   0.3s\n","[CV 1/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 1/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.180, test=0.000) total time=   0.3s\n","[CV 2/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 2/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.142, test=0.092) total time=   0.2s\n","[CV 3/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 3/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.152, test=0.026) total time=   0.2s\n","[CV 4/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 4/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.198, test=0.049) total time=   0.3s\n","[CV 5/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 5/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.242, test=0.000) total time=   0.2s\n","[CV 6/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 6/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.211, test=0.072) total time=   0.2s\n","[CV 7/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 7/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.217, test=0.050) total time=   0.3s\n","[CV 1/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 1/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.827, test=0.000) total time=   1.0s\n","[CV 2/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 2/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.836, test=0.101) total time=   0.9s\n","[CV 3/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 3/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.810, test=0.047) total time=   1.0s\n","[CV 4/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 4/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.845, test=0.072) total time=   0.8s\n","[CV 5/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 5/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.873, test=0.067) total time=   0.8s\n","[CV 6/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 6/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.840, test=0.094) total time=   0.8s\n","[CV 7/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 7/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.862, test=0.050) total time=   0.9s\n","[CV 1/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 1/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.635, test=0.000) total time=   0.5s\n","[CV 2/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 2/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.636, test=0.080) total time=   0.6s\n","[CV 3/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 3/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.579, test=0.040) total time=   0.6s\n","[CV 4/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 4/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.539, test=0.069) total time=   0.5s\n","[CV 5/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 5/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.520, test=0.065) total time=   0.5s\n","[CV 6/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 6/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.595, test=0.084) total time=   0.5s\n","[CV 7/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 7/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.502, test=0.063) total time=   0.6s\n","[CV 1/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 1/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.471, test=0.000) total time=   0.4s\n","[CV 2/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 2/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.491, test=0.094) total time=   0.4s\n","[CV 3/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 3/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.353, test=0.043) total time=   0.4s\n","[CV 4/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 4/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.409, test=0.067) total time=   0.4s\n","[CV 5/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 5/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.384, test=0.082) total time=   0.4s\n","[CV 6/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 6/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.416, test=0.101) total time=   0.4s\n","[CV 7/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 7/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.386, test=0.063) total time=   0.4s\n","Best_Hyperparameters: \n"," {'learning_rate': 0.05, 'n_estimators': 100, 'num_leaves': 43}\n","cluster:34 ; total_samples:58175 ; positives:467 ; negatives:57708\n","Fitting 7 folds for each of 8 candidates, totalling 56 fits\n","[CV 1/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 1/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.897, test=0.000) total time=   0.7s\n","[CV 2/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 2/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.859, test=0.052) total time=   0.7s\n","[CV 3/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 3/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.885, test=0.023) total time=   0.7s\n","[CV 4/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 4/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.894, test=0.049) total time=   0.8s\n","[CV 5/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 5/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.902, test=0.038) total time=   0.7s\n","[CV 6/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 6/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.904, test=0.067) total time=   0.7s\n","[CV 7/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 7/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.897, test=0.031) total time=   0.7s\n","[CV 1/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 1/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.538, test=0.000) total time=   0.5s\n","[CV 2/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 2/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.528, test=0.054) total time=   0.6s\n","[CV 3/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 3/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.525, test=0.051) total time=   0.6s\n","[CV 4/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 4/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.538, test=0.047) total time=   0.6s\n","[CV 5/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 5/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.527, test=0.052) total time=   0.6s\n","[CV 6/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 6/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.544, test=0.071) total time=   0.6s\n","[CV 7/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 7/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.494, test=0.045) total time=   0.5s\n","[CV 1/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 1/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.986, test=0.000) total time=   1.0s\n","[CV 2/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 2/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.991, test=0.034) total time=   0.9s\n","[CV 3/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 3/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.982, test=0.016) total time=   1.0s\n","[CV 4/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 4/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.991, test=0.038) total time=   0.9s\n","[CV 5/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 5/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.993, test=0.061) total time=   0.9s\n","[CV 6/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 6/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.991, test=0.058) total time=   0.9s\n","[CV 7/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 7/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.989, test=0.033) total time=   1.0s\n","[CV 1/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 1/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.169, test=0.000) total time=   0.2s\n","[CV 2/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 2/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.202, test=0.023) total time=   0.2s\n","[CV 3/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 3/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.173, test=0.039) total time=   0.2s\n","[CV 4/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 4/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.215, test=0.024) total time=   0.3s\n","[CV 5/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 5/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.164, test=0.000) total time=   0.2s\n","[CV 6/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 6/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.196, test=0.084) total time=   0.3s\n","[CV 7/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 7/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.193, test=0.061) total time=   0.3s\n","[CV 1/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 1/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.167, test=0.000) total time=   0.2s\n","[CV 2/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 2/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.206, test=0.032) total time=   0.2s\n","[CV 3/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 3/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.170, test=0.031) total time=   0.2s\n","[CV 4/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 4/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.208, test=0.031) total time=   0.3s\n","[CV 5/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 5/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.167, test=0.000) total time=   0.2s\n","[CV 6/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 6/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.196, test=0.084) total time=   0.3s\n","[CV 7/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 7/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.184, test=0.063) total time=   0.3s\n","[CV 1/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 1/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.877, test=0.000) total time=   0.9s\n","[CV 2/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 2/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.833, test=0.037) total time=   0.8s\n","[CV 3/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 3/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.856, test=0.033) total time=   0.8s\n","[CV 4/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 4/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.838, test=0.032) total time=   0.8s\n","[CV 5/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 5/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.866, test=0.053) total time=   0.8s\n","[CV 6/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 6/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.889, test=0.064) total time=   0.8s\n","[CV 7/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 7/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.868, test=0.062) total time=   1.0s\n","[CV 1/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 1/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.531, test=0.000) total time=   0.6s\n","[CV 2/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 2/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.517, test=0.051) total time=   0.6s\n","[CV 3/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 3/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.552, test=0.033) total time=   0.5s\n","[CV 4/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 4/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.589, test=0.042) total time=   0.5s\n","[CV 5/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 5/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.527, test=0.027) total time=   0.6s\n","[CV 6/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 6/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.547, test=0.048) total time=   0.5s\n","[CV 7/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 7/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.545, test=0.032) total time=   0.5s\n","[CV 1/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 1/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.362, test=0.000) total time=   0.4s\n","[CV 2/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 2/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.346, test=0.043) total time=   0.4s\n","[CV 3/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 3/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.337, test=0.030) total time=   0.4s\n","[CV 4/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 4/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.402, test=0.046) total time=   0.4s\n","[CV 5/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 5/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.390, test=0.044) total time=   0.4s\n","[CV 6/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 6/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.363, test=0.058) total time=   0.4s\n","[CV 7/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 7/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.376, test=0.034) total time=   0.4s\n","Best_Hyperparameters: \n"," {'learning_rate': 0.05, 'n_estimators': 100, 'num_leaves': 43}\n","cluster:38 ; total_samples:58175 ; positives:464 ; negatives:57711\n","Fitting 7 folds for each of 8 candidates, totalling 56 fits\n","[CV 1/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 1/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.868, test=0.068) total time=   0.8s\n","[CV 2/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 2/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.895, test=0.059) total time=   0.8s\n","[CV 3/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 3/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.913, test=0.037) total time=   0.7s\n","[CV 4/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 4/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.912, test=0.070) total time=   0.7s\n","[CV 5/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 5/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.918, test=0.056) total time=   0.7s\n","[CV 6/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 6/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.916, test=0.076) total time=   0.7s\n","[CV 7/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 7/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.929, test=0.000) total time=   0.8s\n","[CV 1/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 1/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.540, test=0.075) total time=   0.5s\n","[CV 2/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 2/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.566, test=0.096) total time=   0.5s\n","[CV 3/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 3/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.562, test=0.029) total time=   0.5s\n","[CV 4/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 4/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.627, test=0.050) total time=   0.5s\n","[CV 5/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 5/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.571, test=0.055) total time=   0.5s\n","[CV 6/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 6/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.615, test=0.040) total time=   0.6s\n","[CV 7/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 7/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.596, test=0.000) total time=   0.5s\n","[CV 1/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 1/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.994, test=0.119) total time=   0.9s\n","[CV 2/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 2/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.993, test=0.025) total time=   0.9s\n","[CV 3/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 3/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.994, test=0.045) total time=   1.0s\n","[CV 4/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 4/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.997, test=0.051) total time=   0.9s\n","[CV 5/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 5/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.997, test=0.024) total time=   0.9s\n","[CV 6/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 6/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.996, test=0.061) total time=   1.0s\n","[CV 7/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 7/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.993, test=0.000) total time=   1.0s\n","[CV 1/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 1/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.249, test=0.083) total time=   0.3s\n","[CV 2/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 2/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.245, test=0.075) total time=   0.3s\n","[CV 3/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 3/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.260, test=0.061) total time=   0.3s\n","[CV 4/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 4/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.250, test=0.012) total time=   0.3s\n","[CV 5/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 5/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.270, test=0.054) total time=   0.3s\n","[CV 6/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 6/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.229, test=0.056) total time=   0.3s\n","[CV 7/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 7/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.248, test=0.000) total time=   0.3s\n","[CV 1/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 1/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.233, test=0.047) total time=   0.2s\n","[CV 2/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 2/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.204, test=0.043) total time=   0.2s\n","[CV 3/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 3/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.254, test=0.049) total time=   0.2s\n","[CV 4/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 4/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.221, test=0.014) total time=   0.3s\n","[CV 5/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 5/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.259, test=0.068) total time=   0.3s\n","[CV 6/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 6/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.219, test=0.058) total time=   0.3s\n","[CV 7/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 7/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.243, test=0.000) total time=   0.3s\n","[CV 1/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 1/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.877, test=0.080) total time=   0.8s\n","[CV 2/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 2/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.895, test=0.067) total time=   0.9s\n","[CV 3/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 3/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.869, test=0.020) total time=   0.9s\n","[CV 4/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 4/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.862, test=0.062) total time=   0.8s\n","[CV 5/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 5/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.857, test=0.039) total time=   0.9s\n","[CV 6/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 6/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.881, test=0.055) total time=   0.8s\n","[CV 7/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 7/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.871, test=0.000) total time=   0.8s\n","[CV 1/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 1/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.557, test=0.115) total time=   0.5s\n","[CV 2/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 2/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.605, test=0.073) total time=   0.5s\n","[CV 3/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 3/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.557, test=0.027) total time=   0.5s\n","[CV 4/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 4/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.632, test=0.057) total time=   0.5s\n","[CV 5/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 5/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.561, test=0.067) total time=   0.5s\n","[CV 6/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 6/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.626, test=0.087) total time=   0.6s\n","[CV 7/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 7/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.633, test=0.000) total time=   0.6s\n","[CV 1/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 1/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.395, test=0.093) total time=   0.4s\n","[CV 2/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 2/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.406, test=0.062) total time=   0.4s\n","[CV 3/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 3/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.427, test=0.015) total time=   0.4s\n","[CV 4/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 4/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.472, test=0.050) total time=   0.4s\n","[CV 5/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 5/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.434, test=0.077) total time=   0.4s\n","[CV 6/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 6/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.436, test=0.070) total time=   0.4s\n","[CV 7/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 7/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.433, test=0.000) total time=   0.4s\n","Best_Hyperparameters: \n"," {'learning_rate': 0.1, 'n_estimators': 150, 'num_leaves': 20}\n","cluster:36 ; total_samples:58175 ; positives:381 ; negatives:57794\n","Fitting 7 folds for each of 8 candidates, totalling 56 fits\n","[CV 1/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 1/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.886, test=0.000) total time=   0.8s\n","[CV 2/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 2/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.893, test=0.000) total time=   0.7s\n","[CV 3/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 3/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.888, test=0.034) total time=   0.7s\n","[CV 4/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 4/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.909, test=0.027) total time=   0.7s\n","[CV 5/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 5/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.891, test=0.044) total time=   0.7s\n","[CV 6/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 6/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.898, test=0.048) total time=   0.7s\n","[CV 7/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 7/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.873, test=0.053) total time=   0.8s\n","[CV 1/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 1/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.506, test=0.000) total time=   0.6s\n","[CV 2/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 2/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.502, test=0.042) total time=   0.5s\n","[CV 3/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 3/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.535, test=0.039) total time=   0.5s\n","[CV 4/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 4/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.574, test=0.046) total time=   0.6s\n","[CV 5/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 5/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.613, test=0.054) total time=   0.6s\n","[CV 6/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 6/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.545, test=0.073) total time=   0.5s\n","[CV 7/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 7/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.523, test=0.087) total time=   0.6s\n","[CV 1/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 1/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.991, test=0.036) total time=   0.9s\n","[CV 2/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 2/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.989, test=0.034) total time=   1.0s\n","[CV 3/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 3/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.994, test=0.013) total time=   0.9s\n","[CV 4/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 4/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.973, test=0.031) total time=   0.9s\n","[CV 5/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 5/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.994, test=0.045) total time=   0.9s\n","[CV 6/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 6/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.992, test=0.062) total time=   0.9s\n","[CV 7/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 7/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.992, test=0.059) total time=   0.8s\n","[CV 1/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 1/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.271, test=0.027) total time=   0.3s\n","[CV 2/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 2/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.245, test=0.046) total time=   0.2s\n","[CV 3/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 3/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.276, test=0.038) total time=   0.2s\n","[CV 4/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 4/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.265, test=0.025) total time=   0.3s\n","[CV 5/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 5/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.290, test=0.058) total time=   0.2s\n","[CV 6/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 6/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.247, test=0.075) total time=   0.3s\n","[CV 7/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 7/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.267, test=0.069) total time=   0.3s\n","[CV 1/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 1/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.259, test=0.027) total time=   0.2s\n","[CV 2/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 2/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.245, test=0.050) total time=   0.3s\n","[CV 3/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 3/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.268, test=0.041) total time=   0.3s\n","[CV 4/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 4/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.262, test=0.026) total time=   0.2s\n","[CV 5/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 5/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.281, test=0.064) total time=   0.2s\n","[CV 6/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 6/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.240, test=0.059) total time=   0.3s\n","[CV 7/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 7/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.260, test=0.078) total time=   0.3s\n","[CV 1/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 1/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.870, test=0.000) total time=   0.9s\n","[CV 2/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 2/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.856, test=0.000) total time=   0.8s\n","[CV 3/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 3/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.845, test=0.030) total time=   0.8s\n","[CV 4/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 4/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.881, test=0.028) total time=   0.8s\n","[CV 5/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 5/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.843, test=0.050) total time=   1.1s\n","[CV 6/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 6/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.839, test=0.064) total time=   2.4s\n","[CV 7/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 7/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.837, test=0.051) total time=   0.8s\n","[CV 1/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 1/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.601, test=0.000) total time=   0.5s\n","[CV 2/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 2/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.617, test=0.026) total time=   0.6s\n","[CV 3/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 3/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.554, test=0.031) total time=   0.5s\n","[CV 4/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 4/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.664, test=0.019) total time=   0.6s\n","[CV 5/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 5/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.589, test=0.059) total time=   0.6s\n","[CV 6/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 6/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.557, test=0.053) total time=   0.6s\n","[CV 7/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 7/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.598, test=0.038) total time=   0.5s\n","[CV 1/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 1/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.381, test=0.052) total time=   0.4s\n","[CV 2/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 2/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.441, test=0.035) total time=   0.4s\n","[CV 3/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 3/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.434, test=0.018) total time=   0.4s\n","[CV 4/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 4/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.494, test=0.029) total time=   0.4s\n","[CV 5/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 5/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.458, test=0.058) total time=   0.4s\n","[CV 6/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 6/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.438, test=0.070) total time=   0.4s\n","[CV 7/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 7/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.429, test=0.046) total time=   0.4s\n","Best_Hyperparameters: \n"," {'learning_rate': 0.05, 'n_estimators': 20, 'num_leaves': 59}\n","cluster:35 ; total_samples:58175 ; positives:558 ; negatives:57617\n","Fitting 7 folds for each of 8 candidates, totalling 56 fits\n","[CV 1/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 1/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.910, test=0.000) total time=   0.7s\n","[CV 2/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 2/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.901, test=0.000) total time=   0.7s\n","[CV 3/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 3/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.856, test=0.074) total time=   0.8s\n","[CV 4/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 4/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.868, test=0.072) total time=   0.7s\n","[CV 5/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 5/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.879, test=0.071) total time=   0.6s\n","[CV 6/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 6/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.903, test=0.018) total time=   0.7s\n","[CV 7/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 7/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.900, test=0.033) total time=   0.7s\n","[CV 1/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 1/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.630, test=0.000) total time=   0.5s\n","[CV 2/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 2/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.586, test=0.000) total time=   0.5s\n","[CV 3/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 3/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.596, test=0.080) total time=   0.5s\n","[CV 4/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 4/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.602, test=0.097) total time=   0.5s\n","[CV 5/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 5/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.603, test=0.049) total time=   0.5s\n","[CV 6/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 6/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.620, test=0.018) total time=   0.5s\n","[CV 7/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 7/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.665, test=0.065) total time=   0.5s\n","[CV 1/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 1/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.987, test=0.000) total time=   0.8s\n","[CV 2/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 2/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.983, test=0.022) total time=   1.0s\n","[CV 3/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 3/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.982, test=0.055) total time=   0.9s\n","[CV 4/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 4/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.988, test=0.082) total time=   0.8s\n","[CV 5/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 5/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.989, test=0.038) total time=   0.9s\n","[CV 6/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 6/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.993, test=0.000) total time=   0.8s\n","[CV 7/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 7/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.991, test=0.061) total time=   1.0s\n","[CV 1/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 1/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.203, test=0.000) total time=   0.3s\n","[CV 2/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 2/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.261, test=0.000) total time=   0.3s\n","[CV 3/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 3/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.255, test=0.056) total time=   0.2s\n","[CV 4/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 4/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.251, test=0.052) total time=   0.2s\n","[CV 5/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 5/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.283, test=0.028) total time=   0.2s\n","[CV 6/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 6/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.237, test=0.000) total time=   0.2s\n","[CV 7/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 7/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.236, test=0.028) total time=   0.2s\n","[CV 1/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 1/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.171, test=0.000) total time=   0.2s\n","[CV 2/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 2/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.266, test=0.000) total time=   0.2s\n","[CV 3/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 3/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.227, test=0.041) total time=   0.3s\n","[CV 4/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 4/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.245, test=0.067) total time=   0.2s\n","[CV 5/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 5/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.256, test=0.056) total time=   0.2s\n","[CV 6/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 6/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.233, test=0.021) total time=   0.3s\n","[CV 7/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 7/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.205, test=0.047) total time=   0.2s\n","[CV 1/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 1/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.915, test=0.000) total time=   0.9s\n","[CV 2/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 2/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.886, test=0.000) total time=   0.9s\n","[CV 3/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 3/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.907, test=0.086) total time=   0.9s\n","[CV 4/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 4/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.855, test=0.069) total time=   0.8s\n","[CV 5/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 5/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.893, test=0.063) total time=   0.7s\n","[CV 6/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 6/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.918, test=0.042) total time=   0.8s\n","[CV 7/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 7/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.876, test=0.035) total time=   0.8s\n","[CV 1/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 1/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.592, test=0.000) total time=   0.5s\n","[CV 2/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 2/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.646, test=0.000) total time=   0.6s\n","[CV 3/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 3/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.624, test=0.064) total time=   0.6s\n","[CV 4/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 4/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.664, test=0.071) total time=   0.6s\n","[CV 5/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 5/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.627, test=0.075) total time=   0.6s\n","[CV 6/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 6/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.647, test=0.053) total time=   0.6s\n","[CV 7/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 7/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.686, test=0.044) total time=   0.6s\n","[CV 1/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 1/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.455, test=0.000) total time=   0.4s\n","[CV 2/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 2/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.474, test=0.054) total time=   0.4s\n","[CV 3/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 3/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.412, test=0.078) total time=   0.4s\n","[CV 4/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 4/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.517, test=0.068) total time=   0.4s\n","[CV 5/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 5/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.476, test=0.039) total time=   0.4s\n","[CV 6/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 6/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.476, test=0.072) total time=   0.4s\n","[CV 7/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 7/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.521, test=0.013) total time=   0.4s\n","Best_Hyperparameters: \n"," {'learning_rate': 0.1, 'n_estimators': 75, 'num_leaves': 26}\n","cluster:29 ; total_samples:58175 ; positives:444 ; negatives:57731\n","Fitting 7 folds for each of 8 candidates, totalling 56 fits\n","[CV 1/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 1/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.950, test=0.000) total time=   0.7s\n","[CV 2/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 2/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.942, test=0.000) total time=   0.7s\n","[CV 3/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 3/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.971, test=0.049) total time=   0.7s\n","[CV 4/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 4/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.962, test=0.072) total time=   0.7s\n","[CV 5/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 5/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.960, test=0.040) total time=   0.8s\n","[CV 6/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 6/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.944, test=0.018) total time=   0.7s\n","[CV 7/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 7/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.951, test=0.000) total time=   0.7s\n","[CV 1/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 1/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.646, test=0.017) total time=   0.5s\n","[CV 2/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 2/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.659, test=0.000) total time=   0.5s\n","[CV 3/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 3/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.715, test=0.060) total time=   0.5s\n","[CV 4/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 4/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.706, test=0.048) total time=   0.5s\n","[CV 5/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 5/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.652, test=0.066) total time=   0.5s\n","[CV 6/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 6/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.664, test=0.030) total time=   0.6s\n","[CV 7/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 7/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.642, test=0.028) total time=   0.5s\n","[CV 1/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 1/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.997, test=0.014) total time=   0.9s\n","[CV 2/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 2/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.996, test=0.000) total time=   0.9s\n","[CV 3/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 3/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.999, test=0.063) total time=   0.9s\n","[CV 4/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 4/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=1.000, test=0.021) total time=   1.0s\n","[CV 5/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 5/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.996, test=0.067) total time=   1.0s\n","[CV 6/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 6/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.997, test=0.039) total time=   0.9s\n","[CV 7/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 7/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.993, test=0.000) total time=   1.0s\n","[CV 1/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 1/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.302, test=0.013) total time=   0.2s\n","[CV 2/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 2/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.311, test=0.000) total time=   0.2s\n","[CV 3/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 3/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.308, test=0.052) total time=   0.2s\n","[CV 4/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 4/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.301, test=0.038) total time=   0.2s\n","[CV 5/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 5/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.277, test=0.122) total time=   0.3s\n","[CV 6/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 6/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.335, test=0.026) total time=   0.3s\n","[CV 7/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 7/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.305, test=0.067) total time=   0.3s\n","[CV 1/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 1/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.288, test=0.014) total time=   0.3s\n","[CV 2/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 2/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.275, test=0.014) total time=   0.3s\n","[CV 3/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 3/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.324, test=0.035) total time=   0.3s\n","[CV 4/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 4/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.282, test=0.069) total time=   0.2s\n","[CV 5/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 5/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.271, test=0.112) total time=   0.2s\n","[CV 6/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 6/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.318, test=0.013) total time=   0.3s\n","[CV 7/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 7/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.308, test=0.070) total time=   0.3s\n","[CV 1/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 1/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.888, test=0.018) total time=   0.9s\n","[CV 2/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 2/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.920, test=0.000) total time=   0.8s\n","[CV 3/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 3/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.914, test=0.051) total time=   0.9s\n","[CV 4/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 4/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.934, test=0.071) total time=   0.8s\n","[CV 5/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 5/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.950, test=0.061) total time=   0.8s\n","[CV 6/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 6/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.875, test=0.031) total time=   0.8s\n","[CV 7/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 7/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.900, test=0.000) total time=   0.9s\n","[CV 1/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 1/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.657, test=0.058) total time=   0.5s\n","[CV 2/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 2/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.685, test=0.000) total time=   0.5s\n","[CV 3/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 3/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.710, test=0.046) total time=   0.6s\n","[CV 4/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 4/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.686, test=0.072) total time=   0.5s\n","[CV 5/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 5/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.673, test=0.088) total time=   0.6s\n","[CV 6/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 6/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.623, test=0.038) total time=   0.5s\n","[CV 7/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 7/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.655, test=0.000) total time=   0.6s\n","[CV 1/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 1/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.519, test=0.049) total time=   0.4s\n","[CV 2/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 2/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.480, test=0.019) total time=   0.4s\n","[CV 3/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 3/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.554, test=0.070) total time=   0.4s\n","[CV 4/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 4/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.522, test=0.058) total time=   0.4s\n","[CV 5/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 5/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.512, test=0.085) total time=   0.4s\n","[CV 6/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 6/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.464, test=0.039) total time=   0.4s\n","[CV 7/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 7/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.496, test=0.000) total time=   0.4s\n","Best_Hyperparameters: \n"," {'learning_rate': 0.05, 'n_estimators': 20, 'num_leaves': 59}\n","cluster:15 ; total_samples:58175 ; positives:799 ; negatives:57376\n","Fitting 7 folds for each of 8 candidates, totalling 56 fits\n","[CV 1/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 1/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.796, test=0.132) total time=   0.7s\n","[CV 2/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 2/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.769, test=0.154) total time=   0.7s\n","[CV 3/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 3/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.797, test=0.127) total time=   0.7s\n","[CV 4/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 4/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.794, test=0.161) total time=   0.7s\n","[CV 5/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 5/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.769, test=0.067) total time=   0.7s\n","[CV 6/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 6/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.755, test=0.124) total time=   0.7s\n","[CV 7/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 7/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.794, test=0.000) total time=   0.7s\n","[CV 1/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 1/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.512, test=0.099) total time=   0.6s\n","[CV 2/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 2/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.490, test=0.162) total time=   0.6s\n","[CV 3/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 3/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.419, test=0.138) total time=   0.5s\n","[CV 4/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 4/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.482, test=0.152) total time=   0.6s\n","[CV 5/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 5/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.466, test=0.108) total time=   0.6s\n","[CV 6/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 6/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.465, test=0.113) total time=   0.5s\n","[CV 7/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 7/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.488, test=0.000) total time=   0.6s\n","[CV 1/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 1/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.924, test=0.133) total time=   0.8s\n","[CV 2/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 2/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.924, test=0.132) total time=   0.8s\n","[CV 3/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 3/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.914, test=0.134) total time=   0.9s\n","[CV 4/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 4/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.936, test=0.127) total time=   0.9s\n","[CV 5/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 5/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.922, test=0.076) total time=   0.8s\n","[CV 6/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 6/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.927, test=0.045) total time=   0.9s\n","[CV 7/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 7/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.935, test=0.000) total time=   0.9s\n","[CV 1/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 1/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.151, test=0.144) total time=   0.3s\n","[CV 2/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 2/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.158, test=0.085) total time=   0.3s\n","[CV 3/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 3/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.174, test=0.041) total time=   0.3s\n","[CV 4/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 4/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.154, test=0.044) total time=   0.3s\n","[CV 5/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 5/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.163, test=0.016) total time=   0.2s\n","[CV 6/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 6/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.187, test=0.000) total time=   0.3s\n","[CV 7/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 7/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.118, test=0.000) total time=   0.3s\n","[CV 1/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 1/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.146, test=0.146) total time=   0.3s\n","[CV 2/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 2/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.156, test=0.085) total time=   0.3s\n","[CV 3/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 3/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.164, test=0.039) total time=   0.3s\n","[CV 4/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 4/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.140, test=0.062) total time=   0.3s\n","[CV 5/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 5/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.140, test=0.000) total time=   0.3s\n","[CV 6/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 6/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.188, test=0.000) total time=   0.3s\n","[CV 7/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 7/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.097, test=0.000) total time=   0.2s\n","[CV 1/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 1/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.730, test=0.117) total time=   0.9s\n","[CV 2/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 2/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.741, test=0.150) total time=   0.9s\n","[CV 3/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 3/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.757, test=0.150) total time=   0.9s\n","[CV 4/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 4/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.782, test=0.154) total time=   0.8s\n","[CV 5/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 5/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.718, test=0.104) total time=   0.8s\n","[CV 6/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 6/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.730, test=0.072) total time=   0.9s\n","[CV 7/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 7/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.793, test=0.000) total time=   0.8s\n","[CV 1/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 1/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.467, test=0.093) total time=   0.6s\n","[CV 2/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 2/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.440, test=0.163) total time=   0.5s\n","[CV 3/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 3/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.468, test=0.141) total time=   0.5s\n","[CV 4/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 4/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.469, test=0.176) total time=   0.5s\n","[CV 5/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 5/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.436, test=0.097) total time=   0.5s\n","[CV 6/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 6/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.444, test=0.128) total time=   0.5s\n","[CV 7/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 7/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.460, test=0.000) total time=   0.6s\n","[CV 1/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 1/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.347, test=0.089) total time=   0.4s\n","[CV 2/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 2/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.353, test=0.178) total time=   0.4s\n","[CV 3/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 3/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.359, test=0.138) total time=   0.4s\n","[CV 4/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 4/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.371, test=0.166) total time=   0.4s\n","[CV 5/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 5/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.348, test=0.116) total time=   0.4s\n","[CV 6/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 6/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.361, test=0.158) total time=   0.4s\n","[CV 7/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 7/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.394, test=0.000) total time=   0.4s\n","Best_Hyperparameters: \n"," {'learning_rate': 0.1, 'n_estimators': 75, 'num_leaves': 26}\n","cluster:17 ; total_samples:58175 ; positives:429 ; negatives:57746\n","Fitting 7 folds for each of 8 candidates, totalling 56 fits\n","[CV 1/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 1/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.908, test=0.031) total time=   0.8s\n","[CV 2/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 2/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.923, test=0.063) total time=   0.8s\n","[CV 3/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 3/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.891, test=0.049) total time=   0.7s\n","[CV 4/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 4/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.846, test=0.074) total time=   0.7s\n","[CV 5/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 5/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.854, test=0.000) total time=   0.8s\n","[CV 6/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 6/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.910, test=0.054) total time=   0.7s\n","[CV 7/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 7/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.883, test=0.000) total time=   0.8s\n","[CV 1/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 1/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.591, test=0.000) total time=   0.5s\n","[CV 2/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 2/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.621, test=0.058) total time=   0.5s\n","[CV 3/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 3/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.561, test=0.076) total time=   0.5s\n","[CV 4/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 4/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.555, test=0.083) total time=   0.6s\n","[CV 5/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 5/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.571, test=0.000) total time=   0.6s\n","[CV 6/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 6/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.607, test=0.052) total time=   0.6s\n","[CV 7/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 7/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.603, test=0.000) total time=   0.5s\n","[CV 1/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 1/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.987, test=0.000) total time=   1.0s\n","[CV 2/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 2/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.992, test=0.067) total time=   1.0s\n","[CV 3/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 3/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.995, test=0.051) total time=   1.0s\n","[CV 4/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 4/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.980, test=0.039) total time=   0.9s\n","[CV 5/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 5/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.989, test=0.000) total time=   0.9s\n","[CV 6/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 6/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.992, test=0.049) total time=   0.9s\n","[CV 7/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 7/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.991, test=0.000) total time=   0.9s\n","[CV 1/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 1/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.217, test=0.088) total time=   0.3s\n","[CV 2/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 2/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.236, test=0.055) total time=   0.3s\n","[CV 3/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 3/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.224, test=0.060) total time=   0.3s\n","[CV 4/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 4/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.224, test=0.070) total time=   0.3s\n","[CV 5/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 5/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.213, test=0.024) total time=   0.2s\n","[CV 6/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 6/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.237, test=0.050) total time=   0.3s\n","[CV 7/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 7/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.193, test=0.032) total time=   0.3s\n","[CV 1/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 1/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.191, test=0.082) total time=   0.3s\n","[CV 2/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 2/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.220, test=0.066) total time=   0.3s\n","[CV 3/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 3/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.225, test=0.043) total time=   0.3s\n","[CV 4/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 4/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.206, test=0.054) total time=   0.3s\n","[CV 5/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 5/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.197, test=0.025) total time=   0.3s\n","[CV 6/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 6/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.225, test=0.052) total time=   0.3s\n","[CV 7/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 7/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.200, test=0.023) total time=   0.3s\n","[CV 1/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 1/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.851, test=0.000) total time=   0.9s\n","[CV 2/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 2/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.845, test=0.069) total time=   0.8s\n","[CV 3/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 3/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.889, test=0.067) total time=   0.8s\n","[CV 4/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 4/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.842, test=0.053) total time=   0.9s\n","[CV 5/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 5/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.880, test=0.000) total time=   0.9s\n","[CV 6/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 6/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.824, test=0.062) total time=   0.9s\n","[CV 7/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 7/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.856, test=0.022) total time=   0.8s\n","[CV 1/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 1/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.598, test=0.032) total time=   0.6s\n","[CV 2/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 2/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.577, test=0.057) total time=   0.6s\n","[CV 3/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 3/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.600, test=0.062) total time=   0.5s\n","[CV 4/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 4/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.517, test=0.073) total time=   0.5s\n","[CV 5/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 5/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.565, test=0.000) total time=   0.5s\n","[CV 6/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 6/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.589, test=0.032) total time=   0.5s\n","[CV 7/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 7/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.574, test=0.047) total time=   0.5s\n","[CV 1/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 1/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.441, test=0.030) total time=   0.4s\n","[CV 2/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 2/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.454, test=0.059) total time=   0.4s\n","[CV 3/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 3/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.427, test=0.049) total time=   0.4s\n","[CV 4/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 4/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.425, test=0.081) total time=   0.4s\n","[CV 5/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 5/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.424, test=0.000) total time=   0.4s\n","[CV 6/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 6/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.414, test=0.050) total time=   0.4s\n","[CV 7/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 7/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.458, test=0.026) total time=   0.4s\n","Best_Hyperparameters: \n"," {'learning_rate': 0.05, 'n_estimators': 20, 'num_leaves': 62}\n","cluster:22 ; total_samples:58175 ; positives:775 ; negatives:57400\n","Fitting 7 folds for each of 8 candidates, totalling 56 fits\n","[CV 1/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 1/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.796, test=0.000) total time=   0.7s\n","[CV 2/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 2/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.854, test=0.047) total time=   0.7s\n","[CV 3/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 3/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.853, test=0.039) total time=   0.7s\n","[CV 4/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 4/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.827, test=0.065) total time=   0.7s\n","[CV 5/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 5/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.816, test=0.028) total time=   0.6s\n","[CV 6/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 6/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.834, test=0.016) total time=   0.7s\n","[CV 7/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 7/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.840, test=0.068) total time=   0.7s\n","[CV 1/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 1/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.461, test=0.000) total time=   0.5s\n","[CV 2/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 2/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.467, test=0.000) total time=   0.6s\n","[CV 3/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 3/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.474, test=0.000) total time=   0.5s\n","[CV 4/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 4/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.486, test=0.073) total time=   0.6s\n","[CV 5/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 5/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.462, test=0.029) total time=   0.5s\n","[CV 6/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 6/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.454, test=0.016) total time=   0.5s\n","[CV 7/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 7/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.484, test=0.058) total time=   0.6s\n","[CV 1/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 1/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.957, test=0.000) total time=   0.9s\n","[CV 2/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 2/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.967, test=0.000) total time=   0.8s\n","[CV 3/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 3/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.959, test=0.030) total time=   0.8s\n","[CV 4/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 4/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.959, test=0.085) total time=   0.9s\n","[CV 5/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 5/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.962, test=0.023) total time=   0.8s\n","[CV 6/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 6/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.969, test=0.000) total time=   0.9s\n","[CV 7/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 7/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.971, test=0.044) total time=   0.8s\n","[CV 1/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 1/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.076, test=0.000) total time=   0.2s\n","[CV 2/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 2/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.054, test=0.000) total time=   0.3s\n","[CV 3/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 3/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.083, test=0.000) total time=   0.3s\n","[CV 4/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 4/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.086, test=0.073) total time=   0.3s\n","[CV 5/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 5/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.059, test=0.032) total time=   0.3s\n","[CV 6/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 6/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.078, test=0.000) total time=   0.3s\n","[CV 7/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 7/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.060, test=0.081) total time=   0.3s\n","[CV 1/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 1/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.077, test=0.000) total time=   0.2s\n","[CV 2/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 2/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.046, test=0.000) total time=   0.2s\n","[CV 3/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 3/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.061, test=0.017) total time=   0.3s\n","[CV 4/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 4/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.078, test=0.085) total time=   0.2s\n","[CV 5/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 5/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.061, test=0.031) total time=   0.2s\n","[CV 6/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 6/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.078, test=0.000) total time=   0.3s\n","[CV 7/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 7/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.049, test=0.076) total time=   0.3s\n","[CV 1/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 1/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.836, test=0.000) total time=   0.9s\n","[CV 2/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 2/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.853, test=0.000) total time=   0.9s\n","[CV 3/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 3/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.829, test=0.051) total time=   0.9s\n","[CV 4/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 4/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.830, test=0.063) total time=   0.9s\n","[CV 5/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 5/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.853, test=0.025) total time=   0.9s\n","[CV 6/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 6/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.851, test=0.000) total time=   0.9s\n","[CV 7/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 7/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.838, test=0.051) total time=   0.9s\n","[CV 1/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 1/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.517, test=0.000) total time=   0.5s\n","[CV 2/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 2/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.539, test=0.000) total time=   0.5s\n","[CV 3/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 3/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.519, test=0.028) total time=   0.5s\n","[CV 4/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 4/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.565, test=0.077) total time=   0.6s\n","[CV 5/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 5/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.523, test=0.038) total time=   0.5s\n","[CV 6/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 6/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.521, test=0.031) total time=   0.5s\n","[CV 7/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 7/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.512, test=0.064) total time=   0.6s\n","[CV 1/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 1/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.393, test=0.000) total time=   0.4s\n","[CV 2/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 2/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.375, test=0.000) total time=   0.4s\n","[CV 3/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 3/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.376, test=0.068) total time=   0.4s\n","[CV 4/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 4/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.376, test=0.069) total time=   0.4s\n","[CV 5/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 5/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.375, test=0.000) total time=   0.4s\n","[CV 6/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 6/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.380, test=0.026) total time=   0.4s\n","[CV 7/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 7/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.330, test=0.061) total time=   0.4s\n","Best_Hyperparameters: \n"," {'learning_rate': 0.1, 'n_estimators': 150, 'num_leaves': 45}\n","cluster:2 ; total_samples:58175 ; positives:448 ; negatives:57727\n","Fitting 7 folds for each of 8 candidates, totalling 56 fits\n","[CV 1/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 1/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.898, test=0.037) total time=   0.7s\n","[CV 2/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 2/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.875, test=0.000) total time=   0.7s\n","[CV 3/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 3/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.928, test=0.052) total time=   0.7s\n","[CV 4/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 4/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.913, test=0.088) total time=   0.6s\n","[CV 5/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 5/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.901, test=0.085) total time=   0.7s\n","[CV 6/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 6/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.922, test=0.083) total time=   0.7s\n","[CV 7/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 7/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.908, test=0.000) total time=   0.7s\n","[CV 1/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 1/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.584, test=0.038) total time=   0.5s\n","[CV 2/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 2/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.560, test=0.030) total time=   0.5s\n","[CV 3/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 3/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.581, test=0.086) total time=   0.5s\n","[CV 4/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 4/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.694, test=0.070) total time=   0.5s\n","[CV 5/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 5/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.633, test=0.096) total time=   0.5s\n","[CV 6/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 6/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.603, test=0.075) total time=   0.5s\n","[CV 7/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 7/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.540, test=0.000) total time=   0.5s\n","[CV 1/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 1/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.991, test=0.046) total time=   0.9s\n","[CV 2/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 2/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.992, test=0.000) total time=   1.0s\n","[CV 3/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 3/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.991, test=0.057) total time=   0.8s\n","[CV 4/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 4/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.992, test=0.074) total time=   1.0s\n","[CV 5/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 5/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.996, test=0.065) total time=   0.8s\n","[CV 6/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 6/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.996, test=0.054) total time=   0.9s\n","[CV 7/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 7/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.992, test=0.000) total time=   0.9s\n","[CV 1/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 1/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.323, test=0.034) total time=   0.2s\n","[CV 2/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 2/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.297, test=0.000) total time=   0.2s\n","[CV 3/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 3/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.262, test=0.048) total time=   0.2s\n","[CV 4/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 4/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.302, test=0.031) total time=   0.3s\n","[CV 5/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 5/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.290, test=0.074) total time=   0.3s\n","[CV 6/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 6/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.270, test=0.044) total time=   0.3s\n","[CV 7/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 7/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.324, test=0.000) total time=   0.2s\n","[CV 1/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 1/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.295, test=0.040) total time=   0.3s\n","[CV 2/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 2/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.287, test=0.000) total time=   0.3s\n","[CV 3/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 3/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.255, test=0.000) total time=   0.2s\n","[CV 4/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 4/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.273, test=0.020) total time=   0.3s\n","[CV 5/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 5/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.267, test=0.075) total time=   0.3s\n","[CV 6/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 6/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.257, test=0.028) total time=   0.3s\n","[CV 7/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 7/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.289, test=0.030) total time=   0.3s\n","[CV 1/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 1/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.870, test=0.041) total time=   0.8s\n","[CV 2/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 2/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.875, test=0.000) total time=   0.9s\n","[CV 3/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 3/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.880, test=0.074) total time=   0.7s\n","[CV 4/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 4/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.899, test=0.074) total time=   0.7s\n","[CV 5/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 5/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.852, test=0.090) total time=   0.8s\n","[CV 6/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 6/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.909, test=0.083) total time=   0.9s\n","[CV 7/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 7/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.837, test=0.000) total time=   0.9s\n","[CV 1/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 1/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.606, test=0.056) total time=   0.6s\n","[CV 2/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 2/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.551, test=0.000) total time=   0.5s\n","[CV 3/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 3/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.605, test=0.083) total time=   0.5s\n","[CV 4/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 4/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.627, test=0.084) total time=   0.5s\n","[CV 5/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 5/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.671, test=0.104) total time=   0.5s\n","[CV 6/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 6/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.569, test=0.090) total time=   0.5s\n","[CV 7/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 7/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.641, test=0.000) total time=   0.6s\n","[CV 1/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 1/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.465, test=0.061) total time=   0.4s\n","[CV 2/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 2/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.460, test=0.025) total time=   0.4s\n","[CV 3/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 3/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.420, test=0.078) total time=   0.4s\n","[CV 4/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 4/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.510, test=0.096) total time=   0.4s\n","[CV 5/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 5/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.471, test=0.094) total time=   0.4s\n","[CV 6/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 6/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.479, test=0.083) total time=   0.4s\n","[CV 7/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 7/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.438, test=0.000) total time=   0.4s\n","Best_Hyperparameters: \n"," {'learning_rate': 0.1, 'n_estimators': 75, 'num_leaves': 26}\n","cluster:39 ; total_samples:58175 ; positives:1181 ; negatives:56994\n","Fitting 7 folds for each of 8 candidates, totalling 56 fits\n","[CV 1/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 1/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.740, test=0.012) total time=   0.7s\n","[CV 2/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 2/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.740, test=0.246) total time=   0.6s\n","[CV 3/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 3/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.741, test=0.131) total time=   0.7s\n","[CV 4/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 4/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.737, test=0.113) total time=   0.7s\n","[CV 5/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 5/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.777, test=0.139) total time=   0.7s\n","[CV 6/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 6/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.749, test=0.122) total time=   0.7s\n","[CV 7/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 7/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.748, test=0.125) total time=   0.7s\n","[CV 1/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 1/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.484, test=0.012) total time=   0.5s\n","[CV 2/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 2/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.488, test=0.230) total time=   0.5s\n","[CV 3/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 3/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.490, test=0.199) total time=   0.5s\n","[CV 4/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 4/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.483, test=0.132) total time=   0.5s\n","[CV 5/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 5/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.501, test=0.218) total time=   0.5s\n","[CV 6/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 6/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.489, test=0.157) total time=   0.5s\n","[CV 7/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 7/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.487, test=0.122) total time=   0.6s\n","[CV 1/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 1/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.889, test=0.012) total time=   0.8s\n","[CV 2/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 2/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.915, test=0.249) total time=   0.9s\n","[CV 3/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 3/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.893, test=0.101) total time=   0.8s\n","[CV 4/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 4/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.896, test=0.120) total time=   0.9s\n","[CV 5/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 5/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.911, test=0.162) total time=   0.9s\n","[CV 6/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 6/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.904, test=0.132) total time=   0.8s\n","[CV 7/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 7/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.909, test=0.148) total time=   0.8s\n","[CV 1/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 1/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.242, test=0.012) total time=   0.2s\n","[CV 2/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 2/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.230, test=0.250) total time=   0.3s\n","[CV 3/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 3/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.250, test=0.172) total time=   0.2s\n","[CV 4/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 4/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.240, test=0.227) total time=   0.3s\n","[CV 5/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 5/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.246, test=0.203) total time=   0.2s\n","[CV 6/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 6/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.246, test=0.167) total time=   0.2s\n","[CV 7/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 7/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.256, test=0.163) total time=   0.2s\n","[CV 1/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 1/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.235, test=0.188) total time=   0.2s\n","[CV 2/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 2/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.235, test=0.243) total time=   0.2s\n","[CV 3/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 3/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.240, test=0.190) total time=   0.2s\n","[CV 4/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 4/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.237, test=0.227) total time=   0.3s\n","[CV 5/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 5/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.244, test=0.203) total time=   0.2s\n","[CV 6/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 6/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.243, test=0.172) total time=   0.2s\n","[CV 7/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 7/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.267, test=0.166) total time=   0.2s\n","[CV 1/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 1/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.721, test=0.012) total time=   0.8s\n","[CV 2/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 2/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.721, test=0.243) total time=   0.8s\n","[CV 3/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 3/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.728, test=0.155) total time=   0.9s\n","[CV 4/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 4/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.724, test=0.127) total time=   0.9s\n","[CV 5/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 5/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.739, test=0.190) total time=   0.9s\n","[CV 6/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 6/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.727, test=0.125) total time=   1.2s\n","[CV 7/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 7/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.731, test=0.154) total time=   0.9s\n","[CV 1/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 1/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.467, test=0.012) total time=   0.5s\n","[CV 2/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 2/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.504, test=0.262) total time=   0.5s\n","[CV 3/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 3/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.481, test=0.172) total time=   0.5s\n","[CV 4/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 4/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.508, test=0.116) total time=   0.5s\n","[CV 5/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 5/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.506, test=0.151) total time=   0.5s\n","[CV 6/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 6/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.495, test=0.127) total time=   0.6s\n","[CV 7/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 7/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.470, test=0.131) total time=   0.6s\n","[CV 1/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 1/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.386, test=0.012) total time=   0.3s\n","[CV 2/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 2/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.404, test=0.284) total time=   0.4s\n","[CV 3/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 3/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.414, test=0.191) total time=   0.4s\n","[CV 4/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 4/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.408, test=0.138) total time=   0.4s\n","[CV 5/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 5/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.416, test=0.186) total time=   0.4s\n","[CV 6/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 6/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.422, test=0.136) total time=   0.4s\n","[CV 7/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 7/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.397, test=0.131) total time=   0.4s\n","Best_Hyperparameters: \n"," {'learning_rate': 0.05, 'n_estimators': 20, 'num_leaves': 59}\n","cluster:33 ; total_samples:57022 ; positives:377 ; negatives:56645\n","Fitting 7 folds for each of 8 candidates, totalling 56 fits\n","[CV 1/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 1/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.888, test=0.032) total time=   0.9s\n","[CV 2/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 2/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.910, test=0.000) total time=   0.8s\n","[CV 3/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 3/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.893, test=0.056) total time=   1.0s\n","[CV 4/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 4/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.896, test=0.054) total time=   0.9s\n","[CV 5/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 5/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.902, test=0.040) total time=   0.9s\n","[CV 6/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 6/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.928, test=0.026) total time=   0.9s\n","[CV 7/7; 1/8] START learning_rate=0.1, n_estimators=150, num_leaves=45..........\n","[CV 7/7; 1/8] END learning_rate=0.1, n_estimators=150, num_leaves=45;, score=(train=0.900, test=0.032) total time=   0.8s\n","[CV 1/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 1/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.566, test=0.027) total time=   0.6s\n","[CV 2/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 2/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.536, test=0.000) total time=   0.7s\n","[CV 3/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 3/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.521, test=0.047) total time=   0.6s\n","[CV 4/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 4/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.518, test=0.052) total time=   0.6s\n","[CV 5/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 5/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.532, test=0.000) total time=   0.6s\n","[CV 6/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 6/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.579, test=0.030) total time=   0.6s\n","[CV 7/7; 2/8] START learning_rate=0.05, n_estimators=100, num_leaves=43.........\n","[CV 7/7; 2/8] END learning_rate=0.05, n_estimators=100, num_leaves=43;, score=(train=0.567, test=0.019) total time=   0.7s\n","[CV 1/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 1/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.991, test=0.031) total time=   1.1s\n","[CV 2/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 2/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.995, test=0.000) total time=   1.0s\n","[CV 3/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 3/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.997, test=0.029) total time=   1.2s\n","[CV 4/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 4/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.995, test=0.030) total time=   1.1s\n","[CV 5/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 5/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.997, test=0.036) total time=   1.0s\n","[CV 6/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 6/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.998, test=0.029) total time=   1.1s\n","[CV 7/7; 3/8] START learning_rate=0.1, n_estimators=150, num_leaves=77..........\n","[CV 7/7; 3/8] END learning_rate=0.1, n_estimators=150, num_leaves=77;, score=(train=0.995, test=0.030) total time=   1.2s\n","[CV 1/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 1/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.215, test=0.000) total time=   0.3s\n","[CV 2/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 2/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.281, test=0.019) total time=   0.3s\n","[CV 3/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 3/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.246, test=0.024) total time=   0.3s\n","[CV 4/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 4/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.239, test=0.026) total time=   0.3s\n","[CV 5/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 5/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.236, test=0.019) total time=   0.3s\n","[CV 6/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 6/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.239, test=0.026) total time=   0.3s\n","[CV 7/7; 4/8] START learning_rate=0.05, n_estimators=20, num_leaves=62..........\n","[CV 7/7; 4/8] END learning_rate=0.05, n_estimators=20, num_leaves=62;, score=(train=0.249, test=0.029) total time=   0.3s\n","[CV 1/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 1/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.208, test=0.000) total time=   0.3s\n","[CV 2/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 2/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.257, test=0.019) total time=   0.3s\n","[CV 3/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 3/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.257, test=0.056) total time=   0.3s\n","[CV 4/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 4/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.224, test=0.030) total time=   0.3s\n","[CV 5/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 5/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.234, test=0.043) total time=   0.3s\n","[CV 6/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 6/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.220, test=0.026) total time=   0.3s\n","[CV 7/7; 5/8] START learning_rate=0.05, n_estimators=20, num_leaves=59..........\n","[CV 7/7; 5/8] END learning_rate=0.05, n_estimators=20, num_leaves=59;, score=(train=0.227, test=0.030) total time=   0.3s\n","[CV 1/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 1/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.916, test=0.033) total time=   1.0s\n","[CV 2/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 2/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.853, test=0.000) total time=   1.0s\n","[CV 3/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 3/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.853, test=0.048) total time=   1.0s\n","[CV 4/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 4/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.867, test=0.049) total time=   1.0s\n","[CV 5/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 5/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.884, test=0.033) total time=   1.1s\n","[CV 6/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 6/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.881, test=0.040) total time=   1.0s\n","[CV 7/7; 6/8] START learning_rate=0.05, n_estimators=150, num_leaves=68.........\n","[CV 7/7; 6/8] END learning_rate=0.05, n_estimators=150, num_leaves=68;, score=(train=0.881, test=0.037) total time=   1.0s\n","[CV 1/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 1/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.646, test=0.045) total time=   0.6s\n","[CV 2/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 2/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.621, test=0.000) total time=   0.7s\n","[CV 3/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 3/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.600, test=0.047) total time=   0.6s\n","[CV 4/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 4/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.595, test=0.042) total time=   0.7s\n","[CV 5/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 5/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.586, test=0.010) total time=   0.7s\n","[CV 6/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 6/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.642, test=0.029) total time=   0.6s\n","[CV 7/7; 7/8] START learning_rate=0.1, n_estimators=150, num_leaves=20..........\n","[CV 7/7; 7/8] END learning_rate=0.1, n_estimators=150, num_leaves=20;, score=(train=0.607, test=0.030) total time=   0.6s\n","[CV 1/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 1/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.447, test=0.062) total time=   0.4s\n","[CV 2/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 2/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.442, test=0.000) total time=   0.4s\n","[CV 3/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 3/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.440, test=0.051) total time=   0.4s\n","[CV 4/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 4/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.393, test=0.034) total time=   0.4s\n","[CV 5/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 5/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.385, test=0.023) total time=   0.5s\n","[CV 6/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 6/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.402, test=0.033) total time=   0.4s\n","[CV 7/7; 8/8] START learning_rate=0.1, n_estimators=75, num_leaves=26...........\n","[CV 7/7; 8/8] END learning_rate=0.1, n_estimators=75, num_leaves=26;, score=(train=0.437, test=0.030) total time=   0.4s\n","Best_Hyperparameters: \n"," {'learning_rate': 0.1, 'n_estimators': 150, 'num_leaves': 45}\n"]}],"source":["best_params_dict = dict()\n","\n","for c_id in clusters:\n","  model_params = search_hyper_lgbmodel(c_id)\n","  best_params_dict[c_id] = model_params\n","\n","best_params_df = pd.DataFrame(list(best_params_dict.items()),columns=[\"cluster\",\"best_hypers\"])\n","#best_params_df.to_csv(\"/content/drive/MyDrive/01_Machine_Learning/05_Datasets/AppliedAI_data/Assignment23_CS1_RestaurantRecommendation/vendcust/\"+\"lgb_params.csv\")"]},{"cell_type":"code","source":["best_params_df.to_csv(\"/content/drive/MyDrive/01_Machine_Learning/05_Datasets/AppliedAI_data/Assignment23_CS1_RestaurantRecommendation/vendcust/\"+\"lgb_params_new.csv\")"],"metadata":{"id":"t-G5yf-nw8ly"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This method uses the hyperparameters identified for every cluster and trains the model using it\n","\n","Here train data is split into train and CV"],"metadata":{"id":"wdxdYiudI5IU"}},{"cell_type":"code","source":["def train_predict_lgbmodel(c_id,best_params):\n","\n","  train_cust_vendorval_clus = pd.read_csv(\"/content/drive/MyDrive/01_Machine_Learning/05_Datasets/AppliedAI_data/Assignment23_CS1_RestaurantRecommendation/vendcust/\"+\"train_valcust_valvendors_clus\"+str(int(c_id))+\".csv\",index_col=None)\n","  train_cust_vendorval_clus.drop(columns = [\"Unnamed: 0\",\"index\"],inplace=True)\n","  #form X_train and y_train using the cluster data\n","  y_train = train_cust_vendorval_clus[\"target\"].values\n","  X_train = train_cust_vendorval_clus.drop(columns=[\"target\",\"CID X LOC_NUM X VENDOR\",\"cluster\"])\n","\n","  X_train, X_cv, y_train, y_cv = train_test_split(X_train, y_train,stratify=y_train,test_size=0.20)\n","  \n","  pos = np.count_nonzero(y_train == 1)\n","  neg = np.count_nonzero(y_train == 0)\n","  print(\"Train for cluster:{} ; total_samples:{} ; positives:{} ; negatives:{}\".format(c_id,X_train.shape[0],pos,neg))\n","  print(\"CV for cluster:{} ; total_samples:{} ; positives:{} ; negatives:{}\".format(c_id,X_cv.shape[0],np.count_nonzero(y_cv == 1),np.count_nonzero(y_cv == 0)))\n","  \n","  #fit the model with the chosen hyperparameters\n","  best_model = define_best_lgbmodel(best_params,pos,neg)\n","  best_model.fit(X_train,y_train) \n","  ypred_cv = best_model.predict(X_cv) \n","  ypred_train = best_model.predict(X_train) \n","  \n","  #saves the best model for later usage\n","  joblib.dump(best_model,'/content/drive/MyDrive/01_Machine_Learning/05_Datasets/AppliedAI_data/Assignment23_CS1_RestaurantRecommendation/vendcust_models/'+'clus'+str(int(c_id))+'_lgb.pkl')\n","\n","  return y_cv, ypred_cv, ypred_train, y_train"],"metadata":{"id":"Q0BIbS0rI5IT","executionInfo":{"status":"ok","timestamp":1656765010236,"user_tz":-330,"elapsed":319,"user":{"displayName":"Josh L","userId":"09762323287470919868"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["import ast\n","best_params_df = pd.read_csv(\"/content/drive/MyDrive/01_Machine_Learning/05_Datasets/AppliedAI_data/Assignment23_CS1_RestaurantRecommendation/vendcust/\"+\"lgb_params_new.csv\")\n","\n","X_cv_all = pd.DataFrame()\n","y_true_cv_all = np.empty((0,1), float)\n","y_pred_cv_all = np.empty((0,1), float)\n","\n","y_true_train_all = np.empty((0,1), float)\n","y_pred_train_all = np.empty((0,1), float)\n","\n","for c_id in clusters:\n","  #get the hyperparameters for the cluster\n","  best_params = ast.literal_eval(best_params_df.loc[best_params_df[\"cluster\"] == c_id,\"best_hypers\"].reset_index(drop=True)[0])\n","\n","  y_cv, ypred_cv, ypred_train, y_train = train_predict_lgbmodel(c_id, best_params)\n","\n","  y_true_cv_all = np.append(y_true_cv_all,y_cv)\n","  y_pred_cv_all = np.append(y_pred_cv_all,ypred_cv)\n","  \n","  y_true_train_all = np.append(y_true_train_all,y_train)\n","  y_pred_train_all = np.append(y_pred_train_all,ypred_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"13535699-d875-4806-dd39-db152b5fd891","id":"bcsZ2x5pI5IU","executionInfo":{"status":"ok","timestamp":1656765277213,"user_tz":-330,"elapsed":172073,"user":{"displayName":"Josh L","userId":"09762323287470919868"}}},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Train for cluster:4 ; total_samples:376008 ; positives:4142 ; negatives:371866\n","CV for cluster:4 ; total_samples:94002 ; positives:1036 ; negatives:92966\n","Train for cluster:3 ; total_samples:334517 ; positives:6914 ; negatives:327603\n","CV for cluster:3 ; total_samples:83630 ; positives:1728 ; negatives:81902\n","Train for cluster:6 ; total_samples:313340 ; positives:3891 ; negatives:309449\n","CV for cluster:6 ; total_samples:78336 ; positives:973 ; negatives:77363\n","Train for cluster:21 ; total_samples:250674 ; positives:4284 ; negatives:246390\n","CV for cluster:21 ; total_samples:62669 ; positives:1071 ; negatives:61598\n","Train for cluster:0 ; total_samples:219340 ; positives:3814 ; negatives:215526\n","CV for cluster:0 ; total_samples:54835 ; positives:954 ; negatives:53881\n","Train for cluster:20 ; total_samples:218017 ; positives:5446 ; negatives:212571\n","CV for cluster:20 ; total_samples:54505 ; positives:1362 ; negatives:53143\n","Train for cluster:32 ; total_samples:167265 ; positives:2009 ; negatives:165256\n","CV for cluster:32 ; total_samples:41817 ; positives:502 ; negatives:41315\n","Train for cluster:24 ; total_samples:156672 ; positives:3264 ; negatives:153408\n","CV for cluster:24 ; total_samples:39169 ; positives:816 ; negatives:38353\n","Train for cluster:8 ; total_samples:156672 ; positives:2284 ; negatives:154388\n","CV for cluster:8 ; total_samples:39168 ; positives:571 ; negatives:38597\n","Train for cluster:12 ; total_samples:152055 ; positives:1003 ; negatives:151052\n","CV for cluster:12 ; total_samples:38014 ; positives:251 ; negatives:37763\n","Train for cluster:23 ; total_samples:139620 ; positives:974 ; negatives:138646\n","CV for cluster:23 ; total_samples:34905 ; positives:243 ; negatives:34662\n","Train for cluster:10 ; total_samples:125336 ; positives:1330 ; negatives:124006\n","CV for cluster:10 ; total_samples:31335 ; positives:332 ; negatives:31003\n","Train for cluster:9 ; total_samples:121647 ; positives:1902 ; negatives:119745\n","CV for cluster:9 ; total_samples:30412 ; positives:476 ; negatives:29936\n","Train for cluster:19 ; total_samples:121645 ; positives:0 ; negatives:121645\n","CV for cluster:19 ; total_samples:30412 ; positives:0 ; negatives:30412\n","Train for cluster:16 ; total_samples:94005 ; positives:2196 ; negatives:91809\n","CV for cluster:16 ; total_samples:23502 ; positives:549 ; negatives:22953\n","Train for cluster:13 ; total_samples:94002 ; positives:460 ; negatives:93542\n","CV for cluster:13 ; total_samples:23501 ; positives:115 ; negatives:23386\n","Train for cluster:31 ; total_samples:93080 ; positives:1410 ; negatives:91670\n","CV for cluster:31 ; total_samples:23270 ; positives:352 ; negatives:22918\n","Train for cluster:7 ; total_samples:93080 ; positives:2438 ; negatives:90642\n","CV for cluster:7 ; total_samples:23270 ; positives:610 ; negatives:22660\n","Train for cluster:5 ; total_samples:93080 ; positives:1882 ; negatives:91198\n","CV for cluster:5 ; total_samples:23270 ; positives:470 ; negatives:22800\n","Train for cluster:18 ; total_samples:93080 ; positives:769 ; negatives:92311\n","CV for cluster:18 ; total_samples:23270 ; positives:192 ; negatives:23078\n","Train for cluster:11 ; total_samples:78272 ; positives:570 ; negatives:77702\n","CV for cluster:11 ; total_samples:19568 ; positives:142 ; negatives:19426\n","Train for cluster:37 ; total_samples:77875 ; positives:998 ; negatives:76877\n","CV for cluster:37 ; total_samples:19469 ; positives:249 ; negatives:19220\n","Train for cluster:26 ; total_samples:77875 ; positives:577 ; negatives:77298\n","CV for cluster:26 ; total_samples:19469 ; positives:144 ; negatives:19325\n","Train for cluster:27 ; total_samples:77875 ; positives:941 ; negatives:76934\n","CV for cluster:27 ; total_samples:19469 ; positives:235 ; negatives:19234\n","Train for cluster:28 ; total_samples:77875 ; positives:2126 ; negatives:75749\n","CV for cluster:28 ; total_samples:19469 ; positives:532 ; negatives:18937\n","Train for cluster:25 ; total_samples:76028 ; positives:490 ; negatives:75538\n","CV for cluster:25 ; total_samples:19007 ; positives:122 ; negatives:18885\n","Train for cluster:14 ; total_samples:62670 ; positives:1099 ; negatives:61571\n","CV for cluster:14 ; total_samples:15668 ; positives:275 ; negatives:15393\n","Train for cluster:30 ; total_samples:61746 ; positives:694 ; negatives:61052\n","CV for cluster:30 ; total_samples:15437 ; positives:173 ; negatives:15264\n","Train for cluster:1 ; total_samples:46543 ; positives:437 ; negatives:46106\n","CV for cluster:1 ; total_samples:11636 ; positives:109 ; negatives:11527\n","Train for cluster:34 ; total_samples:46540 ; positives:374 ; negatives:46166\n","CV for cluster:34 ; total_samples:11635 ; positives:93 ; negatives:11542\n","Train for cluster:38 ; total_samples:46540 ; positives:371 ; negatives:46169\n","CV for cluster:38 ; total_samples:11635 ; positives:93 ; negatives:11542\n","Train for cluster:36 ; total_samples:46540 ; positives:305 ; negatives:46235\n","CV for cluster:36 ; total_samples:11635 ; positives:76 ; negatives:11559\n","Train for cluster:35 ; total_samples:46540 ; positives:446 ; negatives:46094\n","CV for cluster:35 ; total_samples:11635 ; positives:112 ; negatives:11523\n","Train for cluster:29 ; total_samples:46540 ; positives:355 ; negatives:46185\n","CV for cluster:29 ; total_samples:11635 ; positives:89 ; negatives:11546\n","Train for cluster:15 ; total_samples:46540 ; positives:639 ; negatives:45901\n","CV for cluster:15 ; total_samples:11635 ; positives:160 ; negatives:11475\n","Train for cluster:17 ; total_samples:46540 ; positives:343 ; negatives:46197\n","CV for cluster:17 ; total_samples:11635 ; positives:86 ; negatives:11549\n","Train for cluster:22 ; total_samples:46540 ; positives:620 ; negatives:45920\n","CV for cluster:22 ; total_samples:11635 ; positives:155 ; negatives:11480\n","Train for cluster:2 ; total_samples:46540 ; positives:358 ; negatives:46182\n","CV for cluster:2 ; total_samples:11635 ; positives:90 ; negatives:11545\n","Train for cluster:39 ; total_samples:46540 ; positives:945 ; negatives:45595\n","CV for cluster:39 ; total_samples:11635 ; positives:236 ; negatives:11399\n","Train for cluster:33 ; total_samples:45617 ; positives:302 ; negatives:45315\n","CV for cluster:33 ; total_samples:11405 ; positives:75 ; negatives:11330\n"]}]},{"cell_type":"code","source":["def plot_confusion_matrix(conf_matrix):\n","  ax= plt.subplot()\n","  sns.heatmap(conf_matrix, annot=True,cmap='Blues',ax=ax,fmt='d')\n","  # labels, title and ticks\n","  ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n","  ax.set_ylim(2.0, 0)\n","  ax.set_title('Confusion Matrix')\n","  ax.xaxis.set_ticklabels(['Negative','Positive']) \n","  ax.yaxis.set_ticklabels(['Negative','Positive'])\n","  plt.show()\n","  return None"],"metadata":{"id":"uPt3OXlpI5IU","executionInfo":{"status":"ok","timestamp":1656765389841,"user_tz":-330,"elapsed":379,"user":{"displayName":"Josh L","userId":"09762323287470919868"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["#Consolidated result from all cluster models\n","print(\"CV data - F1 score\", round(f1_score(y_true_cv_all, y_pred_cv_all,average='macro'),2))\n","print(\"Train data - F1 score\", round(f1_score(y_true_train_all, y_pred_train_all,average='macro'),2))\n","\n","print(\"\")\n","print(\"CV Classification Report and Confusion Matrix\")\n","print(metrics.classification_report(y_true_cv_all, y_pred_cv_all))\n","plot_confusion_matrix(metrics.confusion_matrix(y_true_cv_all, y_pred_cv_all))\n","\n","print(\"\")\n","print(\"\\nTrain Classification Report and Confusion Matrix\")\n","print(metrics.classification_report(y_true_train_all, y_pred_train_all))\n","plot_confusion_matrix(metrics.confusion_matrix(y_true_train_all, y_pred_train_all))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"P5YOzLd46bu8","executionInfo":{"status":"ok","timestamp":1656765923950,"user_tz":-330,"elapsed":22514,"user":{"displayName":"Josh L","userId":"09762323287470919868"}},"outputId":"c12bb511-7739-47df-c469-21cef49b01fc"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["CV data - F1 score 0.6\n","Train data - F1 score 0.66\n","\n","CV Classification Report and Confusion Matrix\n","              precision    recall  f1-score   support\n","\n","         0.0       0.99      0.98      0.99   1124390\n","         1.0       0.18      0.27      0.21     15849\n","\n","    accuracy                           0.97   1140239\n","   macro avg       0.58      0.63      0.60   1140239\n","weighted avg       0.98      0.97      0.98   1140239\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"stream","name":"stdout","text":["\n","\n","Train Classification Report and Confusion Matrix\n","              precision    recall  f1-score   support\n","\n","         0.0       0.99      0.98      0.99   4497509\n","         1.0       0.27      0.42      0.33     63402\n","\n","    accuracy                           0.98   4560911\n","   macro avg       0.63      0.70      0.66   4560911\n","weighted avg       0.98      0.98      0.98   4560911\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LmOlRYTNQY2B"},"outputs":[],"source":["test_customers = process_customer_demo(input_location,test_customer_demographics)\n","test_locations = process_customer_location(input_location,test_customer_locations)\n","test_cust_vendorval  = merge_demo_loc_vendor(test_customers,test_locations,vendors) \n","test_valcust_valvendors, test_valcust_outvendors, test_outcust_outvendors, test_outcust_valvendors = segregate_outliers(test_cust_vendorval)   \n","\n","\n","print(test_customers.shape)\n","print(test_locations.shape)\n","print(test_cust_vendorval.shape)\n","print(\"test_cust_vendorval - positive{} - negative{}\".format(test_cust_vendorval[test_cust_vendorval[\"target\"] == 1].shape,test_cust_vendorval[test_cust_vendorval[\"target\"] == 0].shape))\n","\n","print(\"Valid customers buying from valid vendors: \",test_valcust_valvendors.shape)\n","print(\"Valid customers buying from outlier vendors: \",test_valcust_outvendors.shape)\n","print(\"Outlier customers buying from outlier vendors: \",test_outcust_outvendors.shape)\n","print(\"Outlier customers buying from valid vendors: \",test_outcust_valvendors.shape)"]},{"cell_type":"markdown","source":["##Train using Random Forest Classifier"],"metadata":{"id":"lJ7dJrMfjY9g"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25578,"status":"ok","timestamp":1655336596163,"user":{"displayName":"Josh L","userId":"09762323287470919868"},"user_tz":-330},"outputId":"b8aed90e-4a50-481c-dec0-49866475a1d3","id":"H8d-uIMh-TzQ"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"TEKTqT5X-TzQ","executionInfo":{"status":"ok","timestamp":1656766376894,"user_tz":-330,"elapsed":295,"user":{"displayName":"Josh L","userId":"09762323287470919868"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import ast"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"9PLu9k9c-TzR","executionInfo":{"status":"ok","timestamp":1656766384436,"user_tz":-330,"elapsed":3,"user":{"displayName":"Josh L","userId":"09762323287470919868"}}},"outputs":[],"source":["from sklearn import metrics\n","from scipy.stats import randint as sp_randint\n","from scipy.stats import uniform as sp_uniform\n","\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import RandomizedSearchCV\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import f1_score, recall_score\n","import sklearn.externals\n","import joblib\n","import pickle"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"a8dIB67y-TzR","executionInfo":{"status":"ok","timestamp":1656766387234,"user_tz":-330,"elapsed":315,"user":{"displayName":"Josh L","userId":"09762323287470919868"}}},"outputs":[],"source":["cat_features = ['location_type','customer_city', 'customer_country', 'gender', 'verified_x','language_x', 'year_customer_created', \n","                'month_customer_created', 'year_customer_updated', 'month_customer_updated','vendor_category_id', 'delivery_charge', \n","                'serving_distance', 'is_open', 'prepration_time', 'commission', 'discount_percentage', 'status', 'verified_y', 'rank', \n","                'language_y', 'vendor_rating', 'device_type', 'tag_counts','Pasta', 'Shawarma', 'Frozen yoghurt', 'Waffles', 'Mojitos ', \n","                'Kushari', 'Indian', 'Free Delivery', 'Soups', 'Mojitos', 'Vegetarian', 'Mexican', 'Dimsum', 'Smoothies', 'Grills', 'Desserts', \n","                'Fresh Juices', 'Rice','Pastas', 'Pancakes', 'Omani', 'Combos', 'Bagels', 'Kids meal', 'Breakfast', 'Lebanese', 'Spanish Latte', \n","                'Steaks', 'Organic', 'Sushi', 'Milkshakes', 'Pizza', 'American', 'Churros', 'Biryani', 'Family Meal', 'Chinese', 'Seafood', 'Pastry', \n","                'Healthy Food', 'Donuts', 'Mishkak', 'Hot Dogs', 'Cakes', 'Coffee', 'Manakeesh', 'Shuwa', 'Burgers', 'Sandwiches', 'Thai', 'Japanese', 'Karak', \n","                'Kebabs', 'Arabic', 'Cafe', 'Mandazi', 'Salads', 'Hot Chocolate', 'Thali', 'Fatayers', 'Sweets', 'Asian', 'Ice creams', 'Italian', 'Pizzas', \n","                'Rolls', 'Crepes', 'Fries','primary_tags_mod', 'year_vendor_created', 'month_vendor_created', 'year_vendor_updated', 'month_vendor_updated', \n","                'vendor_city', 'vendor_country']"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"JkHoPEL5-TzR","executionInfo":{"status":"ok","timestamp":1656766387561,"user_tz":-330,"elapsed":1,"user":{"displayName":"Josh L","userId":"09762323287470919868"}}},"outputs":[],"source":["num_features = ['latitude_x', 'longitude_x','latitude_y', 'longitude_y','open_duration','customer_id_count', 'customer_id_nunique', \n","                'payment_mode_nunique', 'promo_code_count', 'vendor_discount_amount_sum', 'promo_code_discount_percentage_mean', \n","                'item_count_median', 'grand_total_median', 'driver_rating_median', 'deliverydistance_mean', 'preparationtime_mean', \n","                'order_turnaround_min', 'order_turnaround_max', 'order_turnaround_mean','haversine_distance', \n","                'distance_diff', 'distance_ratio', 'latitude_diff','longitude_diff']"]},{"cell_type":"markdown","metadata":{"id":"HFbteZkI-TzR"},"source":["Read the cluster data - file where the cluster ids are ordered by size"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":2335,"status":"ok","timestamp":1655336600083,"user":{"displayName":"Josh L","userId":"09762323287470919868"},"user_tz":-330},"outputId":"08dc2e60-9621-442e-9104-0b3237f26ece","id":"BYO5M5aq-TzR"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   cluster  CID X LOC_NUM X VENDOR\n","0        4                  470010\n","1        3                  418147\n","2        6                  391676\n","3       21                  313343\n","4        0                  274175"],"text/html":["\n","  <div id=\"df-17aa0e07-09ba-481d-b488-3b03ef7f913d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>cluster</th>\n","      <th>CID X LOC_NUM X VENDOR</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4</td>\n","      <td>470010</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3</td>\n","      <td>418147</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>6</td>\n","      <td>391676</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>21</td>\n","      <td>313343</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>274175</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17aa0e07-09ba-481d-b488-3b03ef7f913d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-17aa0e07-09ba-481d-b488-3b03ef7f913d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-17aa0e07-09ba-481d-b488-3b03ef7f913d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":6}],"source":["cluster_df = pd.read_csv(\"/content/drive/MyDrive/01_Machine_Learning/05_Datasets/AppliedAI_data/Assignment23_CS1_RestaurantRecommendation/\"+\"cluster_vendcust.csv\",index_col=False)\n","cluster_df.drop(columns = [\"Unnamed: 0\"],inplace=True)\n","clusters = cluster_df[\"cluster\"].tolist()\n","cluster_df.head()"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"zQ-Vfi83kvh3","executionInfo":{"status":"ok","timestamp":1656766455269,"user_tz":-330,"elapsed":365,"user":{"displayName":"Josh L","userId":"09762323287470919868"}}},"outputs":[],"source":["def preprocess_rfmodel(pos,neg):\n","  if pos != 0:\n","    class_weight = {0:round((neg+pos)/(2*neg)),1:round(np.sqrt((neg+pos)/(2*pos)))} #since the positive class is extremely unbalanced sqrt of the value is taken\n","\n","  else:\n","    class_weight = None\n","  #preprocess data\n","\n","  #model and its parameters\n","  param = {'n_estimators':[20,40, 50, 60, 80],\n","          'max_depth':[int(x) for x in np.linspace(10, 30, num = 1)] + [None]\n","          #'min_samples_split': sp_randint(10,60) \n","        }\n","\n","  clf_dt = RandomForestClassifier(random_state=7,class_weight = class_weight)\n","\n","  return clf_dt, param"]},{"cell_type":"markdown","metadata":{"id":"skG5lGq_kvh4"},"source":["This method builds the RF classifier model for the best hyperparameters"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"x17EORsGkvh5","executionInfo":{"status":"ok","timestamp":1656766455270,"user_tz":-330,"elapsed":4,"user":{"displayName":"Josh L","userId":"09762323287470919868"}}},"outputs":[],"source":["def define_best_rfmodel(chosen_params,pos,neg):\n","\n","  #https://stats.stackexchange.com/questions/243207/what-is-the-proper-usage-of-scale-pos-weight-in-xgboost-for-imbalanced-datasets\n","  if pos != 0:\n","    class_weight = {0:round((neg+pos)/(2*neg)),1:round(np.sqrt((neg+pos)/(2*pos)))} #since the positive class is extremely unbalanced sqrt of the value is taken\n","\n","  else:\n","    class_weight = None\n","  \n","  best_clf=RandomForestClassifier(n_estimators = chosen_params[\"n_estimators\"], \n","                                  max_depth = chosen_params[\"max_depth\"], \n","                                  class_weight = class_weight,\n","                                  random_state=7)\n","  \n","  return best_clf"]},{"cell_type":"code","source":["def search_hyper_rfmodel(c_id):\n","  \n","  train_cust_vendorval_clus = pd.read_csv(\"/content/drive/MyDrive/01_Machine_Learning/05_Datasets/AppliedAI_data/Assignment23_CS1_RestaurantRecommendation/vendcust/\"+\"train_valcust_valvendors_clus\"+str(int(c_id))+\".csv\",index_col=None)\n","  train_cust_vendorval_clus.drop(columns = [\"Unnamed: 0\",\"index\"],inplace=True)\n","  #form X_train and y_train using the cluster data\n","  y_train = train_cust_vendorval_clus[\"target\"].values\n","  X_train = train_cust_vendorval_clus.drop(columns=[\"target\",\"CID X LOC_NUM X VENDOR\",\"cluster\"])\n","  \n","  pos = np.count_nonzero(y_train == 1)\n","  neg = np.count_nonzero(y_train == 0)\n","  print(\"cluster:{} ; total_samples:{} ; positives:{} ; negatives:{}\".format(c_id,X_train.shape[0],pos,neg))\n","\n","  #perform one hot encoding for the categorical variables\n","  ohe = OneHotEncoder(handle_unknown='ignore')\n","  ohe.fit_transform(X_train[cat_features])\n","  \n","  #ohe returns a sparse matrix..hence convert to numpy array\n","  x_train_cat_ohe = pd.DataFrame(ohe.transform(X_train[cat_features]).toarray(),columns=ohe.get_feature_names_out())\n","  X_train = X_train[num_features].join(x_train_cat_ohe)\n","\n","  #define the model, its hyperparameter space and do required data preprocessing if any\n","  model,param = preprocess_rfmodel(pos,neg)\n","  \n","  #using RandomizedSearchCV to search for hyperparameters with stratified k-fold cross validation\n","  cv_fold = 7\n","  score = 'f1'\n","  nbr_combos = 5\n","  srch_model = RandomizedSearchCV(model, param ,cv=cv_fold,scoring=score,return_train_score=True,n_iter=nbr_combos,random_state=7,verbose=100,error_score='raise')  \n","  clf_model = srch_model.fit(X_train,y_train)  \n","\n","  #retrieve the best hyperparameters\n","  best_params = clf_model.best_params_  #retrieve the best hyperparameters after training\n","  print(\"Best_Hyperparameters: \\n\",best_params)\n","\n","  return best_params\n","  "],"metadata":{"id":"Kz0Lv6BNwMzQ","executionInfo":{"status":"ok","timestamp":1656766461529,"user_tz":-330,"elapsed":1063,"user":{"displayName":"Josh L","userId":"09762323287470919868"}}},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":["This code searches the hyperparameters"],"metadata":{"id":"4q2RCcbh1nHI"}},{"cell_type":"code","source":["best_params_dict = dict()\n","for c_id in clusters:\n","  model_params = search_hyper_rfmodel(c_id)\n","  best_params_dict[c_id] = model_params\n","  \n","best_params_df = pd.DataFrame(list(best_params_dict.items()),columns=[\"cluster\",\"best_hypers\"])\n","best_params_df.to_csv(\"/content/drive/MyDrive/01_Machine_Learning/05_Datasets/AppliedAI_data/Assignment23_CS1_RestaurantRecommendation/vendcust_models_rf/\"+\"lgb_params.csv\")"],"metadata":{"id":"J2c1DlbOxEIg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["How to retain the onehotencodings from train during test?\n","\n","https://stackoverflow.com/questions/69197666/how-to-retain-the-columns-from-training-data-for-prediction-in-python"],"metadata":{"id":"Db0nigjt2ViC"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import OneHotEncoder\n","import pickle\n","def train_predict_rfmodel(c_id,best_params):\n","\n","  train_cust_vendorval_clus = pd.read_csv(\"/content/drive/MyDrive/01_Machine_Learning/05_Datasets/AppliedAI_data/Assignment23_CS1_RestaurantRecommendation/vendcust/\"+\"train_valcust_valvendors_clus\"+str(int(c_id))+\".csv\",index_col=None)\n","  train_cust_vendorval_clus.drop(columns = [\"Unnamed: 0\",\"index\"],inplace=True)\n","  #form X_train and y_train using the cluster data\n","  y_train = train_cust_vendorval_clus[\"target\"].values\n","  X_train = train_cust_vendorval_clus.drop(columns=[\"target\",\"CID X LOC_NUM X VENDOR\",\"cluster\"])\n","\n","  X_train, X_cv, y_train, y_cv = train_test_split(X_train, y_train,stratify=y_train,test_size=0.20)\n","  \n","  #perform one hot encoding for the categorical variables\n","  ohe = OneHotEncoder(handle_unknown='ignore')\n","  ohe.fit(X_train[cat_features])\n","  pickle.dump(ohe, open(\"/content/drive/MyDrive/01_Machine_Learning/05_Datasets/AppliedAI_data/Assignment23_CS1_RestaurantRecommendation/vendcust_models_ohe/\"+\"onehot_clus\"+str(int(c_id))+\".pickle\", 'wb'))\n","  \n","  #ohe returns a sparse matrix..hence convert to numpy array\n","  x_train_cat_ohe = pd.DataFrame(ohe.transform(X_train[cat_features]).toarray(),columns=ohe.get_feature_names_out())\n","  x_cv_cat_ohe = pd.DataFrame(ohe.transform(X_cv[cat_features]).toarray(),columns=ohe.get_feature_names_out())\n","  \n","  X_train = X_train[num_features].reset_index(drop=True).join(x_train_cat_ohe)\n","  X_cv = X_cv[num_features].reset_index(drop=True).join(x_cv_cat_ohe)\n","\n","  pos = np.count_nonzero(y_train == 1)\n","  neg = np.count_nonzero(y_train == 0)\n","  print(\"cluster:{} ; total_samples:{} ; positives:{} ; negatives:{}\".format(c_id,X_train.shape[0],pos,neg))\n","  print(\"cluster:{} ; total_samples:{} ; positives:{} ; negatives:{}\".format(c_id,X_cv.shape[0],np.count_nonzero(y_cv == 1),np.count_nonzero(y_cv == 0)))\n","  \n","  #fit the model with the chosen hyperparameters\n","  best_model = define_best_rfmodel(best_params,pos,neg)\n","  best_model.fit(X_train,y_train) \n","  ypred_cv = best_model.predict(X_cv) \n","  ypred_train = best_model.predict(X_train) \n","  \n","  #saves the best model for later usage\n","  joblib.dump(best_model,'/content/drive/MyDrive/01_Machine_Learning/05_Datasets/AppliedAI_data/Assignment23_CS1_RestaurantRecommendation/vendcust_models_rfnew/'+'clus'+str(int(c_id))+'_lgb.pkl')\n","\n","  X_cv[\"cluster\"] = c_id\n","  return X_cv, y_cv, ypred_cv, ypred_train, y_train"],"metadata":{"id":"VaVJcd7Tx1sX","executionInfo":{"status":"ok","timestamp":1656766612331,"user_tz":-330,"elapsed":368,"user":{"displayName":"Josh L","userId":"09762323287470919868"}}},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":["This code uses the hyperparameters identified for every cluster and trains the model using it\n","\n","Here train data is split into train and CV"],"metadata":{"id":"dMjB23Jw1Jtp"}},{"cell_type":"code","source":["best_params_df = pd.read_csv(\"/content/drive/MyDrive/01_Machine_Learning/05_Datasets/AppliedAI_data/Assignment23_CS1_RestaurantRecommendation/vendcust_models_rf/\"+\"lgb_params.csv\")\n","\n","X_cv_all = pd.DataFrame()\n","y_true_cv_all = np.empty((0,1), float)\n","y_pred_cv_all = np.empty((0,1), float)\n","\n","y_true_train_all = np.empty((0,1), float)\n","y_pred_train_all = np.empty((0,1), float)\n","\n","for c_id in clusters:\n","  #get the hyperparameters for the cluster\n","  best_params = ast.literal_eval(best_params_df.loc[best_params_df[\"cluster\"] == c_id,\"best_hypers\"].reset_index(drop=True)[0])\n","\n","  X_cv, y_cv, ypred_cv, ypred_train, y_train = train_predict_rfmodel(c_id, best_params)\n","\n","  y_true_cv_all = np.append(y_true_cv_all,y_cv)\n","  y_pred_cv_all = np.append(y_pred_cv_all,ypred_cv)\n","  X_cv_all = X_cv_all.append(X_cv)\n","\n","  y_true_train_all = np.append(y_true_train_all,y_train)\n","  y_pred_train_all = np.append(y_pred_train_all,ypred_train)\n","  "],"metadata":{"id":"zr8d6BKa0vrp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656767137779,"user_tz":-330,"elapsed":522278,"user":{"displayName":"Josh L","userId":"09762323287470919868"}},"outputId":"7c433928-11de-4728-d83e-1b93e2bcc564"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["cluster:4 ; total_samples:376008 ; positives:4142 ; negatives:371866\n","cluster:4 ; total_samples:94002 ; positives:1036 ; negatives:92966\n","cluster:3 ; total_samples:334517 ; positives:6914 ; negatives:327603\n","cluster:3 ; total_samples:83630 ; positives:1728 ; negatives:81902\n","cluster:6 ; total_samples:313340 ; positives:3891 ; negatives:309449\n","cluster:6 ; total_samples:78336 ; positives:973 ; negatives:77363\n","cluster:21 ; total_samples:250674 ; positives:4284 ; negatives:246390\n","cluster:21 ; total_samples:62669 ; positives:1071 ; negatives:61598\n","cluster:0 ; total_samples:219340 ; positives:3814 ; negatives:215526\n","cluster:0 ; total_samples:54835 ; positives:954 ; negatives:53881\n","cluster:20 ; total_samples:218017 ; positives:5446 ; negatives:212571\n","cluster:20 ; total_samples:54505 ; positives:1362 ; negatives:53143\n","cluster:32 ; total_samples:167265 ; positives:2009 ; negatives:165256\n","cluster:32 ; total_samples:41817 ; positives:502 ; negatives:41315\n","cluster:24 ; total_samples:156672 ; positives:3264 ; negatives:153408\n","cluster:24 ; total_samples:39169 ; positives:816 ; negatives:38353\n","cluster:8 ; total_samples:156672 ; positives:2284 ; negatives:154388\n","cluster:8 ; total_samples:39168 ; positives:571 ; negatives:38597\n","cluster:12 ; total_samples:152055 ; positives:1003 ; negatives:151052\n","cluster:12 ; total_samples:38014 ; positives:251 ; negatives:37763\n","cluster:23 ; total_samples:139620 ; positives:974 ; negatives:138646\n","cluster:23 ; total_samples:34905 ; positives:243 ; negatives:34662\n","cluster:10 ; total_samples:125336 ; positives:1330 ; negatives:124006\n","cluster:10 ; total_samples:31335 ; positives:332 ; negatives:31003\n","cluster:9 ; total_samples:121647 ; positives:1902 ; negatives:119745\n","cluster:9 ; total_samples:30412 ; positives:476 ; negatives:29936\n","cluster:19 ; total_samples:121645 ; positives:0 ; negatives:121645\n","cluster:19 ; total_samples:30412 ; positives:0 ; negatives:30412\n","cluster:16 ; total_samples:94005 ; positives:2196 ; negatives:91809\n","cluster:16 ; total_samples:23502 ; positives:549 ; negatives:22953\n","cluster:13 ; total_samples:94002 ; positives:460 ; negatives:93542\n","cluster:13 ; total_samples:23501 ; positives:115 ; negatives:23386\n","cluster:31 ; total_samples:93080 ; positives:1410 ; negatives:91670\n","cluster:31 ; total_samples:23270 ; positives:352 ; negatives:22918\n","cluster:7 ; total_samples:93080 ; positives:2438 ; negatives:90642\n","cluster:7 ; total_samples:23270 ; positives:610 ; negatives:22660\n","cluster:5 ; total_samples:93080 ; positives:1882 ; negatives:91198\n","cluster:5 ; total_samples:23270 ; positives:470 ; negatives:22800\n","cluster:18 ; total_samples:93080 ; positives:769 ; negatives:92311\n","cluster:18 ; total_samples:23270 ; positives:192 ; negatives:23078\n","cluster:11 ; total_samples:78272 ; positives:570 ; negatives:77702\n","cluster:11 ; total_samples:19568 ; positives:142 ; negatives:19426\n","cluster:37 ; total_samples:77875 ; positives:998 ; negatives:76877\n","cluster:37 ; total_samples:19469 ; positives:249 ; negatives:19220\n","cluster:26 ; total_samples:77875 ; positives:577 ; negatives:77298\n","cluster:26 ; total_samples:19469 ; positives:144 ; negatives:19325\n","cluster:27 ; total_samples:77875 ; positives:941 ; negatives:76934\n","cluster:27 ; total_samples:19469 ; positives:235 ; negatives:19234\n","cluster:28 ; total_samples:77875 ; positives:2126 ; negatives:75749\n","cluster:28 ; total_samples:19469 ; positives:532 ; negatives:18937\n","cluster:25 ; total_samples:76028 ; positives:490 ; negatives:75538\n","cluster:25 ; total_samples:19007 ; positives:122 ; negatives:18885\n","cluster:14 ; total_samples:62670 ; positives:1099 ; negatives:61571\n","cluster:14 ; total_samples:15668 ; positives:275 ; negatives:15393\n","cluster:30 ; total_samples:61746 ; positives:694 ; negatives:61052\n","cluster:30 ; total_samples:15437 ; positives:173 ; negatives:15264\n","cluster:1 ; total_samples:46543 ; positives:437 ; negatives:46106\n","cluster:1 ; total_samples:11636 ; positives:109 ; negatives:11527\n","cluster:34 ; total_samples:46540 ; positives:374 ; negatives:46166\n","cluster:34 ; total_samples:11635 ; positives:93 ; negatives:11542\n","cluster:38 ; total_samples:46540 ; positives:371 ; negatives:46169\n","cluster:38 ; total_samples:11635 ; positives:93 ; negatives:11542\n","cluster:36 ; total_samples:46540 ; positives:305 ; negatives:46235\n","cluster:36 ; total_samples:11635 ; positives:76 ; negatives:11559\n","cluster:35 ; total_samples:46540 ; positives:446 ; negatives:46094\n","cluster:35 ; total_samples:11635 ; positives:112 ; negatives:11523\n","cluster:29 ; total_samples:46540 ; positives:355 ; negatives:46185\n","cluster:29 ; total_samples:11635 ; positives:89 ; negatives:11546\n","cluster:15 ; total_samples:46540 ; positives:639 ; negatives:45901\n","cluster:15 ; total_samples:11635 ; positives:160 ; negatives:11475\n","cluster:17 ; total_samples:46540 ; positives:343 ; negatives:46197\n","cluster:17 ; total_samples:11635 ; positives:86 ; negatives:11549\n","cluster:22 ; total_samples:46540 ; positives:620 ; negatives:45920\n","cluster:22 ; total_samples:11635 ; positives:155 ; negatives:11480\n","cluster:2 ; total_samples:46540 ; positives:358 ; negatives:46182\n","cluster:2 ; total_samples:11635 ; positives:90 ; negatives:11545\n","cluster:39 ; total_samples:46540 ; positives:945 ; negatives:45595\n","cluster:39 ; total_samples:11635 ; positives:236 ; negatives:11399\n","cluster:33 ; total_samples:45617 ; positives:302 ; negatives:45315\n","cluster:33 ; total_samples:11405 ; positives:75 ; negatives:11330\n"]}]},{"cell_type":"code","source":["def plot_confusion_matrix(conf_matrix):\n","  ax= plt.subplot()\n","  sns.heatmap(conf_matrix, annot=True,cmap='Blues',ax=ax,fmt='d')\n","  # labels, title and ticks\n","  ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n","  ax.set_ylim(2.0, 0)\n","  ax.set_title('Confusion Matrix')\n","  ax.xaxis.set_ticklabels(['Negative','Positive']) \n","  ax.yaxis.set_ticklabels(['Negative','Positive'])\n","  plt.show()\n","  return None"],"metadata":{"id":"UkS0H1ZoaU-L","executionInfo":{"status":"ok","timestamp":1656767137780,"user_tz":-330,"elapsed":6,"user":{"displayName":"Josh L","userId":"09762323287470919868"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["#Consolidated result from all cluster models\n","\n","print(\"CV data - F1 score of RF model\", round(f1_score(y_true_cv_all, y_pred_cv_all,average='macro'),2))\n","print(\"Train data - F1 score of RF model\", round(f1_score(y_true_train_all, y_pred_train_all,average='macro'),2))\n","\n","print(metrics.classification_report(y_true_cv_all, y_pred_cv_all))\n","print(\"CV Classification Report and Confusion Matrix\")\n","print(metrics.classification_report(y_true_cv_all, y_pred_cv_all))\n","#print(metrics.confusion_matrix(y_true_all, y_pred_all))\n","plot_confusion_matrix(metrics.confusion_matrix(y_true_cv_all, y_pred_cv_all))\n","\n","print(\"\\nTrain Classification Report and Confusion Matrix\")\n","print(metrics.classification_report(y_true_train_all, y_pred_train_all))\n","#print(metrics.confusion_matrix(y_true_all, y_pred_all))\n","plot_confusion_matrix(metrics.confusion_matrix(y_true_train_all, y_pred_train_all))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"RyzgjuUdBm7l","executionInfo":{"status":"ok","timestamp":1656767555800,"user_tz":-330,"elapsed":24231,"user":{"displayName":"Josh L","userId":"09762323287470919868"}},"outputId":"f041f313-5c55-49c4-e4bb-f136649dddfc"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["CV data - F1 score of RF model 0.57\n","Train data - F1 score of RF model 0.79\n","              precision    recall  f1-score   support\n","\n","         0.0       0.99      1.00      0.99   1124390\n","         1.0       0.29      0.10      0.15     15849\n","\n","    accuracy                           0.98   1140239\n","   macro avg       0.64      0.55      0.57   1140239\n","weighted avg       0.98      0.98      0.98   1140239\n","\n","CV Classification Report and Confusion Matrix\n","              precision    recall  f1-score   support\n","\n","         0.0       0.99      1.00      0.99   1124390\n","         1.0       0.29      0.10      0.15     15849\n","\n","    accuracy                           0.98   1140239\n","   macro avg       0.64      0.55      0.57   1140239\n","weighted avg       0.98      0.98      0.98   1140239\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"stream","name":"stdout","text":["\n","Train Classification Report and Confusion Matrix\n","              precision    recall  f1-score   support\n","\n","         0.0       0.99      1.00      1.00   4497509\n","         1.0       0.70      0.51      0.59     63402\n","\n","    accuracy                           0.99   4560911\n","   macro avg       0.85      0.75      0.79   4560911\n","weighted avg       0.99      0.99      0.99   4560911\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":[" Identify restaurants with most customers (most popular) in largely populated clusters of Solution#2 and recommend them as a generic solution to the 250 customers without any information."],"metadata":{"id":"AUmnmLzLsl3t"}},{"cell_type":"markdown","source":["- Identify the largely populated clusters \n","- Shortlist the restaurants with large number of customers (having large number of positive class)"],"metadata":{"id":"4W9jQApsspZp"}}],"metadata":{"colab":{"collapsed_sections":[],"machine_shape":"hm","name":"CS1_Restaurant_Reco_ContentFiltering.ipynb","provenance":[{"file_id":"1xfkKWSWN29eZmgkIQvHv4Tni65E8_XJ-","timestamp":1655625383014},{"file_id":"1fgNdmftSxmI4IcWeGHb9gzC8XaOW2Xl8","timestamp":1655183803730},{"file_id":"1f_EavOq3s2K-NbiGqSOBdmTiPosAxVNg","timestamp":1654664493970}],"authorship_tag":"ABX9TyPX0icwjXVxgc/UA0Myubcc"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"TPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}